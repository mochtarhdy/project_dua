[0m21:09:10.551494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bf82e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10971af40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10971ac40>]}


============================== 21:09:10.558564 | 8dc00a1c-437b-49b0-8bb8-bb43ee0dbeed ==============================
[0m21:09:10.558564 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:09:10.559252 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt debug', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:09:10.583804 [info ] [MainThread]: dbt version: 1.8.5
[0m21:09:10.584312 [info ] [MainThread]: python version: 3.9.6
[0m21:09:10.584877 [info ] [MainThread]: python path: /Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/bin/python3
[0m21:09:10.585254 [info ] [MainThread]: os info: macOS-14.5-x86_64-i386-64bit
[0m21:09:10.589900 [info ] [MainThread]: Using profiles dir at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse
[0m21:09:10.590377 [info ] [MainThread]: Using profiles.yml file at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/profiles.yml
[0m21:09:10.590848 [info ] [MainThread]: Using dbt_project.yml file at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/dbt_project.yml
[0m21:09:10.702622 [info ] [MainThread]: Configuration:
[0m21:09:10.703487 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m21:09:10.704184 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:09:10.704643 [info ] [MainThread]: Required dependencies:
[0m21:09:10.705387 [debug] [MainThread]: Executing "git --help"
[0m21:09:10.740060 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:09:10.741163 [debug] [MainThread]: STDERR: "b''"
[0m21:09:10.741680 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:09:10.742104 [info ] [MainThread]: Connection test skipped since no profile was found
[0m21:09:10.742503 [info ] [MainThread]: [31m1 check failed:[0m
[0m21:09:10.742873 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Could not find profile named 'datawarehouse'


[0m21:09:10.744644 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_wall_clock_time": 0.285466, "process_user_time": 1.593096, "process_kernel_time": 0.272348, "process_mem_max_rss": "85901312", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:09:10.745465 [debug] [MainThread]: Command `dbt debug` failed at 21:09:10.745322 after 0.29 seconds
[0m21:09:10.746046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bf82e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084450a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10971a3a0>]}
[0m21:09:10.746589 [debug] [MainThread]: Flushing usage events
[0m21:09:25.418556 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m21:10:20.681210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbda2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116fcf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116fcc10>]}


============================== 21:10:20.688479 | 26273683-ed66-4e45-8126-e4e943ae687d ==============================
[0m21:10:20.688479 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:10:20.689210 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:10:20.715135 [info ] [MainThread]: dbt version: 1.8.5
[0m21:10:20.715673 [info ] [MainThread]: python version: 3.9.6
[0m21:10:20.716143 [info ] [MainThread]: python path: /Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/bin/python3
[0m21:10:20.716542 [info ] [MainThread]: os info: macOS-14.5-x86_64-i386-64bit
[0m21:10:21.217977 [info ] [MainThread]: Using profiles dir at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse
[0m21:10:21.218532 [info ] [MainThread]: Using profiles.yml file at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/profiles.yml
[0m21:10:21.218957 [info ] [MainThread]: Using dbt_project.yml file at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/dbt_project.yml
[0m21:10:21.319149 [info ] [MainThread]: Configuration:
[0m21:10:21.319700 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m21:10:21.320110 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:10:21.320569 [info ] [MainThread]: Required dependencies:
[0m21:10:21.321173 [debug] [MainThread]: Executing "git --help"
[0m21:10:21.349098 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:10:21.350672 [debug] [MainThread]: STDERR: "b''"
[0m21:10:21.351200 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:10:21.351649 [info ] [MainThread]: Connection test skipped since no profile was found
[0m21:10:21.352162 [info ] [MainThread]: [31m1 check failed:[0m
[0m21:10:21.352576 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "datawarehouse", target "dev" invalid: 5435 is not of type 'string'


[0m21:10:21.354751 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_wall_clock_time": 0.75009215, "process_user_time": 1.672725, "process_kernel_time": 0.287629, "process_mem_max_rss": "88768512", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:10:21.355910 [debug] [MainThread]: Command `dbt debug` failed at 21:10:21.355603 after 0.75 seconds
[0m21:10:21.356716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbda2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110433280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110426df0>]}
[0m21:10:21.357543 [debug] [MainThread]: Flushing usage events
[0m21:10:57.319801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10455b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106060f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106060c40>]}


============================== 21:10:57.325662 | 1ddf4ccc-471c-478a-9214-2a9cb59692bf ==============================
[0m21:10:57.325662 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:10:57.326347 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:10:57.337341 [info ] [MainThread]: dbt version: 1.8.5
[0m21:10:57.338055 [info ] [MainThread]: python version: 3.9.6
[0m21:10:57.338509 [info ] [MainThread]: python path: /Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/bin/python3
[0m21:10:57.338881 [info ] [MainThread]: os info: macOS-14.5-x86_64-i386-64bit
[0m21:10:57.401603 [info ] [MainThread]: Using profiles dir at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse
[0m21:10:57.402237 [info ] [MainThread]: Using profiles.yml file at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/profiles.yml
[0m21:10:57.402749 [info ] [MainThread]: Using dbt_project.yml file at /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/dbt_project.yml
[0m21:10:57.403957 [info ] [MainThread]: adapter type: postgres
[0m21:10:57.404458 [info ] [MainThread]: adapter version: 1.8.2
[0m21:10:57.506589 [info ] [MainThread]: Configuration:
[0m21:10:57.507167 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m21:10:57.507662 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:10:57.508105 [info ] [MainThread]: Required dependencies:
[0m21:10:57.508703 [debug] [MainThread]: Executing "git --help"
[0m21:10:57.533784 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:10:57.534953 [debug] [MainThread]: STDERR: "b''"
[0m21:10:57.535412 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:10:57.535849 [info ] [MainThread]: Connection:
[0m21:10:57.536413 [info ] [MainThread]:   host: localhost
[0m21:10:57.536927 [info ] [MainThread]:   port: 5435
[0m21:10:57.537397 [info ] [MainThread]:   user: postgres
[0m21:10:57.537785 [info ] [MainThread]:   database: datawarehouse
[0m21:10:57.538146 [info ] [MainThread]:   schema: dbt_dev
[0m21:10:57.538564 [info ] [MainThread]:   connect_timeout: 10
[0m21:10:57.539077 [info ] [MainThread]:   role: None
[0m21:10:57.539476 [info ] [MainThread]:   search_path: None
[0m21:10:57.539830 [info ] [MainThread]:   keepalives_idle: 0
[0m21:10:57.540178 [info ] [MainThread]:   sslmode: None
[0m21:10:57.540614 [info ] [MainThread]:   sslcert: None
[0m21:10:57.540974 [info ] [MainThread]:   sslkey: None
[0m21:10:57.541381 [info ] [MainThread]:   sslrootcert: None
[0m21:10:57.541735 [info ] [MainThread]:   application_name: dbt
[0m21:10:57.542084 [info ] [MainThread]:   retries: 1
[0m21:10:57.542882 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:10:57.554650 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m21:10:57.617314 [debug] [MainThread]: Using postgres connection "debug"
[0m21:10:57.617954 [debug] [MainThread]: On debug: select 1 as id
[0m21:10:57.618470 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:10:57.672065 [debug] [MainThread]: SQL status: SELECT 1 in 0.054 seconds
[0m21:10:57.673252 [debug] [MainThread]: On debug: Close
[0m21:10:57.673695 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m21:10:57.674112 [info ] [MainThread]: [32mAll checks passed![0m
[0m21:10:57.675800 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.42578793, "process_user_time": 1.508228, "process_kernel_time": 0.218951, "process_mem_max_rss": "96657408", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:10:57.676607 [debug] [MainThread]: Command `dbt debug` succeeded at 21:10:57.676482 after 0.43 seconds
[0m21:10:57.677032 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m21:10:57.677477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10455b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065d38b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106060f40>]}
[0m21:10:57.677972 [debug] [MainThread]: Flushing usage events
[0m21:23:13.567574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d31b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee44130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee44430>]}


============================== 21:23:13.576188 | 516914dc-422f-445d-9438-2b87dfd07a7c ==============================
[0m21:23:13.576188 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:23:13.577016 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s payment', 'send_anonymous_usage_stats': 'True'}
[0m21:23:13.789521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '516914dc-422f-445d-9438-2b87dfd07a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5d4e80>]}
[0m21:23:13.849310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '516914dc-422f-445d-9438-2b87dfd07a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ecbf280>]}
[0m21:23:13.851259 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:23:13.870840 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:23:13.871900 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m21:23:13.872479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '516914dc-422f-445d-9438-2b87dfd07a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f305130>]}
[0m21:23:15.412536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '516914dc-422f-445d-9438-2b87dfd07a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb6a130>]}
[0m21:23:15.564472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '516914dc-422f-445d-9438-2b87dfd07a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc6bee0>]}
[0m21:23:15.565076 [info ] [MainThread]: Found 3 models, 4 data tests, 9 sources, 417 macros
[0m21:23:15.565505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '516914dc-422f-445d-9438-2b87dfd07a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb6daf0>]}
[0m21:23:15.566816 [info ] [MainThread]: 
[0m21:23:15.567430 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:23:15.568346 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m21:23:15.638832 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:23:15.639331 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:23:15.639732 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:23:15.672625 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.033 seconds
[0m21:23:15.674066 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:23:15.674916 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now create_datawarehouse_dbt_dev_raw)
[0m21:23:15.675591 [debug] [ThreadPool]: Creating schema "database: "datawarehouse"
schema: "dbt_dev_raw"
"
[0m21:23:15.681740 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_raw"
[0m21:23:15.682172 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_raw: BEGIN
[0m21:23:15.682515 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:23:15.688291 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:23:15.688741 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_raw"
[0m21:23:15.689102 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "create_datawarehouse_dbt_dev_raw"} */
create schema if not exists "dbt_dev_raw"
[0m21:23:15.690111 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m21:23:15.691188 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_raw: COMMIT
[0m21:23:15.691570 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_raw"
[0m21:23:15.691984 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_raw: COMMIT
[0m21:23:15.693127 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m21:23:15.693594 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_raw: Close
[0m21:23:15.699007 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev_raw)
[0m21:23:15.705850 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:23:15.706292 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m21:23:15.706630 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:23:15.713176 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:23:15.713647 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:23:15.714032 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:23:15.718029 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:23:15.719347 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m21:23:15.720130 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m21:23:15.720871 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev)
[0m21:23:15.723415 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:23:15.723873 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m21:23:15.724204 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:23:15.729430 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:23:15.729892 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:23:15.730277 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:23:15.733252 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:23:15.734538 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m21:23:15.735196 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m21:23:15.740953 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:15.741394 [debug] [MainThread]: On master: BEGIN
[0m21:23:15.741738 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:23:15.746844 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:23:15.747301 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:15.747749 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:23:15.777814 [debug] [MainThread]: SQL status: SELECT 37 in 0.030 seconds
[0m21:23:15.780218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '516914dc-422f-445d-9438-2b87dfd07a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2c55e0>]}
[0m21:23:15.780848 [debug] [MainThread]: On master: ROLLBACK
[0m21:23:15.781831 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:15.782201 [debug] [MainThread]: On master: BEGIN
[0m21:23:15.783542 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:23:15.783978 [debug] [MainThread]: On master: COMMIT
[0m21:23:15.784326 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:15.784741 [debug] [MainThread]: On master: COMMIT
[0m21:23:15.785680 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:23:15.786122 [debug] [MainThread]: On master: Close
[0m21:23:15.786757 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:23:15.787258 [info ] [MainThread]: 
[0m21:23:15.797152 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m21:23:15.797812 [info ] [Thread-1  ]: 1 of 1 START sql table model dbt_dev_raw.payment ............................... [RUN]
[0m21:23:15.798363 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now model.datawarehouse.payment)
[0m21:23:15.798787 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m21:23:15.808748 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m21:23:15.809941 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m21:23:15.856876 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m21:23:15.859749 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:23:15.860240 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m21:23:15.860659 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:23:15.866974 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:23:15.867501 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:23:15.867952 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT "datawarehouse"."public"."payment"
  );
  
[0m21:23:15.869547 [debug] [Thread-1  ]: Postgres adapter: Postgres error: missing FROM-clause entry for table "public"
LINE 14: SELECT "datawarehouse"."public"."payment"
                ^

[0m21:23:15.870062 [debug] [Thread-1  ]: On model.datawarehouse.payment: ROLLBACK
[0m21:23:15.871120 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m21:23:15.911920 [debug] [Thread-1  ]: Database Error in model payment (models/raw/payment.sql)
  missing FROM-clause entry for table "public"
  LINE 14: SELECT "datawarehouse"."public"."payment"
                  ^
  compiled Code at target/run/datawarehouse/models/raw/payment.sql
[0m21:23:15.913740 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '516914dc-422f-445d-9438-2b87dfd07a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11016d670>]}
[0m21:23:15.914532 [error] [Thread-1  ]: 1 of 1 ERROR creating sql table model dbt_dev_raw.payment ...................... [[31mERROR[0m in 0.11s]
[0m21:23:15.915266 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m21:23:15.916530 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:15.916921 [debug] [MainThread]: On master: BEGIN
[0m21:23:15.917267 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:23:15.923400 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:23:15.923927 [debug] [MainThread]: On master: COMMIT
[0m21:23:15.924342 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:15.925058 [debug] [MainThread]: On master: COMMIT
[0m21:23:15.926644 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:23:15.927159 [debug] [MainThread]: On master: Close
[0m21:23:15.927685 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:23:15.928055 [debug] [MainThread]: Connection 'model.datawarehouse.payment' was properly closed.
[0m21:23:15.928439 [info ] [MainThread]: 
[0m21:23:15.928840 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.36 seconds (0.36s).
[0m21:23:15.929633 [debug] [MainThread]: Command end result
[0m21:23:15.965772 [info ] [MainThread]: 
[0m21:23:15.966451 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:23:15.966972 [info ] [MainThread]: 
[0m21:23:15.967576 [error] [MainThread]:   Database Error in model payment (models/raw/payment.sql)
  missing FROM-clause entry for table "public"
  LINE 14: SELECT "datawarehouse"."public"."payment"
                  ^
  compiled Code at target/run/datawarehouse/models/raw/payment.sql
[0m21:23:15.968196 [info ] [MainThread]: 
[0m21:23:15.968704 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m21:23:15.970319 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.488426, "process_user_time": 3.429722, "process_kernel_time": 0.285533, "process_mem_max_rss": "112644096", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:23:15.971012 [debug] [MainThread]: Command `dbt run` failed at 21:23:15.970888 after 2.49 seconds
[0m21:23:15.971757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d31b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8523d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11007ef70>]}
[0m21:23:15.972356 [debug] [MainThread]: Flushing usage events
[0m21:24:51.052036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10261b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104144130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104144430>]}


============================== 21:24:51.061562 | 9130803b-8caf-4895-a209-132c72d13e26 ==============================
[0m21:24:51.061562 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:24:51.062416 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s payment', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:24:51.283493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9130803b-8caf-4895-a209-132c72d13e26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1028d4e80>]}
[0m21:24:51.348819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9130803b-8caf-4895-a209-132c72d13e26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fbf280>]}
[0m21:24:51.350609 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:24:51.370496 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:24:51.627647 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:24:51.628592 [debug] [MainThread]: Partial parsing: updated file: datawarehouse://models/raw/payment.sql
[0m21:24:51.953992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9130803b-8caf-4895-a209-132c72d13e26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e49130>]}
[0m21:24:52.108616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9130803b-8caf-4895-a209-132c72d13e26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10446be20>]}
[0m21:24:52.109342 [info ] [MainThread]: Found 3 models, 4 data tests, 9 sources, 417 macros
[0m21:24:52.109791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9130803b-8caf-4895-a209-132c72d13e26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1029f86d0>]}
[0m21:24:52.111476 [info ] [MainThread]: 
[0m21:24:52.112175 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:24:52.113192 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m21:24:52.192578 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:24:52.193070 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:24:52.193534 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:24:52.233016 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.039 seconds
[0m21:24:52.234766 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:24:52.240344 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now list_datawarehouse_dbt_dev_raw)
[0m21:24:52.247954 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:24:52.248495 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m21:24:52.248888 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:24:52.256030 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:24:52.256501 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:24:52.256983 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:24:52.260194 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:24:52.261714 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m21:24:52.262727 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m21:24:52.263521 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev)
[0m21:24:52.266256 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:24:52.266787 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m21:24:52.267226 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:24:52.273196 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:24:52.273644 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:24:52.274093 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:24:52.277312 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:24:52.278823 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m21:24:52.279831 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m21:24:52.284792 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:52.285308 [debug] [MainThread]: On master: BEGIN
[0m21:24:52.285764 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:24:52.291034 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:24:52.291492 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:52.291937 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:24:52.323041 [debug] [MainThread]: SQL status: SELECT 37 in 0.031 seconds
[0m21:24:52.325295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9130803b-8caf-4895-a209-132c72d13e26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040f4130>]}
[0m21:24:52.325836 [debug] [MainThread]: On master: ROLLBACK
[0m21:24:52.326928 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:52.327773 [debug] [MainThread]: On master: BEGIN
[0m21:24:52.329905 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:24:52.330472 [debug] [MainThread]: On master: COMMIT
[0m21:24:52.331297 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:52.332083 [debug] [MainThread]: On master: COMMIT
[0m21:24:52.333541 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:24:52.334325 [debug] [MainThread]: On master: Close
[0m21:24:52.335510 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:24:52.336449 [info ] [MainThread]: 
[0m21:24:52.341991 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m21:24:52.343366 [info ] [Thread-1  ]: 1 of 1 START sql table model dbt_dev_raw.payment ............................... [RUN]
[0m21:24:52.344522 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now model.datawarehouse.payment)
[0m21:24:52.345710 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m21:24:52.362514 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m21:24:52.364508 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m21:24:52.422906 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m21:24:52.424913 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:24:52.426008 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m21:24:52.426592 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:24:52.433874 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:24:52.434378 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:24:52.434797 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m21:24:52.455281 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.020 seconds
[0m21:24:52.464491 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:24:52.465143 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:24:52.466744 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:24:52.503744 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:24:52.504887 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:24:52.505498 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:24:52.508293 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:24:52.515576 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:24:52.521193 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:24:52.521705 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:24:52.522783 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:24:52.525399 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m21:24:52.527280 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9130803b-8caf-4895-a209-132c72d13e26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052b4eb0>]}
[0m21:24:52.528218 [info ] [Thread-1  ]: 1 of 1 OK created sql table model dbt_dev_raw.payment .......................... [[32mSELECT 14596[0m in 0.18s]
[0m21:24:52.529017 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m21:24:52.530551 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:52.530965 [debug] [MainThread]: On master: BEGIN
[0m21:24:52.531315 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:24:52.538759 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:24:52.539302 [debug] [MainThread]: On master: COMMIT
[0m21:24:52.539779 [debug] [MainThread]: Using postgres connection "master"
[0m21:24:52.540389 [debug] [MainThread]: On master: COMMIT
[0m21:24:52.541770 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:24:52.542279 [debug] [MainThread]: On master: Close
[0m21:24:52.542840 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:24:52.543276 [debug] [MainThread]: Connection 'model.datawarehouse.payment' was properly closed.
[0m21:24:52.543973 [info ] [MainThread]: 
[0m21:24:52.544651 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.43 seconds (0.43s).
[0m21:24:52.545862 [debug] [MainThread]: Command end result
[0m21:24:52.637098 [info ] [MainThread]: 
[0m21:24:52.637687 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:24:52.638071 [info ] [MainThread]: 
[0m21:24:52.638541 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:24:52.640057 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.6762211, "process_user_time": 2.674269, "process_kernel_time": 0.393385, "process_mem_max_rss": "108093440", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:24:52.640717 [debug] [MainThread]: Command `dbt run` succeeded at 21:24:52.640598 after 1.68 seconds
[0m21:24:52.641172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10261b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d44970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10359d5e0>]}
[0m21:24:52.641600 [debug] [MainThread]: Flushing usage events
[0m21:30:04.074763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11199a2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134a0b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134a0880>]}


============================== 21:30:04.080965 | 55a52b02-b92e-4d04-bcfc-c4ef9d33063d ==============================
[0m21:30:04.080965 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:30:04.081620 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:30:04.260505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11380d5b0>]}
[0m21:30:04.325609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11382d100>]}
[0m21:30:04.326626 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:30:04.346599 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:30:04.530315 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 8 files added, 0 files changed.
[0m21:30:04.531021 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/raw/actor.sql
[0m21:30:04.531430 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/raw/film_actor.sql
[0m21:30:04.531813 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/raw/rental.sql
[0m21:30:04.532198 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/raw/film.sql
[0m21:30:04.532624 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/raw/address.sql
[0m21:30:04.533003 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/raw/customer.sql
[0m21:30:04.533379 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/raw/staff.sql
[0m21:30:04.533758 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/raw/inventory.sql
[0m21:30:04.854587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114223e20>]}
[0m21:30:04.992262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137d5be0>]}
[0m21:30:04.992886 [info ] [MainThread]: Found 11 models, 4 data tests, 9 sources, 417 macros
[0m21:30:04.993303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11421dcd0>]}
[0m21:30:04.995537 [info ] [MainThread]: 
[0m21:30:04.996154 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:30:05.002243 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m21:30:05.074599 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:30:05.075102 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:30:05.075516 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:30:05.098039 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.022 seconds
[0m21:30:05.099557 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:30:05.102600 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:30:05.103118 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:30:05.103527 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:30:05.109447 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m21:30:05.110856 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:30:05.111834 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now create_datawarehouse_dbt_dev)
[0m21:30:05.113362 [debug] [ThreadPool]: Creating schema "database: "datawarehouse"
schema: "dbt_dev"
"
[0m21:30:05.122678 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev"
[0m21:30:05.123216 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev: BEGIN
[0m21:30:05.123571 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:30:05.130607 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:30:05.131285 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev"
[0m21:30:05.131709 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "create_datawarehouse_dbt_dev"} */
create schema if not exists "dbt_dev"
[0m21:30:05.132875 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m21:30:05.134038 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev: COMMIT
[0m21:30:05.134735 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev"
[0m21:30:05.135177 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev: COMMIT
[0m21:30:05.136752 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.137415 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev: Close
[0m21:30:05.140147 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_datawarehouse_dbt_dev, now list_datawarehouse_dbt_dev_raw)
[0m21:30:05.149587 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:30:05.150422 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m21:30:05.151146 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:30:05.158320 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:30:05.158873 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:30:05.159406 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:30:05.163220 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m21:30:05.165457 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m21:30:05.166819 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m21:30:05.167934 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev)
[0m21:30:05.171553 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:30:05.172071 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m21:30:05.172745 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:30:05.178676 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:30:05.179130 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:30:05.179520 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:30:05.182728 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:30:05.184192 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m21:30:05.185195 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m21:30:05.191297 [debug] [MainThread]: Using postgres connection "master"
[0m21:30:05.191823 [debug] [MainThread]: On master: BEGIN
[0m21:30:05.192356 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:30:05.198429 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:30:05.198961 [debug] [MainThread]: Using postgres connection "master"
[0m21:30:05.199602 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:30:05.237834 [debug] [MainThread]: SQL status: SELECT 37 in 0.037 seconds
[0m21:30:05.240286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1145c7eb0>]}
[0m21:30:05.240834 [debug] [MainThread]: On master: ROLLBACK
[0m21:30:05.241643 [debug] [MainThread]: Using postgres connection "master"
[0m21:30:05.242021 [debug] [MainThread]: On master: BEGIN
[0m21:30:05.243074 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:30:05.243467 [debug] [MainThread]: On master: COMMIT
[0m21:30:05.243831 [debug] [MainThread]: Using postgres connection "master"
[0m21:30:05.244178 [debug] [MainThread]: On master: COMMIT
[0m21:30:05.244998 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:30:05.245447 [debug] [MainThread]: On master: Close
[0m21:30:05.246133 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:30:05.246776 [info ] [MainThread]: 
[0m21:30:05.249102 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m21:30:05.249740 [info ] [Thread-1  ]: 1 of 11 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:30:05.250342 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now model.datawarehouse.actor)
[0m21:30:05.250771 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m21:30:05.261521 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m21:30:05.262454 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m21:30:05.310848 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m21:30:05.311819 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:30:05.312250 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m21:30:05.312647 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.317801 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:30:05.318315 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:30:05.318736 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m21:30:05.320830 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m21:30:05.373662 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:30:05.374406 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:30:05.375800 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.399195 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:30:05.399689 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:30:05.400226 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:30:05.402079 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.409496 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:30:05.414409 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:30:05.414907 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:30:05.415988 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.418587 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m21:30:05.420311 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c3ae80>]}
[0m21:30:05.421062 [info ] [Thread-1  ]: 1 of 11 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.17s]
[0m21:30:05.422100 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m21:30:05.422630 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m21:30:05.423301 [info ] [Thread-1  ]: 2 of 11 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:30:05.423999 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m21:30:05.424434 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m21:30:05.428059 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m21:30:05.429028 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m21:30:05.433948 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m21:30:05.434890 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:30:05.435340 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m21:30:05.435737 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.441577 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:30:05.442137 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:30:05.442634 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m21:30:05.445320 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:30:05.449055 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:30:05.449518 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:30:05.450617 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.452534 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:30:05.452964 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:30:05.453360 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:30:05.455074 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.458073 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:30:05.458974 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:30:05.459400 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:30:05.460453 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.462056 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m21:30:05.462713 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147e2910>]}
[0m21:30:05.463512 [info ] [Thread-1  ]: 2 of 11 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.04s]
[0m21:30:05.464322 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m21:30:05.464902 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m21:30:05.465541 [info ] [Thread-1  ]: 3 of 11 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:30:05.466120 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m21:30:05.466775 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m21:30:05.472600 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m21:30:05.473624 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m21:30:05.478889 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m21:30:05.480039 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:30:05.480523 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m21:30:05.480920 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.487370 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:30:05.488128 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:30:05.488652 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m21:30:05.492096 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.003 seconds
[0m21:30:05.497295 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:30:05.497867 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:30:05.499061 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.500999 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:30:05.501457 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:30:05.501858 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:30:05.503542 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.506854 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:30:05.507779 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:30:05.508203 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:30:05.509191 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.510720 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m21:30:05.511301 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c3ae80>]}
[0m21:30:05.511989 [info ] [Thread-1  ]: 3 of 11 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m21:30:05.512727 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m21:30:05.513694 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m21:30:05.514267 [info ] [Thread-1  ]: 4 of 11 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:30:05.514879 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m21:30:05.515295 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m21:30:05.518797 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m21:30:05.519752 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m21:30:05.525385 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m21:30:05.526232 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:30:05.526648 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m21:30:05.527041 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.532530 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:30:05.533037 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:30:05.533453 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m21:30:05.538828 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.005 seconds
[0m21:30:05.542529 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:30:05.542996 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:30:05.544091 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.546061 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:30:05.546525 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:30:05.546932 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:30:05.548686 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.552695 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:30:05.553567 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:30:05.554483 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:30:05.555583 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.557167 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m21:30:05.557814 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c3ae80>]}
[0m21:30:05.558644 [info ] [Thread-1  ]: 4 of 11 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.04s]
[0m21:30:05.559647 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m21:30:05.560313 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m21:30:05.561002 [info ] [Thread-1  ]: 5 of 11 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:30:05.561548 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m21:30:05.561965 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m21:30:05.565705 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m21:30:05.566734 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m21:30:05.572005 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m21:30:05.572928 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:30:05.573366 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m21:30:05.573781 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.579077 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:30:05.579607 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:30:05.580025 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m21:30:05.584344 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:30:05.588914 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:30:05.589438 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:30:05.590845 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.592697 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:30:05.593111 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:30:05.593499 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:30:05.595377 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.598349 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:30:05.599236 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:30:05.599655 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:30:05.600654 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.602051 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m21:30:05.602670 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142bf2b0>]}
[0m21:30:05.603473 [info ] [Thread-1  ]: 5 of 11 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.04s]
[0m21:30:05.604181 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m21:30:05.604917 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m21:30:05.605596 [info ] [Thread-1  ]: 6 of 11 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:30:05.606449 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m21:30:05.607547 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m21:30:05.611720 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m21:30:05.612536 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m21:30:05.616911 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m21:30:05.617615 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:30:05.618025 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m21:30:05.618423 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.626014 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:30:05.626512 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:30:05.626953 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m21:30:05.631090 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:30:05.635859 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:30:05.636312 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:30:05.637837 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.640221 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:30:05.640696 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:30:05.641100 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:30:05.643119 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.646501 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:30:05.647543 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:30:05.647950 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:30:05.649095 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.650570 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m21:30:05.651299 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c3ae80>]}
[0m21:30:05.652041 [info ] [Thread-1  ]: 6 of 11 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.04s]
[0m21:30:05.652973 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m21:30:05.653655 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m21:30:05.654533 [info ] [Thread-1  ]: 7 of 11 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:30:05.655385 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m21:30:05.655964 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m21:30:05.659699 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m21:30:05.660923 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m21:30:05.665773 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m21:30:05.666719 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:30:05.667170 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m21:30:05.667572 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.673962 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:30:05.674469 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:30:05.674927 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:30:05.676904 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.001 seconds
[0m21:30:05.680849 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:30:05.681354 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:30:05.682458 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.684468 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:30:05.684927 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:30:05.685339 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:30:05.686820 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.691651 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:30:05.693315 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:30:05.693938 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:30:05.695294 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.697378 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m21:30:05.698143 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1146339a0>]}
[0m21:30:05.699216 [info ] [Thread-1  ]: 7 of 11 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.04s]
[0m21:30:05.700098 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m21:30:05.700946 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m21:30:05.701920 [info ] [Thread-1  ]: 8 of 11 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:30:05.702864 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m21:30:05.703374 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m21:30:05.708045 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m21:30:05.708934 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m21:30:05.716858 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m21:30:05.718099 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:30:05.718684 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m21:30:05.719185 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.727965 [debug] [Thread-1  ]: SQL status: BEGIN in 0.009 seconds
[0m21:30:05.728677 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:30:05.729155 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m21:30:05.739474 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.010 seconds
[0m21:30:05.745649 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:30:05.746499 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:30:05.748294 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.752980 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:30:05.753609 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:30:05.755225 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.761378 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:30:05.762173 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:30:05.762941 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:30:05.767600 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m21:30:05.771726 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:30:05.773345 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:30:05.773920 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:30:05.777061 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:30:05.779159 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m21:30:05.779796 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147f5e50>]}
[0m21:30:05.780493 [info ] [Thread-1  ]: 8 of 11 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.08s]
[0m21:30:05.781287 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m21:30:05.781842 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m21:30:05.782516 [info ] [Thread-1  ]: 9 of 11 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:30:05.783246 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m21:30:05.783858 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m21:30:05.788091 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m21:30:05.789909 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m21:30:05.796390 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m21:30:05.797485 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:30:05.798233 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m21:30:05.799052 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.808235 [debug] [Thread-1  ]: SQL status: BEGIN in 0.009 seconds
[0m21:30:05.808988 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:30:05.809584 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m21:30:05.823765 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.013 seconds
[0m21:30:05.828279 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:30:05.828813 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:30:05.830300 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.833016 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:30:05.833554 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:30:05.834017 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:30:05.837291 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:30:05.844593 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:30:05.846240 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:30:05.847057 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:30:05.848823 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.851414 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m21:30:05.852422 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147870d0>]}
[0m21:30:05.853789 [info ] [Thread-1  ]: 9 of 11 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m21:30:05.855277 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m21:30:05.856161 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m21:30:05.857071 [info ] [Thread-1  ]: 10 of 11 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:30:05.857834 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m21:30:05.858378 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m21:30:05.864533 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m21:30:05.865985 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m21:30:05.872225 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m21:30:05.873127 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:30:05.873543 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m21:30:05.874109 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.882138 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:30:05.882706 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:30:05.883163 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m21:30:05.888067 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m21:30:05.893436 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:30:05.894038 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:30:05.895583 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.898697 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:30:05.899273 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:30:05.899693 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:30:05.901417 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.906183 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:30:05.907410 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:30:05.908146 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:30:05.909237 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:30:05.910744 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m21:30:05.911781 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114061eb0>]}
[0m21:30:05.912580 [info ] [Thread-1  ]: 10 of 11 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m21:30:05.913710 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m21:30:05.914276 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m21:30:05.914832 [info ] [Thread-1  ]: 11 of 11 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:30:05.915466 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.my_second_dbt_model)
[0m21:30:05.915913 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m21:30:05.919852 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m21:30:05.920816 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m21:30:05.947661 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m21:30:05.948604 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:30:05.949093 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m21:30:05.949687 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:30:05.958503 [debug] [Thread-1  ]: SQL status: BEGIN in 0.009 seconds
[0m21:30:05.959119 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:30:05.959751 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:30:05.961969 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m21:30:05.966250 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:30:05.966880 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:30:05.968775 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:30:05.970881 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:30:05.971445 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:30:05.971859 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:30:05.973646 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:30:05.976779 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:30:05.979906 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:30:05.980389 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:30:05.981379 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m21:30:05.982835 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m21:30:05.983407 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55a52b02-b92e-4d04-bcfc-c4ef9d33063d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c3ae80>]}
[0m21:30:05.984079 [info ] [Thread-1  ]: 11 of 11 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m21:30:05.984764 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m21:30:05.986055 [debug] [MainThread]: Using postgres connection "master"
[0m21:30:05.986442 [debug] [MainThread]: On master: BEGIN
[0m21:30:05.986819 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:30:05.992980 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:30:05.993479 [debug] [MainThread]: On master: COMMIT
[0m21:30:05.993843 [debug] [MainThread]: Using postgres connection "master"
[0m21:30:05.994188 [debug] [MainThread]: On master: COMMIT
[0m21:30:05.994954 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:30:05.995360 [debug] [MainThread]: On master: Close
[0m21:30:05.995900 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:30:05.996269 [debug] [MainThread]: Connection 'model.datawarehouse.my_second_dbt_model' was properly closed.
[0m21:30:05.996859 [info ] [MainThread]: 
[0m21:30:05.997468 [info ] [MainThread]: Finished running 10 table models, 1 view model in 0 hours 0 minutes and 1.00 seconds (1.00s).
[0m21:30:06.000071 [debug] [MainThread]: Command end result
[0m21:30:06.040821 [info ] [MainThread]: 
[0m21:30:06.041596 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:30:06.042025 [info ] [MainThread]: 
[0m21:30:06.042438 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=0 SKIP=0 TOTAL=11
[0m21:30:06.043952 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.0456302, "process_user_time": 2.935195, "process_kernel_time": 0.306443, "process_mem_max_rss": "108851200", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:30:06.044608 [debug] [MainThread]: Command `dbt run` succeeded at 21:30:06.044495 after 2.05 seconds
[0m21:30:06.045052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11199a2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140964f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e3f70>]}
[0m21:30:06.045486 [debug] [MainThread]: Flushing usage events
[0m21:38:53.886276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a1b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106520ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106520be0>]}


============================== 21:38:53.895008 | 18296e48-8d33-4e7f-a473-afff8e87b551 ==============================
[0m21:38:53.895008 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:38:53.895743 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:38:54.126976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064f80a0>]}
[0m21:38:54.193236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063ae910>]}
[0m21:38:54.195489 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:38:54.216680 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:38:54.440872 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 9 files added, 0 files changed.
[0m21:38:54.441547 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/dim_rental.sql
[0m21:38:54.441973 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/dim_address.sql
[0m21:38:54.442369 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/dim_actor.sql
[0m21:38:54.442817 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/dim_film.sql
[0m21:38:54.443469 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/dim_staff.sql
[0m21:38:54.444049 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/fact_payment.sql
[0m21:38:54.444596 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/dim_customer.sql
[0m21:38:54.444991 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/dim_inventory.sql
[0m21:38:54.445374 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/intermediete/dim_film_actor.sql
[0m21:38:54.784739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10727f130>]}
[0m21:38:54.942914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070d2f70>]}
[0m21:38:54.943828 [info ] [MainThread]: Found 20 models, 4 data tests, 9 sources, 417 macros
[0m21:38:54.944374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072d00a0>]}
[0m21:38:54.947685 [info ] [MainThread]: 
[0m21:38:54.948403 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:38:54.955494 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m21:38:55.025065 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:38:55.025586 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:38:55.026085 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:38:55.069185 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.043 seconds
[0m21:38:55.070779 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:38:55.073640 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:38:55.074152 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:38:55.074644 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:38:55.079828 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m21:38:55.081219 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:38:55.084055 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:38:55.084572 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:38:55.085130 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:38:55.090221 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m21:38:55.091603 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:38:55.092740 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now create_datawarehouse_dbt_dev_intermediete)
[0m21:38:55.093395 [debug] [ThreadPool]: Creating schema "database: "datawarehouse"
schema: "dbt_dev_intermediete"
"
[0m21:38:55.099454 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_intermediete"
[0m21:38:55.099945 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_intermediete: BEGIN
[0m21:38:55.100354 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:38:55.106102 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:38:55.106566 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_intermediete"
[0m21:38:55.106936 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "create_datawarehouse_dbt_dev_intermediete"} */
create schema if not exists "dbt_dev_intermediete"
[0m21:38:55.107821 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m21:38:55.108819 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_intermediete: COMMIT
[0m21:38:55.109185 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_intermediete"
[0m21:38:55.109536 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_intermediete: COMMIT
[0m21:38:55.110657 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m21:38:55.111072 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_intermediete: Close
[0m21:38:55.113771 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_datawarehouse_dbt_dev_intermediete, now list_datawarehouse_dbt_dev_intermediete)
[0m21:38:55.120776 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:38:55.121376 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m21:38:55.121718 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:38:55.126854 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:38:55.127382 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:38:55.127787 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m21:38:55.130857 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:38:55.132201 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m21:38:55.132938 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m21:38:55.133588 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now list_datawarehouse_dbt_dev_raw)
[0m21:38:55.136197 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:38:55.136628 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m21:38:55.136970 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:38:55.141581 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:38:55.142038 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:38:55.142423 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:38:55.145428 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:38:55.146982 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m21:38:55.147713 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m21:38:55.148324 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev)
[0m21:38:55.152607 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:38:55.153058 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m21:38:55.153421 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:38:55.158250 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:38:55.158718 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:38:55.159100 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:38:55.162014 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.002 seconds
[0m21:38:55.163408 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m21:38:55.164084 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m21:38:55.172000 [debug] [MainThread]: Using postgres connection "master"
[0m21:38:55.172450 [debug] [MainThread]: On master: BEGIN
[0m21:38:55.172799 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:38:55.178350 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m21:38:55.178799 [debug] [MainThread]: Using postgres connection "master"
[0m21:38:55.179237 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:38:55.228173 [debug] [MainThread]: SQL status: SELECT 38 in 0.048 seconds
[0m21:38:55.230755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dbaa00>]}
[0m21:38:55.231356 [debug] [MainThread]: On master: ROLLBACK
[0m21:38:55.232277 [debug] [MainThread]: Using postgres connection "master"
[0m21:38:55.232673 [debug] [MainThread]: On master: BEGIN
[0m21:38:55.233899 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:38:55.234563 [debug] [MainThread]: On master: COMMIT
[0m21:38:55.234963 [debug] [MainThread]: Using postgres connection "master"
[0m21:38:55.235316 [debug] [MainThread]: On master: COMMIT
[0m21:38:55.236163 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:38:55.236578 [debug] [MainThread]: On master: Close
[0m21:38:55.237129 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:38:55.237551 [info ] [MainThread]: 
[0m21:38:55.289000 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m21:38:55.289785 [info ] [Thread-1  ]: 1 of 20 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:38:55.290454 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now model.datawarehouse.actor)
[0m21:38:55.290987 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m21:38:55.301472 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m21:38:55.302901 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m21:38:55.354180 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m21:38:55.355176 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:38:55.355595 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m21:38:55.355984 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.361424 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:38:55.361957 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:38:55.362390 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m21:38:55.364379 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m21:38:55.371696 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:38:55.372202 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m21:38:55.373227 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.376928 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:38:55.377404 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:38:55.378644 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.404261 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:38:55.404954 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:38:55.405503 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:38:55.407183 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:55.416155 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:38:55.421601 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:38:55.422096 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:38:55.424267 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:38:55.426805 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m21:38:55.428405 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cbbee0>]}
[0m21:38:55.429164 [info ] [Thread-1  ]: 1 of 20 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.14s]
[0m21:38:55.429879 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m21:38:55.430487 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m21:38:55.431037 [info ] [Thread-1  ]: 2 of 20 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:38:55.431736 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m21:38:55.432179 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m21:38:55.436351 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m21:38:55.437935 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m21:38:55.443302 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m21:38:55.444256 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:38:55.444706 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m21:38:55.445159 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.450320 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:38:55.450841 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:38:55.451464 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m21:38:55.454265 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:38:55.457913 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:38:55.458354 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m21:38:55.459388 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.462869 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:38:55.463302 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:38:55.464267 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.466242 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:38:55.466651 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:38:55.467038 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:38:55.469113 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:38:55.472851 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:38:55.473830 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:38:55.474244 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:38:55.476882 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:38:55.478561 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m21:38:55.479270 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c8d90>]}
[0m21:38:55.480058 [info ] [Thread-1  ]: 2 of 20 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m21:38:55.480858 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m21:38:55.481464 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m21:38:55.482143 [info ] [Thread-1  ]: 3 of 20 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:38:55.482814 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m21:38:55.483235 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m21:38:55.486958 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m21:38:55.487836 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m21:38:55.495043 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m21:38:55.495952 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:38:55.496374 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m21:38:55.496769 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.502007 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:38:55.502519 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:38:55.502945 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m21:38:55.505544 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m21:38:55.509281 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:38:55.509727 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m21:38:55.510879 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.514336 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:38:55.514779 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:38:55.515881 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.518371 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:38:55.518884 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:38:55.519340 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:38:55.521185 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:55.524434 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:38:55.525309 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:38:55.525727 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:38:55.527703 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:38:55.529198 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m21:38:55.529771 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070e24f0>]}
[0m21:38:55.530436 [info ] [Thread-1  ]: 3 of 20 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m21:38:55.531105 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m21:38:55.531662 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m21:38:55.532359 [info ] [Thread-1  ]: 4 of 20 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:38:55.532986 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m21:38:55.533420 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m21:38:55.537214 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m21:38:55.538117 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m21:38:55.542601 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m21:38:55.543428 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:38:55.543866 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m21:38:55.544267 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.550505 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:38:55.551110 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:38:55.551577 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m21:38:55.556520 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.004 seconds
[0m21:38:55.560318 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:38:55.560803 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m21:38:55.561999 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.566795 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:38:55.567276 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:38:55.568584 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.571528 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:38:55.572078 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:38:55.572518 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:38:55.573865 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:55.576816 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:38:55.577712 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:38:55.578140 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:38:55.580388 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:38:55.581911 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m21:38:55.582511 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10318d790>]}
[0m21:38:55.583209 [info ] [Thread-1  ]: 4 of 20 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m21:38:55.584262 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m21:38:55.584915 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m21:38:55.585872 [info ] [Thread-1  ]: 5 of 20 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:38:55.586594 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m21:38:55.587040 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m21:38:55.590834 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m21:38:55.591733 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m21:38:55.597227 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m21:38:55.598101 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:38:55.598527 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m21:38:55.598920 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.606171 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:38:55.606688 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:38:55.607116 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m21:38:55.611859 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:38:55.615590 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:38:55.616274 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m21:38:55.617413 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.621257 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:38:55.621716 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:38:55.622853 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.624885 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:38:55.625302 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:38:55.625695 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:38:55.627823 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:38:55.630923 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:38:55.631845 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:38:55.632274 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:38:55.634520 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:38:55.636479 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m21:38:55.637181 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077f0310>]}
[0m21:38:55.638379 [info ] [Thread-1  ]: 5 of 20 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m21:38:55.639881 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m21:38:55.640640 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m21:38:55.641534 [info ] [Thread-1  ]: 6 of 20 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:38:55.642514 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m21:38:55.643103 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m21:38:55.650524 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m21:38:55.651809 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m21:38:55.656731 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m21:38:55.657814 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:38:55.658338 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m21:38:55.658740 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.665671 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:38:55.666242 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:38:55.666788 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m21:38:55.671478 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:38:55.675515 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:38:55.676104 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m21:38:55.677320 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.681006 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:38:55.681474 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:38:55.682703 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.684892 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:38:55.685398 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:38:55.685933 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:38:55.687948 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:55.691940 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:38:55.693074 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:38:55.693589 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:38:55.696275 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:38:55.697851 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m21:38:55.698581 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070e1940>]}
[0m21:38:55.699323 [info ] [Thread-1  ]: 6 of 20 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m21:38:55.700030 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m21:38:55.700623 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m21:38:55.701646 [info ] [Thread-1  ]: 7 of 20 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:38:55.702384 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m21:38:55.702842 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m21:38:55.706485 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m21:38:55.707762 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m21:38:55.713500 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m21:38:55.714426 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:38:55.714854 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m21:38:55.715249 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.722569 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:38:55.723080 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:38:55.723605 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:38:55.725857 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.002 seconds
[0m21:38:55.731195 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:38:55.731692 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:38:55.733130 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.736998 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:38:55.737491 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:38:55.738816 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.742501 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:38:55.743307 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:38:55.743838 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:38:55.745655 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:55.751121 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:38:55.752231 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:38:55.752694 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:38:55.755831 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m21:38:55.758017 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m21:38:55.758681 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106baac10>]}
[0m21:38:55.759703 [info ] [Thread-1  ]: 7 of 20 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m21:38:55.760518 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m21:38:55.761074 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m21:38:55.761738 [info ] [Thread-1  ]: 8 of 20 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:38:55.762575 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m21:38:55.763149 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m21:38:55.768154 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m21:38:55.769260 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m21:38:55.773937 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m21:38:55.774875 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:38:55.775579 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m21:38:55.776244 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.782518 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:38:55.783028 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:38:55.783486 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m21:38:55.795152 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.011 seconds
[0m21:38:55.800707 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:38:55.801554 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:38:55.803176 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.807014 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:38:55.807498 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:38:55.808763 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.811310 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:38:55.811812 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:38:55.812227 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:38:55.815265 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:38:55.818928 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:38:55.821482 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:38:55.821960 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:38:55.824728 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:38:55.826534 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m21:38:55.827175 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f8130>]}
[0m21:38:55.827941 [info ] [Thread-1  ]: 8 of 20 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m21:38:55.829082 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m21:38:55.829793 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m21:38:55.830358 [info ] [Thread-1  ]: 9 of 20 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:38:55.831274 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m21:38:55.832029 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m21:38:55.839446 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m21:38:55.840699 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m21:38:55.849798 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m21:38:55.851187 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:38:55.852367 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m21:38:55.853323 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.860422 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:38:55.861175 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:38:55.861860 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m21:38:55.872599 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.010 seconds
[0m21:38:55.876618 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:38:55.877132 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m21:38:55.878210 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.881709 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:38:55.882125 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:38:55.883380 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.885633 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:38:55.886076 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:38:55.886543 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:38:55.889672 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:38:55.894275 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:38:55.895594 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:38:55.896089 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:38:55.899695 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m21:38:55.902208 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m21:38:55.903172 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107883130>]}
[0m21:38:55.904050 [info ] [Thread-1  ]: 9 of 20 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m21:38:55.905385 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m21:38:55.906079 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m21:38:55.906765 [info ] [Thread-1  ]: 10 of 20 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:38:55.907513 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m21:38:55.907952 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m21:38:55.912253 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m21:38:55.913523 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m21:38:55.921022 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m21:38:55.922011 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:38:55.922434 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m21:38:55.922819 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.930082 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:38:55.930651 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:38:55.931053 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m21:38:55.935758 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m21:38:55.940415 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:38:55.942821 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m21:38:55.944685 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.950117 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:38:55.951205 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:38:55.952987 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:55.956573 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:38:55.957097 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:38:55.957645 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:38:55.959595 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:55.963933 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:38:55.965486 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:38:55.966204 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:38:55.969310 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m21:38:55.970971 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m21:38:55.971624 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068b4400>]}
[0m21:38:55.972388 [info ] [Thread-1  ]: 10 of 20 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m21:38:55.973149 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m21:38:55.973819 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m21:38:55.974370 [info ] [Thread-1  ]: 11 of 20 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m21:38:55.975069 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.dim_actor)
[0m21:38:55.976109 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m21:38:55.980411 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m21:38:55.982035 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m21:38:55.988282 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_actor"
[0m21:38:55.989780 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:38:55.990550 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: BEGIN
[0m21:38:55.991283 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:55.999133 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:38:56.000545 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:38:56.001554 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."actor"
  );
  
[0m21:38:56.005123 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.003 seconds
[0m21:38:56.010703 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:38:56.011811 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m21:38:56.013281 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.016461 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:38:56.017154 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:38:56.017892 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:38:56.019988 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:56.023697 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m21:38:56.026159 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:38:56.026903 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m21:38:56.028141 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.029825 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: Close
[0m21:38:56.030879 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070e1940>]}
[0m21:38:56.031631 [info ] [Thread-1  ]: 11 of 20 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.06s]
[0m21:38:56.032381 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m21:38:56.032965 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m21:38:56.033727 [info ] [Thread-1  ]: 12 of 20 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m21:38:56.034796 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m21:38:56.035323 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m21:38:56.039607 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m21:38:56.040903 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m21:38:56.049362 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_address"
[0m21:38:56.051808 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:38:56.052785 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: BEGIN
[0m21:38:56.053799 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.066751 [debug] [Thread-1  ]: SQL status: BEGIN in 0.013 seconds
[0m21:38:56.067645 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:38:56.068646 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."address"
  );
  
[0m21:38:56.071446 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:38:56.075482 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:38:56.075996 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m21:38:56.077195 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.079278 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:38:56.079748 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:38:56.080189 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:38:56.082139 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:56.086117 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m21:38:56.087348 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:38:56.088087 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m21:38:56.089671 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.092247 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: Close
[0m21:38:56.093408 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cd2e50>]}
[0m21:38:56.094669 [info ] [Thread-1  ]: 12 of 20 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m21:38:56.096089 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m21:38:56.096983 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m21:38:56.098027 [info ] [Thread-1  ]: 13 of 20 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m21:38:56.099308 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m21:38:56.101569 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m21:38:56.107822 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m21:38:56.108730 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m21:38:56.115741 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_customer"
[0m21:38:56.117476 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:38:56.119040 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: BEGIN
[0m21:38:56.119834 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.127377 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:38:56.128230 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:38:56.128919 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."customer"
  );
  
[0m21:38:56.132300 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.003 seconds
[0m21:38:56.136867 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:38:56.137434 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m21:38:56.138769 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.144270 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:38:56.145092 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:38:56.145849 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:38:56.147943 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:56.152976 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m21:38:56.154594 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:38:56.155321 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m21:38:56.156654 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.158880 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: Close
[0m21:38:56.160083 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070961f0>]}
[0m21:38:56.161320 [info ] [Thread-1  ]: 13 of 20 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m21:38:56.162619 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m21:38:56.163176 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m21:38:56.163747 [info ] [Thread-1  ]: 14 of 20 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m21:38:56.164531 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m21:38:56.164989 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m21:38:56.170143 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m21:38:56.171112 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m21:38:56.179870 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film"
[0m21:38:56.181200 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:38:56.181964 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: BEGIN
[0m21:38:56.182653 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.190455 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:38:56.191285 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:38:56.192130 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film"
  );
  
[0m21:38:56.200014 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.007 seconds
[0m21:38:56.206454 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:38:56.207041 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m21:38:56.208424 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.211562 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:38:56.212273 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:38:56.212914 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:38:56.215143 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:38:56.220044 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m21:38:56.221302 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:38:56.221893 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m21:38:56.223254 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.224763 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: Close
[0m21:38:56.225422 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078ebbb0>]}
[0m21:38:56.226176 [info ] [Thread-1  ]: 14 of 20 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m21:38:56.227182 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m21:38:56.227884 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m21:38:56.228553 [info ] [Thread-1  ]: 15 of 20 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m21:38:56.229135 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m21:38:56.229674 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m21:38:56.233584 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m21:38:56.235022 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m21:38:56.241895 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film_actor"
[0m21:38:56.243352 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:38:56.244185 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: BEGIN
[0m21:38:56.245170 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.253089 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:38:56.253868 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:38:56.254539 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m21:38:56.259469 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:38:56.265315 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:38:56.265812 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m21:38:56.266962 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.269044 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:38:56.269515 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:38:56.269999 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:38:56.271961 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:56.275210 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m21:38:56.276848 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:38:56.277487 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m21:38:56.278776 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.280460 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: Close
[0m21:38:56.281271 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10318d790>]}
[0m21:38:56.282239 [info ] [Thread-1  ]: 15 of 20 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m21:38:56.283154 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m21:38:56.284009 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m21:38:56.284771 [info ] [Thread-1  ]: 16 of 20 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m21:38:56.285365 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m21:38:56.285819 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m21:38:56.290734 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m21:38:56.292239 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m21:38:56.298749 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_inventory"
[0m21:38:56.299610 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:38:56.300068 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: BEGIN
[0m21:38:56.300469 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.306966 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:38:56.307651 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:38:56.308156 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."inventory"
  );
  
[0m21:38:56.312701 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:38:56.316989 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:38:56.317786 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m21:38:56.319186 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.321353 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:38:56.321847 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:38:56.322259 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:38:56.324099 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:56.327116 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m21:38:56.328118 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:38:56.328625 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m21:38:56.329678 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.331154 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: Close
[0m21:38:56.331741 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10318d790>]}
[0m21:38:56.332427 [info ] [Thread-1  ]: 16 of 20 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m21:38:56.333216 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m21:38:56.333836 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m21:38:56.334402 [info ] [Thread-1  ]: 17 of 20 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:38:56.335119 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m21:38:56.335606 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m21:38:56.339103 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m21:38:56.340682 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m21:38:56.364649 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m21:38:56.365765 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:38:56.366274 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m21:38:56.366676 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.372054 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:38:56.372586 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:38:56.373086 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:38:56.375022 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.001 seconds
[0m21:38:56.378709 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:38:56.379183 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:38:56.380202 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.381848 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:38:56.382414 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:38:56.382905 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:38:56.384636 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:56.387676 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:38:56.390777 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:38:56.391328 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:38:56.392680 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m21:38:56.394597 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m21:38:56.395580 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10784fdc0>]}
[0m21:38:56.396852 [info ] [Thread-1  ]: 17 of 20 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m21:38:56.398161 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m21:38:56.398714 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m21:38:56.399255 [info ] [Thread-1  ]: 18 of 20 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m21:38:56.400058 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now model.datawarehouse.fact_payment)
[0m21:38:56.400565 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m21:38:56.405279 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m21:38:56.406302 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m21:38:56.412429 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.fact_payment"
[0m21:38:56.413315 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:38:56.413753 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: BEGIN
[0m21:38:56.414147 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.419767 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:38:56.420323 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:38:56.420771 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."payment"
  );
  
[0m21:38:56.430056 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.009 seconds
[0m21:38:56.433797 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:38:56.434278 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m21:38:56.435494 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.437340 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:38:56.437793 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:38:56.438243 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:38:56.441251 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:38:56.446267 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m21:38:56.447215 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:38:56.447624 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m21:38:56.448913 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.450580 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: Close
[0m21:38:56.451552 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105267df0>]}
[0m21:38:56.452807 [info ] [Thread-1  ]: 18 of 20 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.05s]
[0m21:38:56.453731 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m21:38:56.454363 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m21:38:56.455358 [info ] [Thread-1  ]: 19 of 20 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m21:38:56.456045 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m21:38:56.456505 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m21:38:56.460831 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m21:38:56.462042 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m21:38:56.466659 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_rental"
[0m21:38:56.467614 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:38:56.468093 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: BEGIN
[0m21:38:56.468493 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.473931 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:38:56.474441 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:38:56.474861 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."rental"
  );
  
[0m21:38:56.486375 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.011 seconds
[0m21:38:56.490346 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:38:56.490894 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m21:38:56.492163 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.494683 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:38:56.495377 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:38:56.495850 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:38:56.499469 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:38:56.503063 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m21:38:56.504130 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:38:56.504559 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m21:38:56.505571 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.507142 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: Close
[0m21:38:56.507780 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079006d0>]}
[0m21:38:56.508535 [info ] [Thread-1  ]: 19 of 20 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.05s]
[0m21:38:56.509377 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m21:38:56.509956 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m21:38:56.510689 [info ] [Thread-1  ]: 20 of 20 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m21:38:56.511455 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m21:38:56.511901 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m21:38:56.515628 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m21:38:56.516452 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m21:38:56.521604 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_staff"
[0m21:38:56.522552 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:38:56.522962 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: BEGIN
[0m21:38:56.523494 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:38:56.529857 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:38:56.530384 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:38:56.530804 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."staff"
  );
  
[0m21:38:56.534094 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.003 seconds
[0m21:38:56.538913 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:38:56.539522 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m21:38:56.540641 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:38:56.542586 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:38:56.543090 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:38:56.543964 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:38:56.545799 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:38:56.548909 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m21:38:56.549815 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:38:56.550265 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m21:38:56.551883 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:38:56.553518 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: Close
[0m21:38:56.554145 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18296e48-8d33-4e7f-a473-afff8e87b551', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070961f0>]}
[0m21:38:56.554958 [info ] [Thread-1  ]: 20 of 20 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.04s]
[0m21:38:56.555656 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m21:38:56.556980 [debug] [MainThread]: Using postgres connection "master"
[0m21:38:56.557373 [debug] [MainThread]: On master: BEGIN
[0m21:38:56.557713 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:38:56.563907 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:38:56.564384 [debug] [MainThread]: On master: COMMIT
[0m21:38:56.564748 [debug] [MainThread]: Using postgres connection "master"
[0m21:38:56.565092 [debug] [MainThread]: On master: COMMIT
[0m21:38:56.565690 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:38:56.566120 [debug] [MainThread]: On master: Close
[0m21:38:56.566616 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:38:56.566952 [debug] [MainThread]: Connection 'model.datawarehouse.dim_staff' was properly closed.
[0m21:38:56.567433 [info ] [MainThread]: 
[0m21:38:56.567918 [info ] [MainThread]: Finished running 19 table models, 1 view model in 0 hours 0 minutes and 1.62 seconds (1.62s).
[0m21:38:56.572344 [debug] [MainThread]: Command end result
[0m21:38:56.616235 [info ] [MainThread]: 
[0m21:38:56.616988 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:38:56.617501 [info ] [MainThread]: 
[0m21:38:56.618069 [info ] [MainThread]: Done. PASS=20 WARN=0 ERROR=0 SKIP=0 TOTAL=20
[0m21:38:56.619792 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.8270643, "process_user_time": 3.503756, "process_kernel_time": 0.442019, "process_mem_max_rss": "109555712", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:38:56.620491 [debug] [MainThread]: Command `dbt run` succeeded at 21:38:56.620371 after 2.83 seconds
[0m21:38:56.620945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a1b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070d22e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063ae910>]}
[0m21:38:56.621380 [debug] [MainThread]: Flushing usage events
[0m21:43:39.014104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047272e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106248b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106248880>]}


============================== 21:43:39.022610 | 2274ee20-35f7-42e3-af23-eb3c113a2bde ==============================
[0m21:43:39.022610 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:43:39.023493 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:43:39.230769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065b55b0>]}
[0m21:43:39.295638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065c6100>]}
[0m21:43:39.297257 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:43:39.318128 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:43:39.530982 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m21:43:39.531665 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/mart/total_revenue.sql
[0m21:43:39.831222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa5130>]}
[0m21:43:39.990894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f81700>]}
[0m21:43:39.991582 [info ] [MainThread]: Found 21 models, 4 data tests, 9 sources, 417 macros
[0m21:43:39.992029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f8ff70>]}
[0m21:43:39.994848 [info ] [MainThread]: 
[0m21:43:39.995565 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:43:40.003276 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m21:43:40.080042 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:43:40.080543 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:43:40.080926 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:43:40.127124 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.046 seconds
[0m21:43:40.129285 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:43:40.132627 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:43:40.133265 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:43:40.133812 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:40.139831 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.006 seconds
[0m21:43:40.141242 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:43:40.144020 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:43:40.144610 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:43:40.145008 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:40.150234 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.005 seconds
[0m21:43:40.151688 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:43:40.154617 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:43:40.155178 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:43:40.155572 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:40.160761 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.005 seconds
[0m21:43:40.162231 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:43:40.162962 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now create_datawarehouse_dbt_dev_mart)
[0m21:43:40.163538 [debug] [ThreadPool]: Creating schema "database: "datawarehouse"
schema: "dbt_dev_mart"
"
[0m21:43:40.169519 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_mart"
[0m21:43:40.169967 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_mart: BEGIN
[0m21:43:40.170320 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:40.175880 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:43:40.176345 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_mart"
[0m21:43:40.176713 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "create_datawarehouse_dbt_dev_mart"} */
create schema if not exists "dbt_dev_mart"
[0m21:43:40.177677 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m21:43:40.178765 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_mart: COMMIT
[0m21:43:40.179195 [debug] [ThreadPool]: Using postgres connection "create_datawarehouse_dbt_dev_mart"
[0m21:43:40.179610 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_mart: COMMIT
[0m21:43:40.182745 [debug] [ThreadPool]: SQL status: COMMIT in 0.003 seconds
[0m21:43:40.183199 [debug] [ThreadPool]: On create_datawarehouse_dbt_dev_mart: Close
[0m21:43:40.186496 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev_mart)
[0m21:43:40.193520 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m21:43:40.193965 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: BEGIN
[0m21:43:40.194315 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:40.200292 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.200760 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m21:43:40.201142 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_mart"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m21:43:40.204970 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:43:40.206328 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: ROLLBACK
[0m21:43:40.207334 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: Close
[0m21:43:40.208310 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev)
[0m21:43:40.211184 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:43:40.211644 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m21:43:40.211998 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:40.218287 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.218747 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:43:40.219138 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:43:40.222431 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m21:43:40.224079 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m21:43:40.225120 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m21:43:40.225904 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now list_datawarehouse_dbt_dev_raw)
[0m21:43:40.229589 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:43:40.230041 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m21:43:40.230495 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:40.236976 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.237438 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:43:40.237825 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:43:40.240857 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:43:40.242403 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m21:43:40.243108 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m21:43:40.243727 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev_intermediete)
[0m21:43:40.293654 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:43:40.294293 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m21:43:40.294798 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:43:40.301935 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:43:40.302643 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:43:40.303158 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m21:43:40.307204 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.004 seconds
[0m21:43:40.309103 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m21:43:40.309994 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m21:43:40.319226 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:40.319703 [debug] [MainThread]: On master: BEGIN
[0m21:43:40.320075 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:43:40.325666 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.326153 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:40.326610 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:43:40.336709 [debug] [MainThread]: SQL status: SELECT 38 in 0.010 seconds
[0m21:43:40.339262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107005790>]}
[0m21:43:40.339763 [debug] [MainThread]: On master: ROLLBACK
[0m21:43:40.340494 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:40.340878 [debug] [MainThread]: On master: BEGIN
[0m21:43:40.341900 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:43:40.342276 [debug] [MainThread]: On master: COMMIT
[0m21:43:40.342635 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:40.342984 [debug] [MainThread]: On master: COMMIT
[0m21:43:40.343642 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:43:40.344029 [debug] [MainThread]: On master: Close
[0m21:43:40.344537 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:43:40.344928 [info ] [MainThread]: 
[0m21:43:40.347705 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m21:43:40.348318 [info ] [Thread-1  ]: 1 of 21 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:43:40.348858 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now model.datawarehouse.actor)
[0m21:43:40.349370 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m21:43:40.360109 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m21:43:40.361074 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m21:43:40.408361 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m21:43:40.409313 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:43:40.409732 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m21:43:40.410122 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.415933 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.416462 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:43:40.416888 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m21:43:40.419265 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m21:43:40.426662 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:43:40.427144 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m21:43:40.428350 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.433036 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:43:40.433482 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:43:40.434802 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.457883 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:43:40.458390 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:43:40.458790 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:43:40.460454 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:40.469103 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:43:40.474970 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:43:40.475572 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:43:40.477803 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.480372 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m21:43:40.482112 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066ccbe0>]}
[0m21:43:40.483108 [info ] [Thread-1  ]: 1 of 21 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m21:43:40.484234 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m21:43:40.484747 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m21:43:40.485296 [info ] [Thread-1  ]: 2 of 21 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:43:40.485924 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m21:43:40.486374 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m21:43:40.490245 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m21:43:40.491248 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m21:43:40.496601 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m21:43:40.497556 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:43:40.497980 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m21:43:40.498372 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.503880 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:43:40.504430 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:43:40.504869 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m21:43:40.507390 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:43:40.511220 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:43:40.511671 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m21:43:40.512766 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.516514 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:43:40.517011 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:43:40.518081 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.520123 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:43:40.520543 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:43:40.520939 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:43:40.522655 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:40.525626 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:43:40.527676 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:43:40.528107 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:43:40.530175 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.531654 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m21:43:40.532223 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10563a7c0>]}
[0m21:43:40.532937 [info ] [Thread-1  ]: 2 of 21 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m21:43:40.534282 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m21:43:40.534855 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m21:43:40.535524 [info ] [Thread-1  ]: 3 of 21 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:43:40.536132 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m21:43:40.536556 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m21:43:40.540499 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m21:43:40.541776 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m21:43:40.546364 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m21:43:40.547205 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:43:40.547626 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m21:43:40.548016 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.554993 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:43:40.555543 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:43:40.556264 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m21:43:40.559986 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.003 seconds
[0m21:43:40.565543 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:43:40.566543 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m21:43:40.568136 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.572930 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:43:40.573440 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:43:40.574735 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.576967 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:43:40.577465 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:43:40.577876 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:43:40.579638 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:40.583341 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:43:40.584397 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:43:40.584910 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:43:40.587326 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.588957 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m21:43:40.590107 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065c10a0>]}
[0m21:43:40.591096 [info ] [Thread-1  ]: 3 of 21 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m21:43:40.591859 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m21:43:40.592408 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m21:43:40.592959 [info ] [Thread-1  ]: 4 of 21 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:43:40.593668 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m21:43:40.594120 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m21:43:40.598133 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m21:43:40.599652 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m21:43:40.607139 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m21:43:40.608190 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:43:40.608697 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m21:43:40.609089 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.614890 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.615406 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:43:40.615856 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m21:43:40.622439 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.006 seconds
[0m21:43:40.626358 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:43:40.626838 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m21:43:40.628001 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.632065 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:43:40.632680 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:43:40.634565 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.637918 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:43:40.638492 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:43:40.638951 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:43:40.640974 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:43:40.644151 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:43:40.645237 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:43:40.645710 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:43:40.648198 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.650131 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m21:43:40.650800 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107450d60>]}
[0m21:43:40.651497 [info ] [Thread-1  ]: 4 of 21 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.06s]
[0m21:43:40.652177 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m21:43:40.652659 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m21:43:40.653237 [info ] [Thread-1  ]: 5 of 21 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:43:40.653921 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m21:43:40.654404 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m21:43:40.658136 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m21:43:40.659113 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m21:43:40.664060 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m21:43:40.664974 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:43:40.665392 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m21:43:40.665792 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.671679 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.672237 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:43:40.672672 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m21:43:40.676967 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:43:40.680956 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:43:40.681466 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m21:43:40.682596 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.686359 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:43:40.686804 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:43:40.688047 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.690181 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:43:40.690630 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:43:40.691028 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:43:40.692668 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:40.696945 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:43:40.697846 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:43:40.698275 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:43:40.700626 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.702814 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m21:43:40.703529 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10563a7c0>]}
[0m21:43:40.704258 [info ] [Thread-1  ]: 5 of 21 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m21:43:40.704950 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m21:43:40.705615 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m21:43:40.706321 [info ] [Thread-1  ]: 6 of 21 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:43:40.706869 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m21:43:40.707284 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m21:43:40.710864 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m21:43:40.711724 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m21:43:40.716422 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m21:43:40.717251 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:43:40.717670 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m21:43:40.718058 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.723610 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:43:40.724241 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:43:40.724792 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m21:43:40.729006 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:43:40.733035 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:43:40.733536 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m21:43:40.735117 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.739799 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:43:40.740308 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:43:40.741779 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.744235 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:43:40.744877 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:43:40.745327 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:43:40.747516 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:43:40.752605 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:43:40.753847 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:43:40.754418 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:43:40.757086 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.758782 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m21:43:40.759527 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107582be0>]}
[0m21:43:40.760336 [info ] [Thread-1  ]: 6 of 21 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m21:43:40.761171 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m21:43:40.761700 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m21:43:40.762265 [info ] [Thread-1  ]: 7 of 21 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:43:40.762921 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m21:43:40.763369 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m21:43:40.767257 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m21:43:40.768666 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m21:43:40.775627 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m21:43:40.776559 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:43:40.777060 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m21:43:40.777715 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.785615 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:43:40.786404 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:43:40.787146 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:43:40.790737 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.003 seconds
[0m21:43:40.795950 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:43:40.796453 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:43:40.797837 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.802561 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:43:40.803108 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:43:40.804546 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.806715 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:43:40.807183 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:43:40.807599 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:43:40.809217 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:40.812422 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:43:40.813360 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:43:40.813792 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:43:40.816432 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.818743 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m21:43:40.819687 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e4faf0>]}
[0m21:43:40.821216 [info ] [Thread-1  ]: 7 of 21 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m21:43:40.822238 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m21:43:40.822827 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m21:43:40.823644 [info ] [Thread-1  ]: 8 of 21 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:43:40.824493 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m21:43:40.824952 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m21:43:40.828668 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m21:43:40.829569 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m21:43:40.834484 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m21:43:40.835401 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:43:40.835847 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m21:43:40.836249 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.843969 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:43:40.844599 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:43:40.845050 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m21:43:40.855694 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.010 seconds
[0m21:43:40.860561 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:43:40.861230 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:43:40.862737 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.869982 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:43:40.870503 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:43:40.872090 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.875002 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:43:40.875505 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:43:40.875922 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:43:40.878578 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:43:40.881578 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:43:40.882617 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:43:40.883353 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:43:40.885596 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.887636 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m21:43:40.888659 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10759e1c0>]}
[0m21:43:40.889813 [info ] [Thread-1  ]: 8 of 21 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m21:43:40.890843 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m21:43:40.891384 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m21:43:40.892061 [info ] [Thread-1  ]: 9 of 21 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:43:40.892942 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m21:43:40.893421 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m21:43:40.898082 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m21:43:40.898991 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m21:43:40.904887 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m21:43:40.905743 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:43:40.906359 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m21:43:40.906831 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.912616 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.913130 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:43:40.913598 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m21:43:40.923856 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.010 seconds
[0m21:43:40.927678 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:43:40.928124 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m21:43:40.929178 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.932522 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:43:40.932938 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:43:40.934766 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.937650 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:43:40.938309 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:43:40.938811 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:43:40.942069 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:43:40.945134 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:43:40.946101 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:43:40.946522 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:43:40.948825 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:40.950520 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m21:43:40.951276 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10657cf10>]}
[0m21:43:40.952094 [info ] [Thread-1  ]: 9 of 21 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m21:43:40.953043 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m21:43:40.953637 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m21:43:40.954360 [info ] [Thread-1  ]: 10 of 21 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:43:40.954929 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m21:43:40.955394 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m21:43:40.960506 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m21:43:40.961419 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m21:43:40.965926 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m21:43:40.966747 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:43:40.967253 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m21:43:40.967672 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:40.973349 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:43:40.973872 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:43:40.974295 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m21:43:40.977922 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.003 seconds
[0m21:43:40.981736 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:43:40.982292 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m21:43:40.983375 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.986950 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:43:40.987547 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:43:40.989372 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:40.991818 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:43:40.992310 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:43:40.992732 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:43:40.994249 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:40.997453 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:43:40.998464 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:43:40.998935 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:43:41.001408 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.003138 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m21:43:41.003809 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066c5b20>]}
[0m21:43:41.004990 [info ] [Thread-1  ]: 10 of 21 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m21:43:41.005715 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m21:43:41.006278 [debug] [Thread-1  ]: Began running node model.datawarehouse.total_revenue
[0m21:43:41.006833 [info ] [Thread-1  ]: 11 of 21 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m21:43:41.007459 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.total_revenue)
[0m21:43:41.007916 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.total_revenue
[0m21:43:41.011292 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.total_revenue"
[0m21:43:41.012379 [debug] [Thread-1  ]: Began executing node model.datawarehouse.total_revenue
[0m21:43:41.017431 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.total_revenue"
[0m21:43:41.018418 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:43:41.018847 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: BEGIN
[0m21:43:41.019237 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.026532 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:43:41.027042 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:43:41.027501 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    date_trunc(payment_date, month) as month_year,
    sum(amount) as total_revenue
FROM {( ref('fact_payment'))}
GROUP BY 1
ORDER BY 1
  );
  
[0m21:43:41.028838 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near "{"
LINE 17: FROM {( ref('fact_payment'))}
              ^

[0m21:43:41.029385 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: ROLLBACK
[0m21:43:41.030396 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: Close
[0m21:43:41.073248 [debug] [Thread-1  ]: Database Error in model total_revenue (models/mart/total_revenue.sql)
  syntax error at or near "{"
  LINE 17: FROM {( ref('fact_payment'))}
                ^
  compiled Code at target/run/datawarehouse/models/mart/total_revenue.sql
[0m21:43:41.073924 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e64550>]}
[0m21:43:41.074623 [error] [Thread-1  ]: 11 of 21 ERROR creating sql table model dbt_dev_mart.total_revenue ............. [[31mERROR[0m in 0.07s]
[0m21:43:41.075441 [debug] [Thread-1  ]: Finished running node model.datawarehouse.total_revenue
[0m21:43:41.075927 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m21:43:41.076449 [info ] [Thread-1  ]: 12 of 21 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m21:43:41.077253 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.total_revenue, now model.datawarehouse.dim_actor)
[0m21:43:41.077687 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m21:43:41.083715 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m21:43:41.084711 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m21:43:41.090891 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_actor"
[0m21:43:41.091803 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:43:41.092271 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: BEGIN
[0m21:43:41.092712 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.099151 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:43:41.099693 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:43:41.100520 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."actor"
  );
  
[0m21:43:41.102837 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m21:43:41.107076 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:43:41.107563 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m21:43:41.108659 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.112260 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:43:41.112723 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m21:43:41.113711 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.115775 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:43:41.116535 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:43:41.116987 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:43:41.118492 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:41.121592 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m21:43:41.122643 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:43:41.123074 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m21:43:41.125019 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.126506 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: Close
[0m21:43:41.127078 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075e0640>]}
[0m21:43:41.127766 [info ] [Thread-1  ]: 12 of 21 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m21:43:41.128459 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m21:43:41.128996 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m21:43:41.129612 [info ] [Thread-1  ]: 13 of 21 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m21:43:41.130151 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m21:43:41.130573 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m21:43:41.134875 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m21:43:41.135779 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m21:43:41.185211 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_address"
[0m21:43:41.186382 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:43:41.187072 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: BEGIN
[0m21:43:41.196707 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.204494 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:43:41.205159 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:43:41.205995 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."address"
  );
  
[0m21:43:41.208941 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:43:41.217648 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:43:41.218361 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m21:43:41.219720 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.224800 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:43:41.225618 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m21:43:41.227301 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.230266 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:43:41.230814 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:43:41.231234 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:43:41.232819 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:41.236478 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m21:43:41.238067 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:43:41.238860 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m21:43:41.241520 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.243328 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: Close
[0m21:43:41.244385 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e64550>]}
[0m21:43:41.245589 [info ] [Thread-1  ]: 13 of 21 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.11s]
[0m21:43:41.246713 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m21:43:41.247285 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m21:43:41.247939 [info ] [Thread-1  ]: 14 of 21 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m21:43:41.248607 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m21:43:41.249068 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m21:43:41.253446 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m21:43:41.254962 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m21:43:41.261894 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_customer"
[0m21:43:41.263258 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:43:41.264024 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: BEGIN
[0m21:43:41.264804 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.273559 [debug] [Thread-1  ]: SQL status: BEGIN in 0.009 seconds
[0m21:43:41.274443 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:43:41.275374 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."customer"
  );
  
[0m21:43:41.278902 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.003 seconds
[0m21:43:41.285500 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:43:41.286203 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m21:43:41.287816 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.294226 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:43:41.295014 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m21:43:41.296682 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.299343 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:43:41.300131 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:43:41.300807 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:43:41.302955 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:41.307355 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m21:43:41.309227 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:43:41.309752 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m21:43:41.312571 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.314483 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: Close
[0m21:43:41.315489 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e64550>]}
[0m21:43:41.317052 [info ] [Thread-1  ]: 14 of 21 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.07s]
[0m21:43:41.318127 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m21:43:41.318738 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m21:43:41.319378 [info ] [Thread-1  ]: 15 of 21 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m21:43:41.320091 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m21:43:41.320666 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m21:43:41.328587 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m21:43:41.329801 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m21:43:41.335346 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film"
[0m21:43:41.336356 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:43:41.337158 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: BEGIN
[0m21:43:41.337995 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.346101 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:43:41.346671 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:43:41.347097 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film"
  );
  
[0m21:43:41.353078 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.005 seconds
[0m21:43:41.356910 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:43:41.357385 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m21:43:41.358453 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.362102 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:43:41.362616 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m21:43:41.363685 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.365769 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:43:41.366223 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:43:41.366717 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:43:41.368986 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:43:41.372090 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m21:43:41.373093 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:43:41.373530 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m21:43:41.376091 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.377683 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: Close
[0m21:43:41.378343 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107674f10>]}
[0m21:43:41.379099 [info ] [Thread-1  ]: 15 of 21 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m21:43:41.379858 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m21:43:41.380509 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m21:43:41.381061 [info ] [Thread-1  ]: 16 of 21 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m21:43:41.381681 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m21:43:41.382123 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m21:43:41.386167 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m21:43:41.387121 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m21:43:41.392886 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film_actor"
[0m21:43:41.393796 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:43:41.394238 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: BEGIN
[0m21:43:41.394709 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.401249 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:43:41.401778 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:43:41.402203 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m21:43:41.406720 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:43:41.412441 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:43:41.412988 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m21:43:41.414097 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.417877 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:43:41.418359 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m21:43:41.419643 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.421908 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:43:41.422369 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:43:41.422775 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:43:41.424622 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:41.427848 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m21:43:41.428802 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:43:41.429253 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m21:43:41.431537 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.433317 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: Close
[0m21:43:41.434116 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073f8a30>]}
[0m21:43:41.435307 [info ] [Thread-1  ]: 16 of 21 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m21:43:41.436649 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m21:43:41.437210 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m21:43:41.437900 [info ] [Thread-1  ]: 17 of 21 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m21:43:41.438456 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m21:43:41.438887 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m21:43:41.442758 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m21:43:41.443726 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m21:43:41.448545 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_inventory"
[0m21:43:41.449704 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:43:41.450242 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: BEGIN
[0m21:43:41.450650 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.457123 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:43:41.457638 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:43:41.458074 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."inventory"
  );
  
[0m21:43:41.463601 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.005 seconds
[0m21:43:41.468920 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:43:41.469675 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m21:43:41.471651 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.476195 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:43:41.485213 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m21:43:41.486850 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.490732 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:43:41.491555 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:43:41.492334 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:43:41.494758 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:43:41.500856 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m21:43:41.502611 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:43:41.503444 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m21:43:41.506462 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.508907 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: Close
[0m21:43:41.509991 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075845b0>]}
[0m21:43:41.510865 [info ] [Thread-1  ]: 17 of 21 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.07s]
[0m21:43:41.511878 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m21:43:41.512698 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m21:43:41.513572 [info ] [Thread-1  ]: 18 of 21 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:43:41.514540 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m21:43:41.515166 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m21:43:41.519952 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m21:43:41.521141 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m21:43:41.552665 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m21:43:41.553703 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:43:41.554174 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m21:43:41.554636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.562488 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:43:41.563164 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:43:41.563732 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:43:41.565741 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m21:43:41.569800 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:43:41.570304 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:43:41.571422 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.573117 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:43:41.573533 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:43:41.573965 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:43:41.575303 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:41.578376 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:43:41.581242 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:43:41.581696 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:43:41.582704 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m21:43:41.584578 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m21:43:41.585406 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b77ac0>]}
[0m21:43:41.586149 [info ] [Thread-1  ]: 18 of 21 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m21:43:41.587494 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m21:43:41.588506 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m21:43:41.589711 [info ] [Thread-1  ]: 19 of 21 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m21:43:41.590711 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now model.datawarehouse.fact_payment)
[0m21:43:41.591253 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m21:43:41.596396 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m21:43:41.597329 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m21:43:41.604655 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.fact_payment"
[0m21:43:41.606062 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:43:41.606715 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: BEGIN
[0m21:43:41.607351 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.614023 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:43:41.616430 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:43:41.616863 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."payment"
  );
  
[0m21:43:41.629310 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.012 seconds
[0m21:43:41.634735 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:43:41.635298 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m21:43:41.636806 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.641099 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:43:41.641597 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m21:43:41.642957 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.646559 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:43:41.647367 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:43:41.648099 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:43:41.650256 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:41.654805 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m21:43:41.656065 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:43:41.656983 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m21:43:41.659981 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.661987 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: Close
[0m21:43:41.663032 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076e0df0>]}
[0m21:43:41.664041 [info ] [Thread-1  ]: 19 of 21 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m21:43:41.664883 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m21:43:41.665518 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m21:43:41.666105 [info ] [Thread-1  ]: 20 of 21 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m21:43:41.667024 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m21:43:41.667627 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m21:43:41.672424 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m21:43:41.673322 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m21:43:41.678169 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_rental"
[0m21:43:41.679031 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:43:41.679449 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: BEGIN
[0m21:43:41.679840 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.685162 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:43:41.685677 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:43:41.686102 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."rental"
  );
  
[0m21:43:41.702292 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.015 seconds
[0m21:43:41.740348 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:43:41.741490 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m21:43:41.743630 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.748283 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:43:41.748792 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m21:43:41.750229 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.752753 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:43:41.753383 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:43:41.753858 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:43:41.756838 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:43:41.761312 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m21:43:41.762472 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:43:41.762930 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m21:43:41.765185 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.766763 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: Close
[0m21:43:41.767575 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b6f160>]}
[0m21:43:41.768394 [info ] [Thread-1  ]: 20 of 21 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.10s]
[0m21:43:41.769427 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m21:43:41.770110 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m21:43:41.770876 [info ] [Thread-1  ]: 21 of 21 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m21:43:41.771427 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m21:43:41.771847 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m21:43:41.775437 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m21:43:41.776269 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m21:43:41.781550 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_staff"
[0m21:43:41.782435 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:43:41.782859 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: BEGIN
[0m21:43:41.783531 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:43:41.790470 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:43:41.791057 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:43:41.791548 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."staff"
  );
  
[0m21:43:41.795584 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m21:43:41.799638 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:43:41.800372 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m21:43:41.801758 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.806307 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:43:41.806817 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m21:43:41.808089 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:43:41.810113 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:43:41.810524 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:43:41.811106 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:43:41.812694 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:43:41.815845 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m21:43:41.817062 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:43:41.817821 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m21:43:41.820205 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:43:41.822125 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: Close
[0m21:43:41.822832 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2274ee20-35f7-42e3-af23-eb3c113a2bde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f81370>]}
[0m21:43:41.823900 [info ] [Thread-1  ]: 21 of 21 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m21:43:41.825194 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m21:43:41.826550 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:41.826947 [debug] [MainThread]: On master: BEGIN
[0m21:43:41.827309 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:43:41.833732 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:43:41.834314 [debug] [MainThread]: On master: COMMIT
[0m21:43:41.834905 [debug] [MainThread]: Using postgres connection "master"
[0m21:43:41.835282 [debug] [MainThread]: On master: COMMIT
[0m21:43:41.836223 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:43:41.836835 [debug] [MainThread]: On master: Close
[0m21:43:41.837774 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:43:41.838467 [debug] [MainThread]: Connection 'model.datawarehouse.dim_staff' was properly closed.
[0m21:43:41.839588 [info ] [MainThread]: 
[0m21:43:41.840412 [info ] [MainThread]: Finished running 20 table models, 1 view model in 0 hours 0 minutes and 1.84 seconds (1.84s).
[0m21:43:41.844937 [debug] [MainThread]: Command end result
[0m21:43:41.900449 [info ] [MainThread]: 
[0m21:43:41.901693 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:43:41.902798 [info ] [MainThread]: 
[0m21:43:41.903723 [error] [MainThread]:   Database Error in model total_revenue (models/mart/total_revenue.sql)
  syntax error at or near "{"
  LINE 17: FROM {( ref('fact_payment'))}
                ^
  compiled Code at target/run/datawarehouse/models/mart/total_revenue.sql
[0m21:43:41.905019 [info ] [MainThread]: 
[0m21:43:41.906135 [info ] [MainThread]: Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
[0m21:43:41.909443 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.9804924, "process_user_time": 3.603359, "process_kernel_time": 0.439779, "process_mem_max_rss": "110198784", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:43:41.910288 [debug] [MainThread]: Command `dbt run` failed at 21:43:41.910120 after 2.98 seconds
[0m21:43:41.910976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047272e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106202c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062026a0>]}
[0m21:43:41.911510 [debug] [MainThread]: Flushing usage events
[0m21:44:27.752282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bb92e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096dabb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096da8b0>]}


============================== 21:44:27.760512 | 4e715e12-cb7f-4e43-a71d-71d5359480d5 ==============================
[0m21:44:27.760512 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:44:27.761195 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:44:27.967340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099f7520>]}
[0m21:44:28.025907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108aeb8e0>]}
[0m21:44:28.027530 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:44:28.047582 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:44:28.277228 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:44:28.278006 [debug] [MainThread]: Partial parsing: updated file: datawarehouse://models/mart/total_revenue.sql
[0m21:44:28.566533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3c2130>]}
[0m21:44:28.713771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a265be0>]}
[0m21:44:28.714437 [info ] [MainThread]: Found 21 models, 4 data tests, 9 sources, 417 macros
[0m21:44:28.714855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a450bb0>]}
[0m21:44:28.717445 [info ] [MainThread]: 
[0m21:44:28.718137 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:44:28.724634 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m21:44:28.790283 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:44:28.807516 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:44:28.828289 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:44:28.884699 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.056 seconds
[0m21:44:28.887785 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:44:28.893693 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:44:28.894785 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:44:28.895440 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:28.902290 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m21:44:28.903710 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:44:28.906734 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:44:28.907236 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:44:28.907604 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:28.913276 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m21:44:28.914851 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:44:28.919276 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:44:28.919989 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:44:28.920381 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:28.927482 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m21:44:28.928954 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:44:28.932290 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now list_datawarehouse_dbt_dev_mart)
[0m21:44:28.940263 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m21:44:28.940706 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: BEGIN
[0m21:44:28.941336 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:28.948403 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m21:44:28.948967 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m21:44:28.949611 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_mart"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m21:44:28.953184 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:44:28.954869 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: ROLLBACK
[0m21:44:28.956174 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: Close
[0m21:44:28.957252 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev_raw)
[0m21:44:28.960153 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:44:28.960641 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m21:44:28.961040 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:28.967185 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:44:28.967635 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:44:28.968144 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:44:28.971426 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:44:28.973008 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m21:44:28.973912 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m21:44:28.974606 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev_intermediete)
[0m21:44:28.979155 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:44:28.979591 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m21:44:28.979939 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:28.985642 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:44:28.986136 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:44:28.986728 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m21:44:28.990024 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:44:28.991586 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m21:44:28.992486 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m21:44:28.993202 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now list_datawarehouse_dbt_dev)
[0m21:44:28.998554 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:44:28.998988 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m21:44:28.999331 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:29.005186 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:44:29.005638 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:44:29.006044 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:44:29.009317 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m21:44:29.010769 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m21:44:29.011723 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m21:44:29.059805 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:29.060384 [debug] [MainThread]: On master: BEGIN
[0m21:44:29.060841 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:44:29.066936 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m21:44:29.067485 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:29.068097 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:44:29.121506 [debug] [MainThread]: SQL status: SELECT 38 in 0.053 seconds
[0m21:44:29.125119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fa8940>]}
[0m21:44:29.125709 [debug] [MainThread]: On master: ROLLBACK
[0m21:44:29.126696 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:29.127160 [debug] [MainThread]: On master: BEGIN
[0m21:44:29.128542 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:44:29.128953 [debug] [MainThread]: On master: COMMIT
[0m21:44:29.129333 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:29.129702 [debug] [MainThread]: On master: COMMIT
[0m21:44:29.130507 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:44:29.130912 [debug] [MainThread]: On master: Close
[0m21:44:29.131447 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:44:29.131863 [info ] [MainThread]: 
[0m21:44:29.134642 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m21:44:29.135290 [info ] [Thread-1  ]: 1 of 21 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:44:29.135979 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now model.datawarehouse.actor)
[0m21:44:29.136430 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m21:44:29.147178 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m21:44:29.148041 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m21:44:29.193384 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m21:44:29.194339 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:29.194761 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m21:44:29.195154 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.200568 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:44:29.201078 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:29.201510 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m21:44:29.203580 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m21:44:29.210859 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:29.211330 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m21:44:29.212379 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.215935 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:29.216356 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:44:29.217361 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.239972 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:44:29.240458 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:29.240862 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:44:29.242808 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:29.249919 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:44:29.254893 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:29.255338 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:44:29.257618 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.260194 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m21:44:29.262193 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e59eb0>]}
[0m21:44:29.263001 [info ] [Thread-1  ]: 1 of 21 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m21:44:29.263739 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m21:44:29.264256 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m21:44:29.264772 [info ] [Thread-1  ]: 2 of 21 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:44:29.265597 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m21:44:29.266124 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m21:44:29.270202 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m21:44:29.271122 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m21:44:29.276773 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m21:44:29.277659 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:29.278077 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m21:44:29.278465 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.283777 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:44:29.284291 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:29.284716 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m21:44:29.287304 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:44:29.291112 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:29.291579 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m21:44:29.292626 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.296068 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:29.296553 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:44:29.297681 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.299768 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:44:29.300190 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:29.300581 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:44:29.302313 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.305667 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:44:29.306602 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:29.307012 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:44:29.309091 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.310558 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m21:44:29.311221 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3ffa90>]}
[0m21:44:29.312070 [info ] [Thread-1  ]: 2 of 21 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m21:44:29.312919 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m21:44:29.313678 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m21:44:29.314380 [info ] [Thread-1  ]: 3 of 21 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:44:29.314954 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m21:44:29.315398 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m21:44:29.320456 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m21:44:29.322000 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m21:44:29.326675 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m21:44:29.327510 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:29.327924 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m21:44:29.328315 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.333689 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:44:29.334194 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:29.334613 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m21:44:29.336956 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m21:44:29.340875 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:29.341418 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m21:44:29.342457 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.345898 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:29.346330 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:44:29.347400 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.349557 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:44:29.350003 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:29.350393 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:44:29.352142 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.355595 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:44:29.356489 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:29.356906 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:44:29.359252 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.360723 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m21:44:29.361453 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a850610>]}
[0m21:44:29.362173 [info ] [Thread-1  ]: 3 of 21 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m21:44:29.362934 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m21:44:29.363582 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m21:44:29.364325 [info ] [Thread-1  ]: 4 of 21 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:44:29.364874 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m21:44:29.365297 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m21:44:29.369060 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m21:44:29.369977 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m21:44:29.375328 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m21:44:29.376179 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:29.376599 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m21:44:29.376989 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.382743 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:29.383251 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:29.383679 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m21:44:29.390005 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.006 seconds
[0m21:44:29.396830 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:29.397374 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m21:44:29.398696 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.402761 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:29.403310 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:44:29.405167 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.408332 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:44:29.408883 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:29.409409 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:44:29.411281 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.414875 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:44:29.415848 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:29.416278 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:44:29.419221 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.420888 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m21:44:29.421512 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a96eca0>]}
[0m21:44:29.422210 [info ] [Thread-1  ]: 4 of 21 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.06s]
[0m21:44:29.422895 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m21:44:29.423389 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m21:44:29.423978 [info ] [Thread-1  ]: 5 of 21 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:44:29.424514 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m21:44:29.424934 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m21:44:29.428497 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m21:44:29.429593 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m21:44:29.434065 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m21:44:29.434794 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:29.435379 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m21:44:29.435756 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.442930 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:44:29.443553 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:29.444036 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m21:44:29.449375 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.005 seconds
[0m21:44:29.454214 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:29.455205 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m21:44:29.456749 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.460486 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:29.460955 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:44:29.462079 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.464235 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:44:29.464671 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:29.465077 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:44:29.466910 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.469982 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:44:29.472419 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:29.472901 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:44:29.474924 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.476416 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m21:44:29.476988 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9d4ee0>]}
[0m21:44:29.477647 [info ] [Thread-1  ]: 5 of 21 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m21:44:29.478384 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m21:44:29.478897 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m21:44:29.479520 [info ] [Thread-1  ]: 6 of 21 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:44:29.480215 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m21:44:29.480650 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m21:44:29.484249 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m21:44:29.485473 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m21:44:29.491725 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m21:44:29.492724 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:29.493210 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m21:44:29.493666 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.499754 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:29.500332 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:29.500769 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m21:44:29.505541 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:44:29.509841 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:29.510331 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m21:44:29.511560 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.515136 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:29.515568 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:44:29.516584 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.518668 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:44:29.519112 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:29.519513 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:44:29.521494 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:29.524788 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:44:29.525704 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:29.526119 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:44:29.528454 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.529922 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m21:44:29.530610 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f963d0>]}
[0m21:44:29.531361 [info ] [Thread-1  ]: 6 of 21 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m21:44:29.532191 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m21:44:29.532737 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m21:44:29.533266 [info ] [Thread-1  ]: 7 of 21 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:44:29.533885 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m21:44:29.534323 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m21:44:29.537934 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m21:44:29.538983 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m21:44:29.544882 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m21:44:29.545767 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:29.546211 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m21:44:29.546609 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.552377 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:29.552906 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:29.553383 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:44:29.555798 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.002 seconds
[0m21:44:29.559654 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:29.560220 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:44:29.561296 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.564964 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:29.565439 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:44:29.566455 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.568628 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:44:29.569102 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:29.569526 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:44:29.571347 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.574749 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:44:29.575723 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:29.576161 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:44:29.578516 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.580058 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m21:44:29.580639 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e59eb0>]}
[0m21:44:29.581322 [info ] [Thread-1  ]: 7 of 21 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m21:44:29.582023 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m21:44:29.582568 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m21:44:29.583119 [info ] [Thread-1  ]: 8 of 21 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:44:29.583757 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m21:44:29.584218 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m21:44:29.588528 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m21:44:29.589829 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m21:44:29.596142 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m21:44:29.597116 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:29.597602 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m21:44:29.598134 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.605795 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:44:29.606314 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:29.606744 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m21:44:29.615943 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.009 seconds
[0m21:44:29.619839 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:29.620359 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:44:29.621529 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.625589 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:29.626163 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:44:29.627491 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.629861 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:44:29.630342 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:29.630959 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:44:29.633994 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:29.640744 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:44:29.642360 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:29.643142 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:44:29.646169 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.648672 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m21:44:29.649835 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9e8130>]}
[0m21:44:29.651127 [info ] [Thread-1  ]: 8 of 21 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.07s]
[0m21:44:29.652623 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m21:44:29.653648 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m21:44:29.654840 [info ] [Thread-1  ]: 9 of 21 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:44:29.655778 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m21:44:29.656224 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m21:44:29.661376 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m21:44:29.662533 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m21:44:29.667313 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m21:44:29.668287 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:29.668740 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m21:44:29.669136 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.675247 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:29.675774 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:29.676515 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m21:44:29.687122 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.010 seconds
[0m21:44:29.692090 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:29.712141 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m21:44:29.714799 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.720370 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:29.721036 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:44:29.722977 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.726570 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:44:29.727568 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:29.728134 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:44:29.731736 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:44:29.735142 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:44:29.736086 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:29.736780 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:44:29.739704 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.741458 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m21:44:29.742343 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9eaf10>]}
[0m21:44:29.743379 [info ] [Thread-1  ]: 9 of 21 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.09s]
[0m21:44:29.744319 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m21:44:29.744940 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m21:44:29.745658 [info ] [Thread-1  ]: 10 of 21 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:44:29.746347 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m21:44:29.746791 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m21:44:29.750766 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m21:44:29.752137 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m21:44:29.760354 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m21:44:29.761618 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:44:29.762526 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m21:44:29.763366 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.770737 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:44:29.771329 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:44:29.772090 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m21:44:29.777505 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.005 seconds
[0m21:44:29.781821 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:44:29.782463 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m21:44:29.783581 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.787666 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:44:29.788167 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:44:29.789301 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.791466 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:44:29.792012 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:44:29.792544 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:44:29.794112 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.797302 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:44:29.798608 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:44:29.799100 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:44:29.801806 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.803540 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m21:44:29.804181 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e59eb0>]}
[0m21:44:29.804910 [info ] [Thread-1  ]: 10 of 21 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m21:44:29.805651 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m21:44:29.806407 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m21:44:29.807265 [info ] [Thread-1  ]: 11 of 21 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m21:44:29.807997 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.dim_actor)
[0m21:44:29.808493 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m21:44:29.813958 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m21:44:29.815059 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m21:44:29.820922 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_actor"
[0m21:44:29.821957 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:44:29.822407 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: BEGIN
[0m21:44:29.822804 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.828340 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:44:29.828852 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:44:29.829285 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."actor"
  );
  
[0m21:44:29.831140 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.001 seconds
[0m21:44:29.835058 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:44:29.835531 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m21:44:29.836647 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.841587 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:44:29.842085 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m21:44:29.843295 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.845737 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:44:29.846335 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:44:29.846864 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:44:29.848991 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.853455 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m21:44:29.854812 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:44:29.855532 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m21:44:29.858263 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.860535 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: Close
[0m21:44:29.861262 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa25d00>]}
[0m21:44:29.861957 [info ] [Thread-1  ]: 11 of 21 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m21:44:29.862650 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m21:44:29.863161 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m21:44:29.863702 [info ] [Thread-1  ]: 12 of 21 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m21:44:29.864315 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m21:44:29.864752 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m21:44:29.868513 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m21:44:29.869359 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m21:44:29.874322 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_address"
[0m21:44:29.875605 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:44:29.876039 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: BEGIN
[0m21:44:29.876435 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.881778 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:44:29.882291 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:44:29.882736 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."address"
  );
  
[0m21:44:29.885057 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:44:29.889202 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:44:29.889702 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m21:44:29.890719 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.894144 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:44:29.894568 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m21:44:29.895634 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.897737 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:44:29.898150 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:44:29.898545 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:44:29.900695 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.904071 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m21:44:29.904942 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:44:29.905349 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m21:44:29.907391 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.908883 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: Close
[0m21:44:29.909516 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa24130>]}
[0m21:44:29.910230 [info ] [Thread-1  ]: 12 of 21 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m21:44:29.911019 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m21:44:29.911703 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m21:44:29.912319 [info ] [Thread-1  ]: 13 of 21 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m21:44:29.913024 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m21:44:29.913454 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m21:44:29.918822 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m21:44:29.921081 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m21:44:29.925714 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_customer"
[0m21:44:29.926494 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:44:29.926906 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: BEGIN
[0m21:44:29.927291 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.933498 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:29.934005 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:44:29.934444 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."customer"
  );
  
[0m21:44:29.936783 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m21:44:29.940480 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:44:29.940924 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m21:44:29.941915 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.945359 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:44:29.945779 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m21:44:29.946870 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.948897 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:44:29.949303 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:44:29.949691 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:44:29.951637 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:29.954823 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m21:44:29.955873 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:44:29.956281 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m21:44:29.958479 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:29.959952 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: Close
[0m21:44:29.960569 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9ffeb0>]}
[0m21:44:29.961281 [info ] [Thread-1  ]: 13 of 21 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m21:44:29.962177 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m21:44:29.962900 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m21:44:29.963495 [info ] [Thread-1  ]: 14 of 21 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m21:44:29.964109 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m21:44:29.964550 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m21:44:29.968187 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m21:44:29.969038 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m21:44:29.974300 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film"
[0m21:44:29.975179 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:44:29.975607 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: BEGIN
[0m21:44:29.975998 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:29.981646 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:29.982150 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:44:29.982583 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film"
  );
  
[0m21:44:29.988115 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.005 seconds
[0m21:44:29.993572 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:44:29.994080 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m21:44:29.995348 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:29.999644 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:44:30.000356 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m21:44:30.002064 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.004431 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:44:30.004889 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:44:30.005285 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:44:30.007597 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:30.010879 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m21:44:30.012050 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:44:30.012552 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m21:44:30.015239 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:30.016859 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: Close
[0m21:44:30.017584 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa81040>]}
[0m21:44:30.018625 [info ] [Thread-1  ]: 14 of 21 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.05s]
[0m21:44:30.019863 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m21:44:30.020661 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m21:44:30.021422 [info ] [Thread-1  ]: 15 of 21 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m21:44:30.022206 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m21:44:30.022709 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m21:44:30.027094 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m21:44:30.028105 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m21:44:30.032758 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film_actor"
[0m21:44:30.033621 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:44:30.034052 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: BEGIN
[0m21:44:30.034448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:30.041296 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:44:30.041822 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:44:30.042286 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m21:44:30.046734 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:44:30.050857 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:44:30.051345 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m21:44:30.052411 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.056780 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:44:30.057272 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m21:44:30.058362 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.060552 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:44:30.060982 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:44:30.061385 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:44:30.063181 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:30.066141 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m21:44:30.066996 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:44:30.067407 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m21:44:30.069534 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:30.071169 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: Close
[0m21:44:30.071741 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa15cd0>]}
[0m21:44:30.072412 [info ] [Thread-1  ]: 15 of 21 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m21:44:30.073085 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m21:44:30.073616 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m21:44:30.074251 [info ] [Thread-1  ]: 16 of 21 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m21:44:30.074793 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m21:44:30.075213 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m21:44:30.080384 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m21:44:30.081458 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m21:44:30.086372 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_inventory"
[0m21:44:30.087345 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:44:30.087925 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: BEGIN
[0m21:44:30.088355 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:30.094149 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:30.094666 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:44:30.095121 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."inventory"
  );
  
[0m21:44:30.099279 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:44:30.103589 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:44:30.104434 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m21:44:30.105888 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.109439 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:44:30.109908 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m21:44:30.111131 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.113192 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:44:30.113627 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:44:30.114017 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:44:30.116162 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:30.119621 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m21:44:30.120560 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:44:30.121073 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m21:44:30.123337 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:30.124801 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: Close
[0m21:44:30.125456 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a850880>]}
[0m21:44:30.126169 [info ] [Thread-1  ]: 16 of 21 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m21:44:30.126973 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m21:44:30.127589 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m21:44:30.128183 [info ] [Thread-1  ]: 17 of 21 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:44:30.128745 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m21:44:30.129157 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m21:44:30.132696 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m21:44:30.133596 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m21:44:30.160138 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m21:44:30.161653 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:44:30.162120 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m21:44:30.162648 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:30.168860 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:30.169629 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:44:30.170510 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:44:30.173109 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m21:44:30.178756 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:44:30.184918 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:44:30.186246 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.189382 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:44:30.190184 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:44:30.190903 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:44:30.192991 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:30.196958 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:44:30.201348 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:44:30.202119 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:44:30.203760 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m21:44:30.205547 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m21:44:30.206354 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a288e20>]}
[0m21:44:30.207611 [info ] [Thread-1  ]: 17 of 21 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.08s]
[0m21:44:30.208998 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m21:44:30.209637 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m21:44:30.210392 [info ] [Thread-1  ]: 18 of 21 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m21:44:30.211009 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now model.datawarehouse.fact_payment)
[0m21:44:30.211472 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m21:44:30.215875 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m21:44:30.217206 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m21:44:30.224078 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.fact_payment"
[0m21:44:30.225022 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:44:30.225460 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: BEGIN
[0m21:44:30.225966 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:30.232727 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:44:30.233490 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:44:30.233932 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."payment"
  );
  
[0m21:44:30.248412 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.014 seconds
[0m21:44:30.255326 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:44:30.256155 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m21:44:30.257945 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.263976 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:44:30.264685 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m21:44:30.266536 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.269696 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:44:30.270445 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:44:30.271144 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:44:30.274428 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:44:30.278788 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m21:44:30.282472 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:44:30.283308 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m21:44:30.286410 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:30.288939 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: Close
[0m21:44:30.290023 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa05be0>]}
[0m21:44:30.291205 [info ] [Thread-1  ]: 18 of 21 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.08s]
[0m21:44:30.292486 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m21:44:30.293443 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m21:44:30.294544 [info ] [Thread-1  ]: 19 of 21 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m21:44:30.295667 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m21:44:30.296550 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m21:44:30.303179 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m21:44:30.304637 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m21:44:30.311057 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_rental"
[0m21:44:30.312257 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:44:30.312807 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: BEGIN
[0m21:44:30.313309 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:30.321044 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:44:30.321711 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:44:30.322151 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."rental"
  );
  
[0m21:44:30.333183 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.011 seconds
[0m21:44:30.338070 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:44:30.338903 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m21:44:30.340604 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.344516 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:44:30.345010 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m21:44:30.346138 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.348759 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:44:30.349366 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:44:30.349866 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:44:30.353443 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:44:30.358047 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m21:44:30.359640 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:44:30.360437 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m21:44:30.363172 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:30.365090 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: Close
[0m21:44:30.365974 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aad73d0>]}
[0m21:44:30.366701 [info ] [Thread-1  ]: 19 of 21 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m21:44:30.367686 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m21:44:30.368570 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m21:44:30.369249 [info ] [Thread-1  ]: 20 of 21 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m21:44:30.369837 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m21:44:30.370397 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m21:44:30.374935 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m21:44:30.376225 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m21:44:30.381309 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_staff"
[0m21:44:30.382169 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:44:30.382587 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: BEGIN
[0m21:44:30.382967 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:30.389288 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:30.389794 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:44:30.390258 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."staff"
  );
  
[0m21:44:30.396409 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m21:44:30.400516 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:44:30.401001 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m21:44:30.402274 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.405981 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:44:30.406456 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m21:44:30.407569 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:30.409773 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:44:30.410241 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:44:30.410653 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:44:30.412621 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:30.415679 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m21:44:30.416640 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:44:30.417072 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m21:44:30.420650 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m21:44:30.422316 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: Close
[0m21:44:30.422938 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9eaf10>]}
[0m21:44:30.423659 [info ] [Thread-1  ]: 20 of 21 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m21:44:30.424480 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m21:44:30.425087 [debug] [Thread-1  ]: Began running node model.datawarehouse.total_revenue
[0m21:44:30.425687 [info ] [Thread-1  ]: 21 of 21 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m21:44:30.426362 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_staff, now model.datawarehouse.total_revenue)
[0m21:44:30.426828 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.total_revenue
[0m21:44:30.430420 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.total_revenue"
[0m21:44:30.431324 [debug] [Thread-1  ]: Began executing node model.datawarehouse.total_revenue
[0m21:44:30.435606 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.total_revenue"
[0m21:44:30.436437 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:44:30.436889 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: BEGIN
[0m21:44:30.437333 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:30.443723 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:30.444245 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:44:30.444749 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    date_trunc(payment_date, month) as month_year,
    sum(amount) as total_revenue
FROM "datawarehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY 1
ORDER BY 1
  );
  
[0m21:44:30.446812 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column "month" does not exist
LINE 15:     date_trunc(payment_date, month) as month_year,
                                      ^

[0m21:44:30.447610 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: ROLLBACK
[0m21:44:30.448852 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: Close
[0m21:44:30.487276 [debug] [Thread-1  ]: Database Error in model total_revenue (models/mart/total_revenue.sql)
  column "month" does not exist
  LINE 15:     date_trunc(payment_date, month) as month_year,
                                        ^
  compiled Code at target/run/datawarehouse/models/mart/total_revenue.sql
[0m21:44:30.488270 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4e715e12-cb7f-4e43-a71d-71d5359480d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a2e8b0>]}
[0m21:44:30.489686 [error] [Thread-1  ]: 21 of 21 ERROR creating sql table model dbt_dev_mart.total_revenue ............. [[31mERROR[0m in 0.06s]
[0m21:44:30.491091 [debug] [Thread-1  ]: Finished running node model.datawarehouse.total_revenue
[0m21:44:30.493292 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:30.493977 [debug] [MainThread]: On master: BEGIN
[0m21:44:30.494587 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:44:30.502645 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m21:44:30.503325 [debug] [MainThread]: On master: COMMIT
[0m21:44:30.504025 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:30.504576 [debug] [MainThread]: On master: COMMIT
[0m21:44:30.505672 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:44:30.506333 [debug] [MainThread]: On master: Close
[0m21:44:30.506928 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:44:30.507502 [debug] [MainThread]: Connection 'model.datawarehouse.total_revenue' was properly closed.
[0m21:44:30.508190 [info ] [MainThread]: 
[0m21:44:30.508943 [info ] [MainThread]: Finished running 20 table models, 1 view model in 0 hours 0 minutes and 1.79 seconds (1.79s).
[0m21:44:30.515292 [debug] [MainThread]: Command end result
[0m21:44:30.558536 [info ] [MainThread]: 
[0m21:44:30.559123 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:44:30.559561 [info ] [MainThread]: 
[0m21:44:30.560047 [error] [MainThread]:   Database Error in model total_revenue (models/mart/total_revenue.sql)
  column "month" does not exist
  LINE 15:     date_trunc(payment_date, month) as month_year,
                                        ^
  compiled Code at target/run/datawarehouse/models/mart/total_revenue.sql
[0m21:44:30.560476 [info ] [MainThread]: 
[0m21:44:30.560926 [info ] [MainThread]: Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
[0m21:44:30.562413 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.891236, "process_user_time": 3.50828, "process_kernel_time": 0.420677, "process_mem_max_rss": "110997504", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:44:30.563055 [debug] [MainThread]: Command `dbt run` failed at 21:44:30.562951 after 2.89 seconds
[0m21:44:30.563648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bb92e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2a99d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c44310>]}
[0m21:44:30.564102 [debug] [MainThread]: Flushing usage events
[0m21:44:58.075447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10295b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10447cb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10447c880>]}


============================== 21:44:58.082991 | fd8915de-530d-4f78-bc0d-8395e62b52fd ==============================
[0m21:44:58.082991 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:44:58.083651 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:44:58.257749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047e95b0>]}
[0m21:44:58.316157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104809100>]}
[0m21:44:58.317677 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:44:58.337872 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:44:58.543857 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:44:58.544593 [debug] [MainThread]: Partial parsing: updated file: datawarehouse://models/mart/total_revenue.sql
[0m21:44:58.826775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051d9130>]}
[0m21:44:58.972947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050437c0>]}
[0m21:44:58.973799 [info ] [MainThread]: Found 21 models, 4 data tests, 9 sources, 417 macros
[0m21:44:58.974349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051f63d0>]}
[0m21:44:58.977626 [info ] [MainThread]: 
[0m21:44:58.978414 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:44:58.985751 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m21:44:59.052608 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:44:59.053103 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:44:59.053488 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:44:59.075849 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.022 seconds
[0m21:44:59.077395 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:44:59.080593 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:44:59.081077 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:44:59.081445 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:59.087820 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m21:44:59.089347 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:44:59.093414 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:44:59.093941 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:44:59.094322 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:59.100256 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m21:44:59.101634 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:44:59.104327 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:44:59.104793 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:44:59.105168 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:59.110350 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.005 seconds
[0m21:44:59.111819 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:44:59.114720 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now list_datawarehouse_dbt_dev)
[0m21:44:59.121855 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:44:59.122293 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m21:44:59.122640 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:59.127966 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:44:59.128434 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:44:59.128821 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:44:59.131791 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m21:44:59.133210 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m21:44:59.133884 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m21:44:59.134539 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now list_datawarehouse_dbt_dev_mart)
[0m21:44:59.137708 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m21:44:59.138166 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: BEGIN
[0m21:44:59.138519 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:59.143079 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:44:59.143537 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m21:44:59.143922 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_mart"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m21:44:59.146975 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:44:59.148378 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: ROLLBACK
[0m21:44:59.149164 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: Close
[0m21:44:59.149909 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev_raw)
[0m21:44:59.152784 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:44:59.153203 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m21:44:59.153529 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:59.159026 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:44:59.159484 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:44:59.159908 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:44:59.163026 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:44:59.164596 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m21:44:59.165438 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m21:44:59.166099 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev_intermediete)
[0m21:44:59.170299 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:44:59.170763 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m21:44:59.171257 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:44:59.177225 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:44:59.177668 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:44:59.178061 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m21:44:59.181208 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:44:59.184095 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m21:44:59.185077 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m21:44:59.237587 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:59.238192 [debug] [MainThread]: On master: BEGIN
[0m21:44:59.238682 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:44:59.245563 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:44:59.246126 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:59.246690 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:44:59.302836 [debug] [MainThread]: SQL status: SELECT 38 in 0.056 seconds
[0m21:44:59.305512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105736f70>]}
[0m21:44:59.306100 [debug] [MainThread]: On master: ROLLBACK
[0m21:44:59.307094 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:59.307631 [debug] [MainThread]: On master: BEGIN
[0m21:44:59.309129 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:44:59.309507 [debug] [MainThread]: On master: COMMIT
[0m21:44:59.309938 [debug] [MainThread]: Using postgres connection "master"
[0m21:44:59.310273 [debug] [MainThread]: On master: COMMIT
[0m21:44:59.311136 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:44:59.311514 [debug] [MainThread]: On master: Close
[0m21:44:59.312166 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:44:59.312674 [info ] [MainThread]: 
[0m21:44:59.315930 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m21:44:59.316543 [info ] [Thread-1  ]: 1 of 21 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:44:59.317258 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now model.datawarehouse.actor)
[0m21:44:59.317673 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m21:44:59.328568 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m21:44:59.329451 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m21:44:59.374703 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m21:44:59.375840 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:59.376362 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m21:44:59.376789 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.384172 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:44:59.401259 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:59.402173 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m21:44:59.406537 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.004 seconds
[0m21:44:59.416495 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:59.417042 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m21:44:59.418292 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.422213 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:59.422668 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:44:59.423749 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.446879 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:44:59.447367 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:59.447764 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:44:59.456749 [debug] [Thread-1  ]: SQL status: COMMIT in 0.009 seconds
[0m21:44:59.463771 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:44:59.468686 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:44:59.469125 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:44:59.471337 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:59.473985 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m21:44:59.475712 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102bfbe80>]}
[0m21:44:59.476536 [info ] [Thread-1  ]: 1 of 21 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.16s]
[0m21:44:59.477305 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m21:44:59.477829 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m21:44:59.478342 [info ] [Thread-1  ]: 2 of 21 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:44:59.479180 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m21:44:59.479614 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m21:44:59.483491 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m21:44:59.484449 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m21:44:59.489922 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m21:44:59.490812 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:59.491236 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m21:44:59.491621 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.497136 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:44:59.497640 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:59.498055 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m21:44:59.500294 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:44:59.504047 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:59.504522 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m21:44:59.505815 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.509553 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:59.510027 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:44:59.511304 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.513267 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:44:59.513672 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:59.514056 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:44:59.515793 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:59.518844 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:44:59.520204 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:44:59.520652 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:44:59.523025 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:59.524609 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m21:44:59.525169 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105744bb0>]}
[0m21:44:59.525829 [info ] [Thread-1  ]: 2 of 21 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m21:44:59.526504 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m21:44:59.527022 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m21:44:59.527557 [info ] [Thread-1  ]: 3 of 21 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:44:59.528255 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m21:44:59.528690 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m21:44:59.533547 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m21:44:59.534424 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m21:44:59.539590 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m21:44:59.540499 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:59.540916 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m21:44:59.541308 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.546708 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:44:59.547213 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:59.547624 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m21:44:59.549864 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m21:44:59.553577 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:59.554108 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m21:44:59.555136 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.558739 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:59.559237 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:44:59.560377 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.562500 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:44:59.563095 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:59.563557 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:44:59.565323 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:59.568565 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:44:59.569611 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:44:59.570072 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:44:59.572314 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:59.573919 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m21:44:59.574512 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105696850>]}
[0m21:44:59.575195 [info ] [Thread-1  ]: 3 of 21 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m21:44:59.575876 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m21:44:59.576414 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m21:44:59.577116 [info ] [Thread-1  ]: 4 of 21 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:44:59.577758 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m21:44:59.578195 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m21:44:59.581812 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m21:44:59.582671 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m21:44:59.587371 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m21:44:59.588262 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:59.588718 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m21:44:59.589121 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.596734 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:44:59.597640 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:59.598474 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m21:44:59.607895 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.009 seconds
[0m21:44:59.613960 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:59.614481 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m21:44:59.615646 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.619320 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:59.619757 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:44:59.620813 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.622937 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:44:59.623367 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:59.623916 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:44:59.626123 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:59.629255 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:44:59.630118 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:44:59.630528 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:44:59.632771 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:59.634433 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m21:44:59.635053 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10569db80>]}
[0m21:44:59.635727 [info ] [Thread-1  ]: 4 of 21 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.06s]
[0m21:44:59.636818 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m21:44:59.637666 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m21:44:59.638529 [info ] [Thread-1  ]: 5 of 21 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:44:59.639181 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m21:44:59.639621 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m21:44:59.643406 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m21:44:59.644313 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m21:44:59.649015 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m21:44:59.649848 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:59.650265 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m21:44:59.650654 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.656526 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:59.657034 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:59.657450 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m21:44:59.661751 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:44:59.665748 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:59.666193 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m21:44:59.667243 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.671372 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:59.671895 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:44:59.673093 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.675267 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:44:59.675779 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:59.676185 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:44:59.678418 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:59.681614 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:44:59.683844 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:44:59.684278 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:44:59.686326 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:59.688217 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m21:44:59.688827 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051b51c0>]}
[0m21:44:59.689533 [info ] [Thread-1  ]: 5 of 21 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m21:44:59.690976 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m21:44:59.691533 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m21:44:59.692323 [info ] [Thread-1  ]: 6 of 21 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:44:59.692993 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m21:44:59.693471 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m21:44:59.698695 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m21:44:59.699746 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m21:44:59.706652 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m21:44:59.707495 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:59.707918 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m21:44:59.708308 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.714113 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:59.714622 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:59.715121 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m21:44:59.719881 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:44:59.724618 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:59.725102 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m21:44:59.726157 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.730310 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:59.731137 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:44:59.732446 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.734843 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:44:59.735695 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:59.736515 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:44:59.738779 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:59.743300 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:44:59.744384 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:44:59.745000 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:44:59.747442 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:59.749298 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m21:44:59.749977 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051b5a90>]}
[0m21:44:59.750780 [info ] [Thread-1  ]: 6 of 21 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m21:44:59.751634 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m21:44:59.752300 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m21:44:59.752928 [info ] [Thread-1  ]: 7 of 21 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:44:59.753734 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m21:44:59.754173 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m21:44:59.758415 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m21:44:59.759684 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m21:44:59.765872 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m21:44:59.766842 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:59.767295 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m21:44:59.767691 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.773636 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:59.774145 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:59.774581 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:44:59.776314 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.001 seconds
[0m21:44:59.780270 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:59.780777 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:44:59.781810 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.785560 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:59.786114 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:44:59.787208 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.789297 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:44:59.789736 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:59.790144 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:44:59.791498 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:44:59.794458 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:44:59.795345 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:44:59.795767 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:44:59.798131 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:59.799684 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m21:44:59.800266 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10508ba00>]}
[0m21:44:59.800967 [info ] [Thread-1  ]: 7 of 21 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m21:44:59.801758 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m21:44:59.802328 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m21:44:59.803053 [info ] [Thread-1  ]: 8 of 21 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:44:59.803612 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m21:44:59.804111 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m21:44:59.807953 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m21:44:59.808980 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m21:44:59.813680 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m21:44:59.814655 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:59.815096 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m21:44:59.815489 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.821679 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:59.822195 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:59.822617 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m21:44:59.831966 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.009 seconds
[0m21:44:59.836496 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:59.837352 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:44:59.838874 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.842974 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:59.843465 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:44:59.844760 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.847781 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:44:59.848530 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:59.849027 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:44:59.851971 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:44:59.856804 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:44:59.858074 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:44:59.858666 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:44:59.862074 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m21:44:59.864355 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m21:44:59.865258 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057caf40>]}
[0m21:44:59.866087 [info ] [Thread-1  ]: 8 of 21 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m21:44:59.866982 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m21:44:59.867528 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m21:44:59.868198 [info ] [Thread-1  ]: 9 of 21 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:44:59.869009 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m21:44:59.869618 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m21:44:59.873650 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m21:44:59.874720 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m21:44:59.879319 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m21:44:59.880286 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:59.880716 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m21:44:59.881212 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.886986 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:44:59.887709 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:59.888500 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m21:44:59.902404 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.013 seconds
[0m21:44:59.907860 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:59.908331 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m21:44:59.909742 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.913564 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:59.914132 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:44:59.915609 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:44:59.918347 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:44:59.919106 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:59.919629 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:44:59.963573 [debug] [Thread-1  ]: SQL status: COMMIT in 0.043 seconds
[0m21:44:59.967022 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:44:59.967971 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:44:59.968494 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:44:59.970810 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:44:59.972442 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m21:44:59.973071 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057c8f40>]}
[0m21:44:59.973791 [info ] [Thread-1  ]: 9 of 21 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.10s]
[0m21:44:59.974509 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m21:44:59.975113 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m21:44:59.975672 [info ] [Thread-1  ]: 10 of 21 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:44:59.976310 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m21:44:59.976752 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m21:44:59.980377 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m21:44:59.981381 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m21:44:59.989145 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m21:44:59.990488 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:44:59.991200 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m21:44:59.991782 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:44:59.999929 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:45:00.000834 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:00.002318 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m21:45:00.009253 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.006 seconds
[0m21:45:00.014088 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:00.014611 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m21:45:00.016721 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.022571 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:00.023503 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:45:00.025749 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.029164 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:45:00.029806 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:00.030731 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:45:00.033188 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:00.037896 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:45:00.039818 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:00.040614 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:45:00.044025 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m21:45:00.046585 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m21:45:00.047631 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10980dfd0>]}
[0m21:45:00.048816 [info ] [Thread-1  ]: 10 of 21 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.07s]
[0m21:45:00.050071 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m21:45:00.050956 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m21:45:00.051930 [info ] [Thread-1  ]: 11 of 21 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m21:45:00.052896 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.dim_actor)
[0m21:45:00.053363 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m21:45:00.057249 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m21:45:00.058346 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m21:45:00.063048 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_actor"
[0m21:45:00.063870 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:00.064291 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: BEGIN
[0m21:45:00.064677 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.070951 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:00.071487 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:00.071926 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."actor"
  );
  
[0m21:45:00.073809 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.001 seconds
[0m21:45:00.077682 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:00.078123 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m21:45:00.079046 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.083565 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:00.083992 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m21:45:00.085015 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.087890 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:45:00.088639 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:00.089395 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:45:00.091488 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:00.095043 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m21:45:00.095982 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:00.096465 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m21:45:00.098851 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.100766 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: Close
[0m21:45:00.101479 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10980dfd0>]}
[0m21:45:00.102199 [info ] [Thread-1  ]: 11 of 21 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m21:45:00.103181 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m21:45:00.103874 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m21:45:00.104403 [info ] [Thread-1  ]: 12 of 21 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m21:45:00.105055 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m21:45:00.105484 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m21:45:00.109468 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m21:45:00.110394 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m21:45:00.114910 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_address"
[0m21:45:00.115651 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:00.116062 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: BEGIN
[0m21:45:00.116448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.122500 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:00.123116 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:00.123634 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."address"
  );
  
[0m21:45:00.125769 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:45:00.129566 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:00.130014 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m21:45:00.130982 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.134349 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:00.134797 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m21:45:00.135890 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.138819 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:45:00.139445 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:00.139906 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:45:00.141298 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:00.144319 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m21:45:00.145190 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:00.145604 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m21:45:00.147690 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.149189 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: Close
[0m21:45:00.149754 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109821c10>]}
[0m21:45:00.150425 [info ] [Thread-1  ]: 12 of 21 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.04s]
[0m21:45:00.151270 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m21:45:00.151802 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m21:45:00.152474 [info ] [Thread-1  ]: 13 of 21 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m21:45:00.153185 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m21:45:00.153629 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m21:45:00.158741 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m21:45:00.159625 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m21:45:00.164293 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_customer"
[0m21:45:00.165092 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:00.165540 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: BEGIN
[0m21:45:00.165922 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.173201 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:00.173768 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:00.174194 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."customer"
  );
  
[0m21:45:00.176475 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m21:45:00.180264 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:00.180732 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m21:45:00.181794 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.185388 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:00.186010 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m21:45:00.187572 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.189968 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:45:00.190469 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:00.190927 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:45:00.192534 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:00.195495 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m21:45:00.196467 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:00.196891 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m21:45:00.198967 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.200524 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: Close
[0m21:45:00.201117 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057caf40>]}
[0m21:45:00.201872 [info ] [Thread-1  ]: 13 of 21 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m21:45:00.202582 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m21:45:00.203205 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m21:45:00.203777 [info ] [Thread-1  ]: 14 of 21 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m21:45:00.204611 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m21:45:00.205233 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m21:45:00.210589 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m21:45:00.211739 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m21:45:00.217689 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film"
[0m21:45:00.218538 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:00.219169 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: BEGIN
[0m21:45:00.219713 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.226154 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:00.226674 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:00.227098 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film"
  );
  
[0m21:45:00.232123 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.005 seconds
[0m21:45:00.237202 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:00.237754 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m21:45:00.239257 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.243317 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:00.243820 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m21:45:00.245138 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.248188 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:45:00.248679 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:00.249095 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:45:00.251577 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:00.254876 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m21:45:00.255732 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:00.256141 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m21:45:00.258817 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.260508 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: Close
[0m21:45:00.261218 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10569b970>]}
[0m21:45:00.261916 [info ] [Thread-1  ]: 14 of 21 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m21:45:00.262751 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m21:45:00.263339 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m21:45:00.263929 [info ] [Thread-1  ]: 15 of 21 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m21:45:00.264525 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m21:45:00.264947 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m21:45:00.268563 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m21:45:00.269383 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m21:45:00.274341 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film_actor"
[0m21:45:00.275568 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:00.276011 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: BEGIN
[0m21:45:00.276443 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.281813 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:45:00.282319 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:00.282744 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m21:45:00.287166 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:45:00.291091 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:00.291555 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m21:45:00.292552 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.296090 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:00.296517 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m21:45:00.297503 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.299588 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:45:00.299998 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:00.300382 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:45:00.302288 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:00.305330 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m21:45:00.306189 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:00.306602 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m21:45:00.308933 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.310436 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: Close
[0m21:45:00.311070 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10569b970>]}
[0m21:45:00.311802 [info ] [Thread-1  ]: 15 of 21 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m21:45:00.312623 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m21:45:00.313200 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m21:45:00.313876 [info ] [Thread-1  ]: 16 of 21 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m21:45:00.314723 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m21:45:00.315260 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m21:45:00.322309 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m21:45:00.323182 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m21:45:00.328755 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_inventory"
[0m21:45:00.330104 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:00.330638 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: BEGIN
[0m21:45:00.331030 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.338102 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:00.338615 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:00.339248 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."inventory"
  );
  
[0m21:45:00.344972 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.005 seconds
[0m21:45:00.350209 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:00.350702 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m21:45:00.352186 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.357234 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:00.363116 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m21:45:00.365146 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.369852 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:45:00.370426 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:00.370922 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:45:00.373438 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:00.377671 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m21:45:00.379081 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:00.379752 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m21:45:00.382276 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.384075 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: Close
[0m21:45:00.385472 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105655520>]}
[0m21:45:00.386568 [info ] [Thread-1  ]: 16 of 21 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.07s]
[0m21:45:00.387843 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m21:45:00.388683 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m21:45:00.389371 [info ] [Thread-1  ]: 17 of 21 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:45:00.390082 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m21:45:00.390686 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m21:45:00.395584 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m21:45:00.396848 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m21:45:00.425135 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m21:45:00.426173 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:00.426609 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m21:45:00.427006 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.433006 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:00.433504 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:00.434014 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:45:00.435928 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.001 seconds
[0m21:45:00.441487 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:00.442287 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:45:00.443975 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.446892 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:45:00.447659 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:00.448372 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:45:00.450315 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:00.454545 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:45:00.458341 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:00.459064 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:45:00.460591 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m21:45:00.462830 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m21:45:00.463554 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105655520>]}
[0m21:45:00.464409 [info ] [Thread-1  ]: 17 of 21 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m21:45:00.465417 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m21:45:00.466154 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m21:45:00.467002 [info ] [Thread-1  ]: 18 of 21 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m21:45:00.467646 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now model.datawarehouse.fact_payment)
[0m21:45:00.468116 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m21:45:00.473841 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m21:45:00.474828 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m21:45:00.481013 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.fact_payment"
[0m21:45:00.481985 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:00.482444 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: BEGIN
[0m21:45:00.483078 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.490853 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:45:00.491686 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:00.492408 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."payment"
  );
  
[0m21:45:00.504951 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.012 seconds
[0m21:45:00.508932 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:00.509433 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m21:45:00.510711 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.514411 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:00.514878 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m21:45:00.516013 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.518166 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:45:00.518628 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:00.519051 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:45:00.521584 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:00.524807 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m21:45:00.527934 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:00.528942 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m21:45:00.531522 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.533918 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: Close
[0m21:45:00.534966 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e1fa0>]}
[0m21:45:00.536398 [info ] [Thread-1  ]: 18 of 21 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m21:45:00.537988 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m21:45:00.538910 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m21:45:00.540151 [info ] [Thread-1  ]: 19 of 21 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m21:45:00.541362 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m21:45:00.542146 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m21:45:00.549778 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m21:45:00.551063 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m21:45:00.559189 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_rental"
[0m21:45:00.560661 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:00.561471 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: BEGIN
[0m21:45:00.562261 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.570279 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:45:00.571131 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:00.571928 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."rental"
  );
  
[0m21:45:00.590143 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.017 seconds
[0m21:45:00.599465 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:00.600245 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m21:45:00.601783 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.609784 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:00.610537 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m21:45:00.611836 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.614177 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:45:00.614698 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:00.615306 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:45:00.618462 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:45:00.622306 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m21:45:00.623431 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:00.623952 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m21:45:00.626630 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.628164 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: Close
[0m21:45:00.628971 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e6130>]}
[0m21:45:00.629815 [info ] [Thread-1  ]: 19 of 21 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.09s]
[0m21:45:00.630716 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m21:45:00.631386 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m21:45:00.632174 [info ] [Thread-1  ]: 20 of 21 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m21:45:00.632996 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m21:45:00.633559 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m21:45:00.643192 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m21:45:00.644740 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m21:45:00.655102 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_staff"
[0m21:45:00.656146 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:00.656627 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: BEGIN
[0m21:45:00.657116 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.664249 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:00.664753 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:00.665595 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."staff"
  );
  
[0m21:45:00.672296 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m21:45:00.676519 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:00.676969 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m21:45:00.678262 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.681860 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:00.682298 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m21:45:00.683438 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:00.685608 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:45:00.686105 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:00.686839 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:45:00.688739 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:00.693615 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m21:45:00.694782 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:00.695449 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m21:45:00.698384 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:00.700329 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: Close
[0m21:45:00.701244 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10564b9d0>]}
[0m21:45:00.702553 [info ] [Thread-1  ]: 20 of 21 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.07s]
[0m21:45:00.703514 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m21:45:00.704051 [debug] [Thread-1  ]: Began running node model.datawarehouse.total_revenue
[0m21:45:00.704588 [info ] [Thread-1  ]: 21 of 21 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m21:45:00.705189 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_staff, now model.datawarehouse.total_revenue)
[0m21:45:00.705597 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.total_revenue
[0m21:45:00.709515 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.total_revenue"
[0m21:45:00.710830 [debug] [Thread-1  ]: Began executing node model.datawarehouse.total_revenue
[0m21:45:00.715659 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.total_revenue"
[0m21:45:00.716544 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:45:00.716959 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: BEGIN
[0m21:45:00.717336 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:00.724157 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:00.724672 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:45:00.725094 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    date_trunc(month, payment_date) as month_year,
    sum(amount) as total_revenue
FROM "datawarehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY 1
ORDER BY 1
  );
  
[0m21:45:00.726165 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column "month" does not exist
LINE 15:     date_trunc(month, payment_date) as month_year,
                        ^

[0m21:45:00.726625 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: ROLLBACK
[0m21:45:00.727571 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: Close
[0m21:45:00.760904 [debug] [Thread-1  ]: Database Error in model total_revenue (models/mart/total_revenue.sql)
  column "month" does not exist
  LINE 15:     date_trunc(month, payment_date) as month_year,
                          ^
  compiled Code at target/run/datawarehouse/models/mart/total_revenue.sql
[0m21:45:00.761526 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd8915de-530d-4f78-bc0d-8395e62b52fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b3130>]}
[0m21:45:00.762259 [error] [Thread-1  ]: 21 of 21 ERROR creating sql table model dbt_dev_mart.total_revenue ............. [[31mERROR[0m in 0.06s]
[0m21:45:00.762984 [debug] [Thread-1  ]: Finished running node model.datawarehouse.total_revenue
[0m21:45:00.764315 [debug] [MainThread]: Using postgres connection "master"
[0m21:45:00.764709 [debug] [MainThread]: On master: BEGIN
[0m21:45:00.765067 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:45:00.771935 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:45:00.772587 [debug] [MainThread]: On master: COMMIT
[0m21:45:00.773324 [debug] [MainThread]: Using postgres connection "master"
[0m21:45:00.773681 [debug] [MainThread]: On master: COMMIT
[0m21:45:00.774714 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:45:00.775100 [debug] [MainThread]: On master: Close
[0m21:45:00.775664 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:45:00.776050 [debug] [MainThread]: Connection 'model.datawarehouse.total_revenue' was properly closed.
[0m21:45:00.776647 [info ] [MainThread]: 
[0m21:45:00.777110 [info ] [MainThread]: Finished running 20 table models, 1 view model in 0 hours 0 minutes and 1.80 seconds (1.80s).
[0m21:45:00.781551 [debug] [MainThread]: Command end result
[0m21:45:00.829577 [info ] [MainThread]: 
[0m21:45:00.830147 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m21:45:00.830542 [info ] [MainThread]: 
[0m21:45:00.831009 [error] [MainThread]:   Database Error in model total_revenue (models/mart/total_revenue.sql)
  column "month" does not exist
  LINE 15:     date_trunc(month, payment_date) as month_year,
                          ^
  compiled Code at target/run/datawarehouse/models/mart/total_revenue.sql
[0m21:45:00.831411 [info ] [MainThread]: 
[0m21:45:00.831795 [info ] [MainThread]: Done. PASS=20 WARN=0 ERROR=1 SKIP=0 TOTAL=21
[0m21:45:00.833326 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.8427641, "process_user_time": 3.360658, "process_kernel_time": 0.322785, "process_mem_max_rss": "110743552", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:45:00.833983 [debug] [MainThread]: Command `dbt run` failed at 21:45:00.833871 after 2.84 seconds
[0m21:45:00.834442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10295b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049ba940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10523a640>]}
[0m21:45:00.834888 [debug] [MainThread]: Flushing usage events
[0m21:45:46.517274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10305b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b60f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b60c10>]}


============================== 21:45:46.532837 | d55cd2fd-e071-4ab8-91b7-7b48d92207b6 ==============================
[0m21:45:46.532837 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:45:46.533700 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:45:46.744678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eb7fa0>]}
[0m21:45:46.804825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104576eb0>]}
[0m21:45:46.806326 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:45:46.829429 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:45:47.096758 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:45:47.097751 [debug] [MainThread]: Partial parsing: updated file: datawarehouse://models/mart/total_revenue.sql
[0m21:45:47.372786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058bf130>]}
[0m21:45:47.528308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c8a60>]}
[0m21:45:47.528959 [info ] [MainThread]: Found 21 models, 4 data tests, 9 sources, 417 macros
[0m21:45:47.529415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10576e880>]}
[0m21:45:47.532148 [info ] [MainThread]: 
[0m21:45:47.532796 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:45:47.539520 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m21:45:47.614488 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:45:47.614978 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:45:47.615376 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:45:47.657832 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.042 seconds
[0m21:45:47.659463 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:45:47.662704 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:45:47.663184 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:45:47.663552 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:47.670418 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m21:45:47.672491 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:45:47.676817 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:45:47.677334 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:45:47.677737 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:47.685675 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.008 seconds
[0m21:45:47.687175 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:45:47.690493 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m21:45:47.691195 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:45:47.691632 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:47.699213 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.008 seconds
[0m21:45:47.701207 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m21:45:47.704764 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now list_datawarehouse_dbt_dev_raw)
[0m21:45:47.711779 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:45:47.712218 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m21:45:47.712565 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:47.718423 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:45:47.718883 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m21:45:47.719266 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:45:47.722379 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:45:47.724015 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m21:45:47.724965 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m21:45:47.725643 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev)
[0m21:45:47.728111 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:45:47.728536 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m21:45:47.730797 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:47.736693 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:45:47.737188 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m21:45:47.737588 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:45:47.740811 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m21:45:47.742258 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m21:45:47.743113 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m21:45:47.743888 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now list_datawarehouse_dbt_dev_mart)
[0m21:45:47.746678 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m21:45:47.747585 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: BEGIN
[0m21:45:47.747974 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:47.753650 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m21:45:47.754117 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m21:45:47.754536 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_mart"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m21:45:47.757538 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m21:45:47.758858 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: ROLLBACK
[0m21:45:47.759528 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: Close
[0m21:45:47.760166 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev_intermediete)
[0m21:45:47.762673 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:45:47.763071 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m21:45:47.763416 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:47.768671 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m21:45:47.769144 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m21:45:47.769568 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m21:45:47.772868 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:45:47.775692 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m21:45:47.776792 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m21:45:47.827155 [debug] [MainThread]: Using postgres connection "master"
[0m21:45:47.827742 [debug] [MainThread]: On master: BEGIN
[0m21:45:47.828212 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:45:47.835161 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m21:45:47.835740 [debug] [MainThread]: Using postgres connection "master"
[0m21:45:47.836316 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:45:47.847511 [debug] [MainThread]: SQL status: SELECT 38 in 0.011 seconds
[0m21:45:47.850208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e191c0>]}
[0m21:45:47.850768 [debug] [MainThread]: On master: ROLLBACK
[0m21:45:47.851631 [debug] [MainThread]: Using postgres connection "master"
[0m21:45:47.852022 [debug] [MainThread]: On master: BEGIN
[0m21:45:47.853199 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:45:47.853616 [debug] [MainThread]: On master: COMMIT
[0m21:45:47.853984 [debug] [MainThread]: Using postgres connection "master"
[0m21:45:47.854331 [debug] [MainThread]: On master: COMMIT
[0m21:45:47.855124 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:45:47.855557 [debug] [MainThread]: On master: Close
[0m21:45:47.856093 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:45:47.856614 [info ] [MainThread]: 
[0m21:45:47.859370 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m21:45:47.859998 [info ] [Thread-1  ]: 1 of 21 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:45:47.860688 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now model.datawarehouse.actor)
[0m21:45:47.861120 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m21:45:47.871967 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m21:45:47.873042 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m21:45:47.915607 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m21:45:47.916531 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:45:47.916951 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m21:45:47.917334 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:47.923900 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:47.924414 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:45:47.924846 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m21:45:47.926826 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m21:45:47.933869 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:45:47.934357 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m21:45:47.935812 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:47.939416 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:45:47.939867 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:45:47.940993 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:47.964224 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:45:47.964717 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:45:47.965122 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m21:45:47.967131 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:47.974484 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:45:47.979573 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m21:45:47.980099 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:45:47.982717 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:47.985798 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m21:45:47.987567 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058982b0>]}
[0m21:45:47.988499 [info ] [Thread-1  ]: 1 of 21 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m21:45:47.989261 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m21:45:47.989926 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m21:45:47.990673 [info ] [Thread-1  ]: 2 of 21 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:45:47.991536 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m21:45:47.992044 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m21:45:47.996314 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m21:45:47.997211 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m21:45:48.003479 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m21:45:48.004569 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:45:48.005021 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m21:45:48.005427 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.012892 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:48.013444 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:45:48.013857 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m21:45:48.016240 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m21:45:48.020196 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:45:48.020641 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m21:45:48.021772 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.025399 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:45:48.025825 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:45:48.027025 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.029140 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:45:48.029556 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:45:48.029943 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m21:45:48.031942 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:48.035061 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:45:48.036284 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m21:45:48.036761 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:45:48.039138 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.040650 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m21:45:48.041321 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea4130>]}
[0m21:45:48.042063 [info ] [Thread-1  ]: 2 of 21 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m21:45:48.042809 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m21:45:48.043456 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m21:45:48.044008 [info ] [Thread-1  ]: 3 of 21 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:45:48.044711 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m21:45:48.045158 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m21:45:48.050055 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m21:45:48.051005 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m21:45:48.056233 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m21:45:48.057139 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:45:48.057568 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m21:45:48.057963 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.064194 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.064699 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:45:48.065119 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m21:45:48.067514 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m21:45:48.071513 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:45:48.072092 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m21:45:48.073128 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.076533 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:45:48.077033 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:45:48.078198 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.080435 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:45:48.080862 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:45:48.081250 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m21:45:48.082918 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:48.086089 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:45:48.087408 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m21:45:48.087930 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:45:48.090261 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.091814 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m21:45:48.092401 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059bfc70>]}
[0m21:45:48.093071 [info ] [Thread-1  ]: 3 of 21 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m21:45:48.093745 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m21:45:48.094234 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m21:45:48.094988 [info ] [Thread-1  ]: 4 of 21 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:45:48.095548 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m21:45:48.095982 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m21:45:48.099591 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m21:45:48.100470 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m21:45:48.106003 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m21:45:48.106882 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:45:48.107309 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m21:45:48.107698 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.113561 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.114069 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:45:48.114491 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m21:45:48.120057 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.005 seconds
[0m21:45:48.124982 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:45:48.125427 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m21:45:48.126441 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.130161 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:45:48.130642 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:45:48.131714 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.133850 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:45:48.134283 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:45:48.134703 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m21:45:48.136802 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:48.139918 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:45:48.140804 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m21:45:48.141220 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:45:48.143570 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.145096 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m21:45:48.145718 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb93d0>]}
[0m21:45:48.146401 [info ] [Thread-1  ]: 4 of 21 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m21:45:48.147079 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m21:45:48.147626 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m21:45:48.148339 [info ] [Thread-1  ]: 5 of 21 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:45:48.148938 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m21:45:48.149366 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m21:45:48.153213 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m21:45:48.154075 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m21:45:48.158737 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m21:45:48.159528 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:45:48.159948 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m21:45:48.160340 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.165389 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m21:45:48.165909 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:45:48.166345 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m21:45:48.171188 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:45:48.174959 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:45:48.175431 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m21:45:48.176767 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.180765 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:45:48.181332 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:45:48.182853 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.185088 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:45:48.185609 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:45:48.186194 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m21:45:48.188925 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:48.192541 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:45:48.195244 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m21:45:48.195763 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:45:48.197991 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.199649 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m21:45:48.200286 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb93d0>]}
[0m21:45:48.200996 [info ] [Thread-1  ]: 5 of 21 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m21:45:48.202003 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m21:45:48.202659 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m21:45:48.203223 [info ] [Thread-1  ]: 6 of 21 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:45:48.203896 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m21:45:48.204383 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m21:45:48.207939 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m21:45:48.209054 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m21:45:48.214418 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m21:45:48.215704 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:45:48.216161 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m21:45:48.216651 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.223102 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.223614 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:45:48.224033 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m21:45:48.227963 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.003 seconds
[0m21:45:48.232947 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:45:48.233608 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m21:45:48.235036 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.240741 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:45:48.241546 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:45:48.243127 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.246988 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:45:48.247834 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:45:48.248697 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m21:45:48.250867 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:48.254798 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:45:48.256140 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m21:45:48.256738 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:45:48.259056 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.260680 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m21:45:48.261375 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e99370>]}
[0m21:45:48.262075 [info ] [Thread-1  ]: 6 of 21 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m21:45:48.262881 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m21:45:48.263458 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m21:45:48.263984 [info ] [Thread-1  ]: 7 of 21 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:45:48.264747 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m21:45:48.265175 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m21:45:48.268665 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m21:45:48.269491 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m21:45:48.276081 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m21:45:48.276954 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:45:48.277381 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m21:45:48.277772 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.284168 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.285139 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:45:48.285781 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:45:48.288618 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.002 seconds
[0m21:45:48.294611 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:45:48.295458 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:45:48.297078 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.301921 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:45:48.302440 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:45:48.303604 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.306075 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:45:48.306571 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:45:48.307185 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m21:45:48.309209 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:48.312770 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:45:48.313808 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m21:45:48.314307 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:45:48.317048 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.318710 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m21:45:48.319393 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105730f70>]}
[0m21:45:48.320125 [info ] [Thread-1  ]: 7 of 21 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m21:45:48.320836 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m21:45:48.321398 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m21:45:48.321942 [info ] [Thread-1  ]: 8 of 21 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:45:48.322615 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m21:45:48.323098 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m21:45:48.326808 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m21:45:48.327922 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m21:45:48.333254 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m21:45:48.334105 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:45:48.334563 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m21:45:48.334993 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.342417 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:48.342936 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:45:48.343409 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m21:45:48.356983 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.013 seconds
[0m21:45:48.363350 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:45:48.363996 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:45:48.365533 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.371884 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:45:48.372669 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:45:48.373925 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.376388 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:45:48.376930 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:45:48.377355 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m21:45:48.380472 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:48.387519 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:45:48.389268 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m21:45:48.390054 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:45:48.393261 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.395658 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m21:45:48.396627 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eb1ee0>]}
[0m21:45:48.397839 [info ] [Thread-1  ]: 8 of 21 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.07s]
[0m21:45:48.398913 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m21:45:48.399501 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m21:45:48.400159 [info ] [Thread-1  ]: 9 of 21 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:45:48.400858 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m21:45:48.401312 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m21:45:48.405846 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m21:45:48.407249 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m21:45:48.412220 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m21:45:48.413262 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:45:48.413821 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m21:45:48.414294 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.421451 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:48.421962 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:45:48.422458 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m21:45:48.435707 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.013 seconds
[0m21:45:48.442469 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:45:48.443254 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m21:45:48.445237 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.450664 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:45:48.451321 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:45:48.452844 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.455252 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:45:48.455784 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:45:48.456207 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m21:45:48.459044 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:48.462145 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:45:48.463054 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m21:45:48.463470 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:45:48.465762 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.467247 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m21:45:48.467864 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea9ee0>]}
[0m21:45:48.468553 [info ] [Thread-1  ]: 9 of 21 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m21:45:48.469228 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m21:45:48.469763 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m21:45:48.470296 [info ] [Thread-1  ]: 10 of 21 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:45:48.471000 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m21:45:48.471436 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m21:45:48.475133 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m21:45:48.476093 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m21:45:48.482215 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m21:45:48.483080 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:48.483498 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m21:45:48.483882 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.491550 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:48.492176 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:48.492693 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m21:45:48.496960 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m21:45:48.502154 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:48.502862 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m21:45:48.504165 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.507813 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:48.508263 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:45:48.509306 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.511439 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:45:48.511892 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:48.512292 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m21:45:48.513735 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:48.516624 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:45:48.517565 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m21:45:48.517995 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:45:48.520303 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.521821 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m21:45:48.522426 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d81b20>]}
[0m21:45:48.523104 [info ] [Thread-1  ]: 10 of 21 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m21:45:48.523949 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m21:45:48.524481 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m21:45:48.525084 [info ] [Thread-1  ]: 11 of 21 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m21:45:48.525657 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.dim_actor)
[0m21:45:48.526085 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m21:45:48.529723 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m21:45:48.530734 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m21:45:48.535368 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_actor"
[0m21:45:48.536307 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:48.536749 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: BEGIN
[0m21:45:48.537256 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.543026 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.543533 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:48.543957 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."actor"
  );
  
[0m21:45:48.545759 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.001 seconds
[0m21:45:48.549504 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:48.550035 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m21:45:48.551230 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.557223 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:48.557722 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m21:45:48.558851 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.560939 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:45:48.561368 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:48.561765 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m21:45:48.563346 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:48.566356 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m21:45:48.567216 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m21:45:48.567639 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m21:45:48.570209 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.571820 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: Close
[0m21:45:48.572460 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d81b20>]}
[0m21:45:48.573292 [info ] [Thread-1  ]: 11 of 21 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m21:45:48.574275 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m21:45:48.574870 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m21:45:48.575786 [info ] [Thread-1  ]: 12 of 21 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m21:45:48.576620 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m21:45:48.577071 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m21:45:48.581165 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m21:45:48.582203 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m21:45:48.588357 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_address"
[0m21:45:48.589248 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:48.589749 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: BEGIN
[0m21:45:48.590232 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.596825 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.597386 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:48.597923 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."address"
  );
  
[0m21:45:48.601024 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.003 seconds
[0m21:45:48.606755 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:48.607242 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m21:45:48.608365 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.611834 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:48.612300 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m21:45:48.613369 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.615597 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:45:48.616096 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:48.616505 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m21:45:48.618013 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:48.621359 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m21:45:48.622563 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m21:45:48.623418 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m21:45:48.625695 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.627580 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: Close
[0m21:45:48.628562 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ee9d00>]}
[0m21:45:48.629638 [info ] [Thread-1  ]: 12 of 21 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m21:45:48.630923 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m21:45:48.631522 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m21:45:48.632096 [info ] [Thread-1  ]: 13 of 21 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m21:45:48.632730 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m21:45:48.633175 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m21:45:48.639856 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m21:45:48.641170 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m21:45:48.648480 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_customer"
[0m21:45:48.649463 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:48.650075 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: BEGIN
[0m21:45:48.650489 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.658462 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:45:48.658979 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:48.659506 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."customer"
  );
  
[0m21:45:48.661973 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m21:45:48.665714 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:48.666140 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m21:45:48.667139 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.671179 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:48.671706 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m21:45:48.673103 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.675186 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:45:48.675598 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:48.676025 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m21:45:48.678042 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:48.681244 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m21:45:48.682191 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m21:45:48.682593 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m21:45:48.684870 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.686612 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: Close
[0m21:45:48.687471 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e9c700>]}
[0m21:45:48.688761 [info ] [Thread-1  ]: 13 of 21 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m21:45:48.690159 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m21:45:48.691030 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m21:45:48.691822 [info ] [Thread-1  ]: 14 of 21 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m21:45:48.692831 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m21:45:48.693628 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m21:45:48.698442 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m21:45:48.699608 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m21:45:48.705488 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film"
[0m21:45:48.706372 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:48.706797 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: BEGIN
[0m21:45:48.707226 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.713247 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.713763 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:48.714190 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film"
  );
  
[0m21:45:48.719620 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.005 seconds
[0m21:45:48.725085 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:48.725585 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m21:45:48.726837 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.730435 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:48.731017 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m21:45:48.732273 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.734602 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:45:48.735117 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:48.735546 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m21:45:48.737611 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:48.740760 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m21:45:48.741633 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m21:45:48.742049 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m21:45:48.744535 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.746087 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: Close
[0m21:45:48.746767 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f45ac0>]}
[0m21:45:48.747501 [info ] [Thread-1  ]: 14 of 21 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.05s]
[0m21:45:48.748220 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m21:45:48.748888 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m21:45:48.749681 [info ] [Thread-1  ]: 15 of 21 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m21:45:48.750242 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m21:45:48.750699 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m21:45:48.754778 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m21:45:48.755650 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m21:45:48.760494 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film_actor"
[0m21:45:48.761369 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:48.761814 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: BEGIN
[0m21:45:48.762212 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.767952 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.768602 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:48.769336 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m21:45:48.774669 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.005 seconds
[0m21:45:48.778869 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:48.779371 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m21:45:48.780563 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.784640 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:48.785248 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m21:45:48.787223 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.789932 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:45:48.790600 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:48.791289 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m21:45:48.793561 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:48.796923 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m21:45:48.798107 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m21:45:48.798658 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m21:45:48.801174 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.803131 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: Close
[0m21:45:48.804182 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f45370>]}
[0m21:45:48.805065 [info ] [Thread-1  ]: 15 of 21 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m21:45:48.805948 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m21:45:48.806645 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m21:45:48.807471 [info ] [Thread-1  ]: 16 of 21 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m21:45:48.808361 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m21:45:48.808893 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m21:45:48.816226 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m21:45:48.817160 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m21:45:48.822780 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_inventory"
[0m21:45:48.823796 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:48.824394 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: BEGIN
[0m21:45:48.824875 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.831320 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:48.831853 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:48.832296 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."inventory"
  );
  
[0m21:45:48.837449 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.005 seconds
[0m21:45:48.845391 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:48.846197 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m21:45:48.848379 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.854535 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:48.855175 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m21:45:48.856627 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.858895 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:45:48.859612 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:48.860178 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m21:45:48.862044 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:48.865337 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m21:45:48.866956 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m21:45:48.867448 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m21:45:48.869994 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:48.871758 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: Close
[0m21:45:48.872405 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045900a0>]}
[0m21:45:48.873118 [info ] [Thread-1  ]: 16 of 21 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m21:45:48.873952 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m21:45:48.874804 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m21:45:48.875606 [info ] [Thread-1  ]: 17 of 21 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:45:48.876495 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m21:45:48.877104 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m21:45:48.883773 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m21:45:48.885566 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m21:45:48.921268 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m21:45:48.922590 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:48.923328 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m21:45:48.924136 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.932373 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:45:48.933278 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:48.933816 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:45:48.937883 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:45:48.944381 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:48.945186 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:45:48.946988 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:48.950049 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:45:48.950926 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:48.951690 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m21:45:48.953905 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:48.957947 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:45:48.961713 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m21:45:48.962240 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:45:48.963485 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m21:45:48.965096 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m21:45:48.965782 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104576ac0>]}
[0m21:45:48.966607 [info ] [Thread-1  ]: 17 of 21 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.09s]
[0m21:45:48.967725 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m21:45:48.968692 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m21:45:48.969515 [info ] [Thread-1  ]: 18 of 21 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m21:45:48.970334 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now model.datawarehouse.fact_payment)
[0m21:45:48.971101 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m21:45:48.977022 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m21:45:48.978143 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m21:45:48.983812 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.fact_payment"
[0m21:45:48.984785 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:48.985454 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: BEGIN
[0m21:45:48.986187 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:48.993845 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m21:45:48.994668 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:48.995500 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."payment"
  );
  
[0m21:45:49.007755 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.012 seconds
[0m21:45:49.012418 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:49.012937 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m21:45:49.014280 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:49.018630 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:49.019303 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m21:45:49.020512 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:49.022697 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:45:49.023170 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:49.023570 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m21:45:49.025281 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m21:45:49.028791 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m21:45:49.031195 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m21:45:49.031694 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m21:45:49.034019 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:49.035725 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: Close
[0m21:45:49.036590 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f19a30>]}
[0m21:45:49.037866 [info ] [Thread-1  ]: 18 of 21 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m21:45:49.038878 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m21:45:49.039430 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m21:45:49.040201 [info ] [Thread-1  ]: 19 of 21 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m21:45:49.040967 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m21:45:49.041432 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m21:45:49.046287 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m21:45:49.047844 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m21:45:49.053972 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_rental"
[0m21:45:49.054882 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:49.055359 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: BEGIN
[0m21:45:49.055841 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:49.062536 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:49.063338 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:49.064103 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."rental"
  );
  
[0m21:45:49.077722 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.013 seconds
[0m21:45:49.081883 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:49.082528 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m21:45:49.083991 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:49.088895 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:49.089634 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m21:45:49.091227 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:49.094477 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:45:49.095097 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:49.095578 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m21:45:49.099089 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m21:45:49.103452 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m21:45:49.104779 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m21:45:49.105566 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m21:45:49.108466 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:49.110236 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: Close
[0m21:45:49.110841 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f9e430>]}
[0m21:45:49.111641 [info ] [Thread-1  ]: 19 of 21 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m21:45:49.112368 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m21:45:49.112916 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m21:45:49.113582 [info ] [Thread-1  ]: 20 of 21 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m21:45:49.114338 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m21:45:49.114768 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m21:45:49.119446 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m21:45:49.120522 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m21:45:49.125304 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_staff"
[0m21:45:49.126186 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:49.126619 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: BEGIN
[0m21:45:49.127011 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:49.132784 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m21:45:49.133297 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:49.133786 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."staff"
  );
  
[0m21:45:49.141426 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.005 seconds
[0m21:45:49.146665 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:49.147370 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m21:45:49.149054 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:49.156145 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:49.157006 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m21:45:49.159464 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.002 seconds
[0m21:45:49.163594 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:45:49.164415 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:49.165180 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m21:45:49.167966 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:49.173739 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m21:45:49.175598 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m21:45:49.176407 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m21:45:49.179558 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m21:45:49.181522 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: Close
[0m21:45:49.182230 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f2e640>]}
[0m21:45:49.183411 [info ] [Thread-1  ]: 20 of 21 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.07s]
[0m21:45:49.184600 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m21:45:49.185496 [debug] [Thread-1  ]: Began running node model.datawarehouse.total_revenue
[0m21:45:49.186460 [info ] [Thread-1  ]: 21 of 21 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m21:45:49.187412 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_staff, now model.datawarehouse.total_revenue)
[0m21:45:49.188213 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.total_revenue
[0m21:45:49.195202 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.total_revenue"
[0m21:45:49.196538 [debug] [Thread-1  ]: Began executing node model.datawarehouse.total_revenue
[0m21:45:49.205050 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.total_revenue"
[0m21:45:49.206136 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:45:49.206826 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: BEGIN
[0m21:45:49.207340 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:49.214055 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m21:45:49.214778 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:45:49.215502 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    date_trunc('month', payment_date) as month_year,
    sum(amount) as total_revenue
FROM "datawarehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY 1
ORDER BY 1
  );
  
[0m21:45:49.229665 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.013 seconds
[0m21:45:49.234416 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:45:49.235272 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
alter table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m21:45:49.237177 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:45:49.240955 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: COMMIT
[0m21:45:49.241745 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:45:49.266155 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: COMMIT
[0m21:45:49.269713 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m21:45:49.276844 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m21:45:49.281724 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m21:45:49.282944 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
drop table if exists "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m21:45:49.284429 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m21:45:49.287320 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: Close
[0m21:45:49.288430 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd55cd2fd-e071-4ab8-91b7-7b48d92207b6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f2e640>]}
[0m21:45:49.289702 [info ] [Thread-1  ]: 21 of 21 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 4[0m in 0.10s]
[0m21:45:49.291227 [debug] [Thread-1  ]: Finished running node model.datawarehouse.total_revenue
[0m21:45:49.293267 [debug] [MainThread]: Using postgres connection "master"
[0m21:45:49.293959 [debug] [MainThread]: On master: BEGIN
[0m21:45:49.294594 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:45:49.303132 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m21:45:49.303856 [debug] [MainThread]: On master: COMMIT
[0m21:45:49.304476 [debug] [MainThread]: Using postgres connection "master"
[0m21:45:49.305088 [debug] [MainThread]: On master: COMMIT
[0m21:45:49.306498 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:45:49.308500 [debug] [MainThread]: On master: Close
[0m21:45:49.309504 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:45:49.310152 [debug] [MainThread]: Connection 'model.datawarehouse.total_revenue' was properly closed.
[0m21:45:49.311036 [info ] [MainThread]: 
[0m21:45:49.311938 [info ] [MainThread]: Finished running 20 table models, 1 view model in 0 hours 0 minutes and 1.78 seconds (1.78s).
[0m21:45:49.318679 [debug] [MainThread]: Command end result
[0m21:45:49.387183 [info ] [MainThread]: 
[0m21:45:49.388551 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:45:49.389596 [info ] [MainThread]: 
[0m21:45:49.393677 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
[0m21:45:49.399561 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.9779844, "process_user_time": 3.64694, "process_kernel_time": 0.496202, "process_mem_max_rss": "110661632", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:45:49.400786 [debug] [MainThread]: Command `dbt run` succeeded at 21:45:49.400590 after 2.98 seconds
[0m21:45:49.401928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10305b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c8a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050fd3a0>]}
[0m21:45:49.403404 [debug] [MainThread]: Flushing usage events
[0m22:06:44.094130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10919b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aca0bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aca08b0>]}


============================== 22:06:44.105768 | 933ec859-4888-46be-86a4-640e1312a973 ==============================
[0m22:06:44.105768 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:06:44.106626 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:06:44.382761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10affd520>]}
[0m22:06:44.442036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0b18e0>]}
[0m22:06:44.443576 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:06:44.463927 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:06:44.688341 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m22:06:44.689017 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/mart/actor_most_roles_play.sql
[0m22:06:44.689427 [debug] [MainThread]: Partial parsing: added file: datawarehouse://models/mart/best_selling_film.sql
[0m22:06:44.966475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba37fd0>]}
[0m22:06:45.119928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b86cca0>]}
[0m22:06:45.120701 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m22:06:45.121212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ba36ac0>]}
[0m22:06:45.124436 [info ] [MainThread]: 
[0m22:06:45.125227 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:06:45.134116 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m22:06:45.209567 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:06:45.210088 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:06:45.210521 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:06:45.251032 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.040 seconds
[0m22:06:45.252647 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:06:45.255618 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:06:45.256109 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:06:45.256464 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:06:45.261791 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.005 seconds
[0m22:06:45.263168 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:06:45.265993 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:06:45.266531 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:06:45.266895 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:06:45.272065 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.005 seconds
[0m22:06:45.273462 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:06:45.276273 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:06:45.276841 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:06:45.277203 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:06:45.282771 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m22:06:45.284239 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:06:45.287104 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now list_datawarehouse_dbt_dev_raw)
[0m22:06:45.294051 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m22:06:45.294450 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m22:06:45.294786 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:06:45.301632 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:06:45.302089 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m22:06:45.302473 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:06:45.305995 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:06:45.307870 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m22:06:45.308908 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m22:06:45.309798 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev_intermediete)
[0m22:06:45.312433 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m22:06:45.314650 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m22:06:45.315081 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:06:45.320868 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:06:45.321322 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m22:06:45.321714 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m22:06:45.325274 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:06:45.326825 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m22:06:45.327835 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m22:06:45.328724 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now list_datawarehouse_dbt_dev_mart)
[0m22:06:45.334101 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m22:06:45.334533 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: BEGIN
[0m22:06:45.334879 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:06:45.340770 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:06:45.341410 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m22:06:45.342145 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_mart"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:06:45.346058 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m22:06:45.347688 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: ROLLBACK
[0m22:06:45.348618 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: Close
[0m22:06:45.349285 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev)
[0m22:06:45.395952 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m22:06:45.396602 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m22:06:45.397117 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:06:45.404357 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:06:45.405221 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m22:06:45.406117 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:06:45.410139 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:06:45.411895 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m22:06:45.412797 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m22:06:45.420829 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:45.421341 [debug] [MainThread]: On master: BEGIN
[0m22:06:45.421730 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:06:45.427503 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m22:06:45.427985 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:45.428569 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:06:45.438081 [debug] [MainThread]: SQL status: SELECT 38 in 0.009 seconds
[0m22:06:45.440640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be4a550>]}
[0m22:06:45.441127 [debug] [MainThread]: On master: ROLLBACK
[0m22:06:45.441903 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:45.442274 [debug] [MainThread]: On master: BEGIN
[0m22:06:45.443331 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:06:45.443722 [debug] [MainThread]: On master: COMMIT
[0m22:06:45.444078 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:45.444429 [debug] [MainThread]: On master: COMMIT
[0m22:06:45.445116 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:06:45.445492 [debug] [MainThread]: On master: Close
[0m22:06:45.446002 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:06:45.446436 [info ] [MainThread]: 
[0m22:06:45.449149 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m22:06:45.449759 [info ] [Thread-1  ]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:06:45.450299 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now model.datawarehouse.actor)
[0m22:06:45.450718 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m22:06:45.461716 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m22:06:45.463047 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m22:06:45.507061 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m22:06:45.508075 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:06:45.508504 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m22:06:45.508886 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:45.516208 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:06:45.516722 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:06:45.517174 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m22:06:45.519892 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m22:06:45.527807 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:06:45.528290 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m22:06:45.529383 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.534112 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:06:45.534562 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:06:45.535770 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.558318 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m22:06:45.559131 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:06:45.559736 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m22:06:45.561679 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:45.568872 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:06:45.574399 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:06:45.574901 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:06:45.576978 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:45.579624 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m22:06:45.581397 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b195dc0>]}
[0m22:06:45.582212 [info ] [Thread-1  ]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m22:06:45.582932 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m22:06:45.583425 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m22:06:45.584057 [info ] [Thread-1  ]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:06:45.584793 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m22:06:45.585241 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m22:06:45.590322 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m22:06:45.591332 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m22:06:45.598204 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m22:06:45.599154 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:06:45.599574 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m22:06:45.599965 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:45.608459 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:06:45.608986 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:06:45.609606 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m22:06:45.613555 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.003 seconds
[0m22:06:45.618464 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:06:45.618955 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m22:06:45.619924 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.623897 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:06:45.624402 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:06:45.625489 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.627777 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m22:06:45.628250 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:06:45.628653 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m22:06:45.630554 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:45.635457 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:06:45.636461 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:06:45.636880 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:06:45.638966 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:45.640487 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m22:06:45.641115 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bee0730>]}
[0m22:06:45.641830 [info ] [Thread-1  ]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m22:06:45.642514 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m22:06:45.643095 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m22:06:45.643791 [info ] [Thread-1  ]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:06:45.644333 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m22:06:45.644751 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m22:06:45.648245 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m22:06:45.649821 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m22:06:45.654629 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m22:06:45.655592 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:06:45.656049 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m22:06:45.656444 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:45.662684 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:06:45.663192 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:06:45.663621 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m22:06:45.666019 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m22:06:45.670381 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:06:45.671184 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m22:06:45.673066 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.677010 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:06:45.677481 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:06:45.678638 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.680765 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m22:06:45.681222 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:06:45.681625 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m22:06:45.683117 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:45.686201 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:06:45.687072 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:06:45.687542 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:06:45.689452 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m22:06:45.690967 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m22:06:45.691538 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0eda90>]}
[0m22:06:45.692215 [info ] [Thread-1  ]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m22:06:45.692889 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m22:06:45.693416 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m22:06:45.693943 [info ] [Thread-1  ]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:06:45.694554 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m22:06:45.695084 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m22:06:45.698618 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m22:06:45.699413 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m22:06:45.706715 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m22:06:45.707607 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:06:45.708022 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m22:06:45.708407 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:45.713937 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:06:45.714437 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:06:45.714851 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m22:06:45.721126 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.006 seconds
[0m22:06:45.725379 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:06:45.725855 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m22:06:45.726926 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.730472 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:06:45.730940 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:06:45.732077 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.734454 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m22:06:45.735061 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:06:45.735492 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m22:06:45.737094 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:45.740062 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:06:45.740989 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:06:45.741444 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:06:45.743919 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:45.745602 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m22:06:45.746539 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b899a90>]}
[0m22:06:45.747619 [info ] [Thread-1  ]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m22:06:45.748838 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m22:06:45.749519 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m22:06:45.750417 [info ] [Thread-1  ]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:06:45.751400 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m22:06:45.752000 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m22:06:45.757130 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m22:06:45.758095 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m22:06:45.762631 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m22:06:45.763489 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:06:45.763915 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m22:06:45.764302 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:45.769909 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:06:45.770439 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:06:45.770937 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m22:06:45.776432 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.005 seconds
[0m22:06:45.781152 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:06:45.781649 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m22:06:45.782726 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.788628 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:06:45.789335 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:06:45.790514 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.792705 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m22:06:45.793159 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:06:45.793561 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m22:06:45.795674 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:06:45.798797 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:06:45.799754 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:06:45.800224 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:06:45.802301 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:45.804050 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m22:06:45.804797 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b899a90>]}
[0m22:06:45.805673 [info ] [Thread-1  ]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m22:06:45.806528 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m22:06:45.807069 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m22:06:45.807617 [info ] [Thread-1  ]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:06:45.808449 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m22:06:45.808877 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m22:06:45.812606 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m22:06:45.813594 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m22:06:45.818100 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m22:06:45.818913 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:06:45.819329 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m22:06:45.819721 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:45.827689 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:06:45.828351 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:06:45.828886 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m22:06:45.834551 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.005 seconds
[0m22:06:45.840170 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:06:45.840675 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m22:06:45.842005 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.845811 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:06:45.846310 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:06:45.847497 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.849889 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m22:06:45.850346 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:06:45.850741 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m22:06:45.852665 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:45.856132 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:06:45.857150 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:06:45.857601 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:06:45.859932 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:45.861499 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m22:06:45.862233 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0eda90>]}
[0m22:06:45.863074 [info ] [Thread-1  ]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m22:06:45.863887 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m22:06:45.864610 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m22:06:45.865149 [info ] [Thread-1  ]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:06:45.866097 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m22:06:45.866520 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m22:06:45.870027 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m22:06:45.871109 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m22:06:45.879695 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m22:06:45.881058 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:06:45.881771 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m22:06:45.882436 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:45.891137 [debug] [Thread-1  ]: SQL status: BEGIN in 0.009 seconds
[0m22:06:45.891675 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:06:45.892120 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:06:45.894363 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.002 seconds
[0m22:06:45.898251 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:06:45.898783 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:06:45.900130 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.905319 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:06:45.906160 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:06:45.907826 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.911048 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m22:06:45.911563 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:06:45.912124 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m22:06:45.914311 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:06:45.918596 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:06:45.919595 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:06:45.920030 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:06:45.923451 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m22:06:45.926063 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m22:06:45.927112 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0eda90>]}
[0m22:06:45.928332 [info ] [Thread-1  ]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m22:06:45.929673 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m22:06:45.930582 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m22:06:45.931528 [info ] [Thread-1  ]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:06:45.932378 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m22:06:45.932951 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m22:06:45.937406 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m22:06:45.938887 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m22:06:45.944814 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m22:06:45.945790 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:06:45.946233 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m22:06:45.946611 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:45.954428 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:06:45.954978 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:06:45.955559 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m22:06:45.964745 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.009 seconds
[0m22:06:45.968824 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:06:45.969471 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:06:45.970766 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.976034 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:06:45.976671 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:06:45.977999 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:45.982608 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m22:06:45.983550 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:06:45.984288 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m22:06:45.988937 [debug] [Thread-1  ]: SQL status: COMMIT in 0.004 seconds
[0m22:06:45.993630 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:06:45.994583 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:06:45.995218 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:06:45.998003 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:45.999605 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m22:06:46.000324 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0eda90>]}
[0m22:06:46.001104 [info ] [Thread-1  ]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.07s]
[0m22:06:46.001860 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m22:06:46.002547 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m22:06:46.003100 [info ] [Thread-1  ]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:06:46.003951 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m22:06:46.004385 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m22:06:46.008619 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m22:06:46.009956 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m22:06:46.015381 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m22:06:46.016346 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:06:46.016781 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m22:06:46.017172 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.024732 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:06:46.025543 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:06:46.026323 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m22:06:46.041487 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.014 seconds
[0m22:06:46.045877 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:06:46.046408 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m22:06:46.047569 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.051557 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:06:46.052035 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:06:46.053288 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.055673 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m22:06:46.056134 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:06:46.056694 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m22:06:46.059948 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m22:06:46.065137 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:06:46.066966 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:06:46.067694 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:06:46.070521 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.072191 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m22:06:46.073008 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0eda90>]}
[0m22:06:46.074156 [info ] [Thread-1  ]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m22:06:46.075336 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m22:06:46.076161 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m22:06:46.077337 [info ] [Thread-1  ]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:06:46.078278 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m22:06:46.078745 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m22:06:46.085347 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m22:06:46.086494 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m22:06:46.093773 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m22:06:46.094725 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:06:46.095148 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m22:06:46.095602 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.102627 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:06:46.103120 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:06:46.103795 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m22:06:46.108915 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m22:06:46.112821 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:06:46.113447 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m22:06:46.114668 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.118348 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:06:46.118807 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:06:46.120070 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.122824 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m22:06:46.123353 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:06:46.123766 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m22:06:46.125939 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:06:46.129331 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:06:46.130329 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:06:46.130797 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:06:46.133685 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.135578 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m22:06:46.136549 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0eda90>]}
[0m22:06:46.137656 [info ] [Thread-1  ]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m22:06:46.138782 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m22:06:46.139360 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m22:06:46.140181 [info ] [Thread-1  ]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m22:06:46.140980 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.dim_actor)
[0m22:06:46.141573 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m22:06:46.145527 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m22:06:46.146874 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m22:06:46.151542 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_actor"
[0m22:06:46.152457 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:06:46.152950 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: BEGIN
[0m22:06:46.153393 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.160174 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:06:46.160675 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:06:46.161088 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."actor"
  );
  
[0m22:06:46.163152 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m22:06:46.168219 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:06:46.168698 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m22:06:46.169815 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.173927 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:06:46.174426 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m22:06:46.175582 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.177984 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m22:06:46.178479 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:06:46.178892 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m22:06:46.180490 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.183677 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m22:06:46.184942 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:06:46.185405 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m22:06:46.187693 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.189631 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: Close
[0m22:06:46.190332 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11003cdc0>]}
[0m22:06:46.191507 [info ] [Thread-1  ]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m22:06:46.192793 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m22:06:46.193372 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m22:06:46.194023 [info ] [Thread-1  ]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m22:06:46.194794 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m22:06:46.195419 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m22:06:46.199916 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m22:06:46.201009 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m22:06:46.206738 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_address"
[0m22:06:46.208038 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:06:46.208650 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: BEGIN
[0m22:06:46.209056 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.214442 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:06:46.214944 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:06:46.215364 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."address"
  );
  
[0m22:06:46.217436 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m22:06:46.221522 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:06:46.222036 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m22:06:46.223075 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.227169 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:06:46.227715 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m22:06:46.228853 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.231062 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m22:06:46.231618 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:06:46.232095 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m22:06:46.233826 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.237118 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m22:06:46.239364 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:06:46.239870 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m22:06:46.241837 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.243309 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: Close
[0m22:06:46.243941 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be57eb0>]}
[0m22:06:46.244602 [info ] [Thread-1  ]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m22:06:46.245266 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m22:06:46.245770 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m22:06:46.246389 [info ] [Thread-1  ]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m22:06:46.246929 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m22:06:46.247362 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m22:06:46.251015 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m22:06:46.251842 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m22:06:46.257023 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_customer"
[0m22:06:46.258367 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:06:46.258805 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: BEGIN
[0m22:06:46.259197 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.264510 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:06:46.265014 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:06:46.265435 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."customer"
  );
  
[0m22:06:46.267525 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m22:06:46.271398 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:06:46.271844 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m22:06:46.272812 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.276275 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:06:46.276706 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m22:06:46.277620 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m22:06:46.279603 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m22:06:46.280010 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:06:46.280391 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m22:06:46.281917 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.284901 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m22:06:46.285755 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:06:46.286162 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m22:06:46.288334 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.289821 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: Close
[0m22:06:46.290402 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11008a130>]}
[0m22:06:46.291077 [info ] [Thread-1  ]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.04s]
[0m22:06:46.291916 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m22:06:46.292461 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m22:06:46.293020 [info ] [Thread-1  ]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m22:06:46.293697 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m22:06:46.294114 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m22:06:46.297668 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m22:06:46.298578 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m22:06:46.303095 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film"
[0m22:06:46.303973 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:06:46.304409 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: BEGIN
[0m22:06:46.304802 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.310543 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:06:46.311043 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:06:46.311466 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film"
  );
  
[0m22:06:46.316565 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.005 seconds
[0m22:06:46.321857 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:06:46.322559 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m22:06:46.324037 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.328197 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:06:46.328790 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m22:06:46.329943 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.332179 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m22:06:46.332701 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:06:46.333232 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m22:06:46.335037 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.338517 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m22:06:46.339514 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:06:46.339936 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m22:06:46.342527 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.344056 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: Close
[0m22:06:46.344643 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100824f0>]}
[0m22:06:46.345388 [info ] [Thread-1  ]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.05s]
[0m22:06:46.346184 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m22:06:46.346793 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m22:06:46.347339 [info ] [Thread-1  ]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m22:06:46.347967 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m22:06:46.348414 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m22:06:46.352019 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m22:06:46.353058 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m22:06:46.360010 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film_actor"
[0m22:06:46.361263 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:06:46.361776 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: BEGIN
[0m22:06:46.362239 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.368658 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:06:46.369161 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:06:46.369587 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m22:06:46.374947 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.005 seconds
[0m22:06:46.379683 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:06:46.380191 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m22:06:46.381551 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.386020 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:06:46.386550 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m22:06:46.388005 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.390077 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m22:06:46.390505 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:06:46.390897 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m22:06:46.392670 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.396951 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m22:06:46.397823 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:06:46.398241 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m22:06:46.400173 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.401640 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: Close
[0m22:06:46.402300 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100365e0>]}
[0m22:06:46.403013 [info ] [Thread-1  ]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m22:06:46.403920 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m22:06:46.404698 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m22:06:46.405339 [info ] [Thread-1  ]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m22:06:46.406181 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m22:06:46.406921 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m22:06:46.411002 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m22:06:46.412154 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m22:06:46.416815 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_inventory"
[0m22:06:46.417639 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:06:46.418057 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: BEGIN
[0m22:06:46.418447 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.424170 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:06:46.424680 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:06:46.425097 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."inventory"
  );
  
[0m22:06:46.429058 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.003 seconds
[0m22:06:46.432860 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:06:46.433299 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m22:06:46.434243 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.437773 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:06:46.438226 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m22:06:46.439275 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.441551 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m22:06:46.442110 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:06:46.442529 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m22:06:46.444317 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.447191 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m22:06:46.448117 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:06:46.448528 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m22:06:46.450707 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.452109 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: Close
[0m22:06:46.452764 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100a9580>]}
[0m22:06:46.453439 [info ] [Thread-1  ]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m22:06:46.454440 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m22:06:46.455027 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m22:06:46.455557 [info ] [Thread-1  ]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:06:46.456285 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m22:06:46.456702 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m22:06:46.460196 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m22:06:46.461079 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m22:06:46.484266 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m22:06:46.485133 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:06:46.485554 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m22:06:46.485945 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.491852 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:06:46.492367 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:06:46.492793 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:06:46.494912 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.001 seconds
[0m22:06:46.498453 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:06:46.498884 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:06:46.499898 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.501479 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m22:06:46.501895 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:06:46.502287 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m22:06:46.503600 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.506504 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:06:46.509274 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:06:46.509709 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:06:46.510757 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m22:06:46.512364 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m22:06:46.513038 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100a6070>]}
[0m22:06:46.513900 [info ] [Thread-1  ]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m22:06:46.515145 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m22:06:46.516000 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m22:06:46.516935 [info ] [Thread-1  ]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m22:06:46.517591 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now model.datawarehouse.fact_payment)
[0m22:06:46.518034 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m22:06:46.522771 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m22:06:46.523951 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m22:06:46.531103 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.fact_payment"
[0m22:06:46.532117 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:06:46.532562 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: BEGIN
[0m22:06:46.533048 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.541288 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:06:46.542432 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:06:46.546461 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."payment"
  );
  
[0m22:06:46.557027 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.010 seconds
[0m22:06:46.561718 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:06:46.562217 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m22:06:46.563327 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.596001 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:06:46.597412 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m22:06:46.599405 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.603322 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m22:06:46.604050 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:06:46.604820 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m22:06:46.608105 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:06:46.613191 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m22:06:46.614586 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:06:46.615331 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m22:06:46.618008 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.620288 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: Close
[0m22:06:46.621259 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100e9040>]}
[0m22:06:46.622205 [info ] [Thread-1  ]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.10s]
[0m22:06:46.623504 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m22:06:46.624445 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m22:06:46.625536 [info ] [Thread-1  ]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m22:06:46.626634 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m22:06:46.627445 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m22:06:46.634013 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m22:06:46.635244 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m22:06:46.643608 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_rental"
[0m22:06:46.644972 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:06:46.645744 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: BEGIN
[0m22:06:46.646510 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.654368 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:06:46.655220 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:06:46.656018 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."rental"
  );
  
[0m22:06:46.672710 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.016 seconds
[0m22:06:46.679377 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:06:46.680219 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m22:06:46.681896 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.688146 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:06:46.688912 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m22:06:46.690423 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.692662 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m22:06:46.693127 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:06:46.693538 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m22:06:46.696612 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m22:06:46.699870 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m22:06:46.700879 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:06:46.701296 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m22:06:46.704173 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.706015 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: Close
[0m22:06:46.706687 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100e7fd0>]}
[0m22:06:46.707587 [info ] [Thread-1  ]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.08s]
[0m22:06:46.708575 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m22:06:46.709390 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m22:06:46.710198 [info ] [Thread-1  ]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m22:06:46.711009 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m22:06:46.711500 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m22:06:46.715960 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m22:06:46.716870 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m22:06:46.725202 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_staff"
[0m22:06:46.726625 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:06:46.727451 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: BEGIN
[0m22:06:46.728192 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.736628 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:06:46.737756 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:06:46.738576 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."staff"
  );
  
[0m22:06:46.743215 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m22:06:46.747780 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:06:46.748452 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m22:06:46.750103 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.753968 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:06:46.754460 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m22:06:46.755742 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.757902 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m22:06:46.758365 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:06:46.758768 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m22:06:46.760379 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.763481 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m22:06:46.764785 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:06:46.765502 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m22:06:46.768082 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.770686 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: Close
[0m22:06:46.771691 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100e9040>]}
[0m22:06:46.773028 [info ] [Thread-1  ]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.06s]
[0m22:06:46.774437 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m22:06:46.775330 [debug] [Thread-1  ]: Began running node model.datawarehouse.total_revenue
[0m22:06:46.776417 [info ] [Thread-1  ]: 21 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m22:06:46.777403 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_staff, now model.datawarehouse.total_revenue)
[0m22:06:46.778187 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.total_revenue
[0m22:06:46.784479 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.total_revenue"
[0m22:06:46.785720 [debug] [Thread-1  ]: Began executing node model.datawarehouse.total_revenue
[0m22:06:46.792206 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.total_revenue"
[0m22:06:46.793093 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:06:46.793510 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: BEGIN
[0m22:06:46.793897 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.799821 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:06:46.800357 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:06:46.800778 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    date_trunc('month', payment_date) as month_year,
    sum(amount) as total_revenue
FROM "datawarehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY 1
ORDER BY 1
  );
  
[0m22:06:46.811320 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.010 seconds
[0m22:06:46.815131 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:06:46.815550 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
alter table "datawarehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m22:06:46.816750 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.821923 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:06:46.822652 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
alter table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m22:06:46.824207 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:06:46.826793 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: COMMIT
[0m22:06:46.827289 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:06:46.827784 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: COMMIT
[0m22:06:46.829470 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:06:46.832718 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m22:06:46.833682 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:06:46.834113 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
drop table if exists "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m22:06:46.836492 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:06:46.838246 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: Close
[0m22:06:46.838913 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110131f10>]}
[0m22:06:46.839633 [info ] [Thread-1  ]: 21 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 4[0m in 0.06s]
[0m22:06:46.840341 [debug] [Thread-1  ]: Finished running node model.datawarehouse.total_revenue
[0m22:06:46.840911 [debug] [Thread-1  ]: Began running node model.datawarehouse.best_selling_film
[0m22:06:46.841469 [info ] [Thread-1  ]: 22 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m22:06:46.841998 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.total_revenue, now model.datawarehouse.best_selling_film)
[0m22:06:46.842417 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.best_selling_film
[0m22:06:46.846653 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.best_selling_film"
[0m22:06:46.847603 [debug] [Thread-1  ]: Began executing node model.datawarehouse.best_selling_film
[0m22:06:46.851995 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.best_selling_film"
[0m22:06:46.852765 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:06:46.853183 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: BEGIN
[0m22:06:46.853570 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:06:46.859602 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:06:46.860106 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:06:46.860539 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.best_selling_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
	title  as film_name,
	count(distinct rental_id) as total_rental 
FROM "datawarehouse"."dbt_dev_intermediete"."dim_film" df 
left join "datawarehouse"."dbt_dev_intermediete"."dim_inventory" inv on df.film_id  = inv.film_id 
left join "datawarehouse"."dbt_dev_intermediete"."dim_rental" dr on inv.inventory_id  = dr.inventory_id 
group by 1
order by 2 desc;
  );
  
[0m22:06:46.861929 [debug] [Thread-1  ]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 21: order by 2 desc;
                        ^

[0m22:06:46.862380 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: ROLLBACK
[0m22:06:46.863149 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: Close
[0m22:06:46.896255 [debug] [Thread-1  ]: Database Error in model best_selling_film (models/mart/best_selling_film.sql)
  syntax error at or near ";"
  LINE 21: order by 2 desc;
                          ^
  compiled Code at target/run/datawarehouse/models/mart/best_selling_film.sql
[0m22:06:46.896905 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '933ec859-4888-46be-86a4-640e1312a973', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be8ce50>]}
[0m22:06:46.897583 [error] [Thread-1  ]: 22 of 22 ERROR creating sql table model dbt_dev_mart.best_selling_film ......... [[31mERROR[0m in 0.05s]
[0m22:06:46.898480 [debug] [Thread-1  ]: Finished running node model.datawarehouse.best_selling_film
[0m22:06:46.900144 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:46.900523 [debug] [MainThread]: On master: BEGIN
[0m22:06:46.900856 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:06:46.909947 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m22:06:46.910665 [debug] [MainThread]: On master: COMMIT
[0m22:06:46.911158 [debug] [MainThread]: Using postgres connection "master"
[0m22:06:46.911511 [debug] [MainThread]: On master: COMMIT
[0m22:06:46.912345 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:06:46.912747 [debug] [MainThread]: On master: Close
[0m22:06:46.913253 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:06:46.913653 [debug] [MainThread]: Connection 'model.datawarehouse.best_selling_film' was properly closed.
[0m22:06:46.914154 [info ] [MainThread]: 
[0m22:06:46.914582 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 1.79 seconds (1.79s).
[0m22:06:46.919169 [debug] [MainThread]: Command end result
[0m22:06:47.011832 [info ] [MainThread]: 
[0m22:06:47.012408 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:06:47.012802 [info ] [MainThread]: 
[0m22:06:47.013282 [error] [MainThread]:   Database Error in model best_selling_film (models/mart/best_selling_film.sql)
  syntax error at or near ";"
  LINE 21: order by 2 desc;
                          ^
  compiled Code at target/run/datawarehouse/models/mart/best_selling_film.sql
[0m22:06:47.013699 [info ] [MainThread]: 
[0m22:06:47.014108 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=1 SKIP=0 TOTAL=22
[0m22:06:47.015716 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 3.0095966, "process_user_time": 3.623821, "process_kernel_time": 0.484986, "process_mem_max_rss": "110247936", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:06:47.016325 [debug] [MainThread]: Command `dbt run` failed at 22:06:47.016221 after 3.01 seconds
[0m22:06:47.016752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10919b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8ca6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b8cafa0>]}
[0m22:06:50.392279 [debug] [MainThread]: Flushing usage events
[0m22:07:28.494464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eecb2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109d0d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109d0a90>]}


============================== 22:07:28.500795 | a0394699-06f1-4618-a045-a98c5a1fce9c ==============================
[0m22:07:28.500795 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:07:28.501497 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:07:28.681353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f184e20>]}
[0m22:07:28.747637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d21310>]}
[0m22:07:28.748673 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:07:28.768674 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:07:28.962362 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:07:28.963117 [debug] [MainThread]: Partial parsing: updated file: datawarehouse://models/mart/best_selling_film.sql
[0m22:07:29.237090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111773f40>]}
[0m22:07:29.379795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115a1040>]}
[0m22:07:29.380417 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m22:07:29.380841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111774be0>]}
[0m22:07:29.383477 [info ] [MainThread]: 
[0m22:07:29.384328 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:07:29.391889 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m22:07:29.471177 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:07:29.471835 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:07:29.472242 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:07:29.495448 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.023 seconds
[0m22:07:29.497268 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:07:29.500614 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:07:29.501266 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:07:29.501660 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:07:29.508395 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m22:07:29.509786 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:07:29.512971 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:07:29.513608 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:07:29.514002 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:07:29.519877 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.006 seconds
[0m22:07:29.521673 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:07:29.524824 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:07:29.525333 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:07:29.525706 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:07:29.531077 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.005 seconds
[0m22:07:29.532594 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:07:29.535571 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now list_datawarehouse_dbt_dev)
[0m22:07:29.542949 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m22:07:29.543411 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m22:07:29.543760 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:07:29.549332 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:07:29.549813 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m22:07:29.550207 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:07:29.553456 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:07:29.554872 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m22:07:29.555573 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m22:07:29.556219 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now list_datawarehouse_dbt_dev_mart)
[0m22:07:29.559190 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m22:07:29.559618 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: BEGIN
[0m22:07:29.559959 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:07:29.564857 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:07:29.565329 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m22:07:29.565715 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_mart"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:07:29.568617 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m22:07:29.570018 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: ROLLBACK
[0m22:07:29.570770 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: Close
[0m22:07:29.571387 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev_raw)
[0m22:07:29.574388 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m22:07:29.574797 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m22:07:29.575142 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:07:29.580116 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:07:29.580571 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m22:07:29.580979 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:07:29.584099 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:07:29.585679 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m22:07:29.586584 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m22:07:29.587851 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev_intermediete)
[0m22:07:29.592393 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m22:07:29.592879 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m22:07:29.593336 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:07:29.600836 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m22:07:29.601384 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m22:07:29.602136 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m22:07:29.606213 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.004 seconds
[0m22:07:29.609438 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m22:07:29.610910 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m22:07:29.662169 [debug] [MainThread]: Using postgres connection "master"
[0m22:07:29.662777 [debug] [MainThread]: On master: BEGIN
[0m22:07:29.663228 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:07:29.669848 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m22:07:29.670420 [debug] [MainThread]: Using postgres connection "master"
[0m22:07:29.670977 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:07:29.682828 [debug] [MainThread]: SQL status: SELECT 38 in 0.011 seconds
[0m22:07:29.685630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111baf370>]}
[0m22:07:29.686150 [debug] [MainThread]: On master: ROLLBACK
[0m22:07:29.687021 [debug] [MainThread]: Using postgres connection "master"
[0m22:07:29.687416 [debug] [MainThread]: On master: BEGIN
[0m22:07:29.688577 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:07:29.688983 [debug] [MainThread]: On master: COMMIT
[0m22:07:29.689340 [debug] [MainThread]: Using postgres connection "master"
[0m22:07:29.689683 [debug] [MainThread]: On master: COMMIT
[0m22:07:29.690395 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:07:29.690782 [debug] [MainThread]: On master: Close
[0m22:07:29.691299 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:07:29.691705 [info ] [MainThread]: 
[0m22:07:29.693710 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m22:07:29.694334 [info ] [Thread-1  ]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:07:29.695010 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now model.datawarehouse.actor)
[0m22:07:29.695439 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m22:07:29.705778 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m22:07:29.706677 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m22:07:29.751297 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m22:07:29.752290 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:07:29.752704 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m22:07:29.753085 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:29.759846 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:07:29.760359 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:07:29.760787 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m22:07:29.763035 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m22:07:29.770184 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:07:29.770671 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m22:07:29.771811 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:29.775410 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:07:29.775848 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:07:29.777059 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:29.802044 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m22:07:29.802635 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:07:29.803039 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m22:07:29.804801 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:29.811837 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:07:29.816620 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:07:29.817046 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:07:29.819349 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:29.822214 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m22:07:29.824524 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11178faf0>]}
[0m22:07:29.825458 [info ] [Thread-1  ]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m22:07:29.826244 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m22:07:29.826721 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m22:07:29.827271 [info ] [Thread-1  ]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:07:29.827935 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m22:07:29.828586 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m22:07:29.832137 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m22:07:29.833030 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m22:07:29.838237 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m22:07:29.839254 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:07:29.839712 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m22:07:29.840444 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:29.847305 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:07:29.847822 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:07:29.848244 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m22:07:29.850617 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m22:07:29.854487 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:07:29.854945 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m22:07:29.856019 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:29.859555 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:07:29.859980 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:07:29.861046 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:29.862991 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m22:07:29.863408 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:07:29.863792 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m22:07:29.865340 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:29.868442 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:07:29.869347 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:07:29.869752 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:07:29.872107 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:29.873625 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m22:07:29.874329 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c93cd0>]}
[0m22:07:29.875016 [info ] [Thread-1  ]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m22:07:29.875838 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m22:07:29.876411 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m22:07:29.876936 [info ] [Thread-1  ]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:07:29.877722 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m22:07:29.878144 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m22:07:29.882932 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m22:07:29.883798 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m22:07:29.888609 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m22:07:29.889544 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:07:29.890178 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m22:07:29.890788 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:29.896255 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:07:29.896771 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:07:29.897196 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m22:07:29.899386 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m22:07:29.903287 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:07:29.904169 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m22:07:29.905238 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:29.908820 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:07:29.909307 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:07:29.910386 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:29.912448 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m22:07:29.912869 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:07:29.913272 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m22:07:29.914643 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:29.917619 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:07:29.918668 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:07:29.919096 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:07:29.921344 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:29.922910 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m22:07:29.923486 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b748b0>]}
[0m22:07:29.924153 [info ] [Thread-1  ]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m22:07:29.924825 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m22:07:29.925334 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m22:07:29.925958 [info ] [Thread-1  ]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:07:29.926623 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m22:07:29.927053 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m22:07:29.930857 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m22:07:29.931766 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m22:07:29.937332 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m22:07:29.938443 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:07:29.938930 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m22:07:29.939335 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:29.946167 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:07:29.946669 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:07:29.947089 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m22:07:29.953130 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.006 seconds
[0m22:07:29.959061 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:07:29.959585 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m22:07:29.960848 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:29.964697 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:07:29.965183 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:07:29.966257 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:29.968431 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m22:07:29.968907 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:07:29.969312 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m22:07:29.971020 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:29.974318 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:07:29.975260 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:07:29.975700 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:07:29.978093 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:29.979741 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m22:07:29.980503 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ca31f0>]}
[0m22:07:29.981316 [info ] [Thread-1  ]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m22:07:29.982107 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m22:07:29.983240 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m22:07:29.984431 [info ] [Thread-1  ]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:07:29.985316 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m22:07:29.985778 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m22:07:29.991141 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m22:07:29.992423 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m22:07:29.997061 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m22:07:29.997935 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:07:29.998366 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m22:07:29.998758 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.004411 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:07:30.005091 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:07:30.005551 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m22:07:30.010158 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m22:07:30.013906 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:07:30.014380 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m22:07:30.015457 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.019077 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:07:30.019735 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:07:30.021060 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.023299 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m22:07:30.023792 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:07:30.024186 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m22:07:30.026374 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:07:30.029801 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:07:30.032405 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:07:30.032934 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:07:30.035347 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.037220 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m22:07:30.038107 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cea460>]}
[0m22:07:30.039201 [info ] [Thread-1  ]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m22:07:30.040608 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m22:07:30.041211 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m22:07:30.041853 [info ] [Thread-1  ]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:07:30.043096 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m22:07:30.043566 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m22:07:30.047302 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m22:07:30.048487 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m22:07:30.053857 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m22:07:30.054917 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:07:30.055433 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m22:07:30.055835 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.061023 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:07:30.061530 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:07:30.061970 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m22:07:30.065724 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.003 seconds
[0m22:07:30.069517 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:07:30.070109 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m22:07:30.071352 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.076073 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:07:30.076794 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:07:30.078135 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.080450 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m22:07:30.080936 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:07:30.081347 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m22:07:30.083403 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:07:30.086950 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:07:30.087917 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:07:30.088343 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:07:30.090737 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.092206 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m22:07:30.092927 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d0f430>]}
[0m22:07:30.093762 [info ] [Thread-1  ]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m22:07:30.094610 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m22:07:30.095236 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m22:07:30.095773 [info ] [Thread-1  ]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:07:30.096591 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m22:07:30.097014 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m22:07:30.100331 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m22:07:30.101199 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m22:07:30.107821 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m22:07:30.108736 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:07:30.109159 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m22:07:30.109544 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.115093 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:07:30.115591 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:07:30.116019 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:07:30.117627 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.001 seconds
[0m22:07:30.121425 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:07:30.122154 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:07:30.123739 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.127644 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:07:30.128148 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:07:30.129405 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.131561 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m22:07:30.132111 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:07:30.132519 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m22:07:30.134265 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.137966 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:07:30.138924 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:07:30.139354 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:07:30.141683 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.143298 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m22:07:30.143888 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ceacd0>]}
[0m22:07:30.144561 [info ] [Thread-1  ]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.05s]
[0m22:07:30.145238 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m22:07:30.145739 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m22:07:30.146435 [info ] [Thread-1  ]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:07:30.146973 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m22:07:30.147391 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m22:07:30.150990 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m22:07:30.151884 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m22:07:30.157150 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m22:07:30.158108 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:07:30.158559 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m22:07:30.159067 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.164321 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:07:30.164893 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:07:30.165338 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m22:07:30.174165 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.008 seconds
[0m22:07:30.178191 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:07:30.178829 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:07:30.180024 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.184894 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:07:30.185415 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:07:30.186683 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.188839 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m22:07:30.189288 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:07:30.189701 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m22:07:30.192157 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:07:30.197058 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:07:30.197998 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:07:30.198430 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:07:30.200548 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.202091 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m22:07:30.202701 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d1e9a0>]}
[0m22:07:30.203439 [info ] [Thread-1  ]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m22:07:30.204209 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m22:07:30.204880 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m22:07:30.205604 [info ] [Thread-1  ]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:07:30.206235 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m22:07:30.206667 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m22:07:30.210342 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m22:07:30.211223 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m22:07:30.216421 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m22:07:30.217310 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:07:30.217739 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m22:07:30.218130 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.224673 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:07:30.225197 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:07:30.225936 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m22:07:30.237229 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.011 seconds
[0m22:07:30.241287 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:07:30.241780 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m22:07:30.243201 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.247821 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:07:30.248408 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:07:30.249764 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.252358 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m22:07:30.252968 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:07:30.253680 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m22:07:30.256931 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m22:07:30.260134 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:07:30.261052 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:07:30.261478 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:07:30.263825 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.265391 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m22:07:30.266006 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d1e8e0>]}
[0m22:07:30.266778 [info ] [Thread-1  ]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m22:07:30.267611 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m22:07:30.268228 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m22:07:30.268792 [info ] [Thread-1  ]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:07:30.269430 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m22:07:30.269870 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m22:07:30.273737 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m22:07:30.274794 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m22:07:30.281443 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m22:07:30.282290 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:07:30.282714 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m22:07:30.283101 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.289432 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:07:30.289936 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:07:30.290353 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m22:07:30.294269 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.003 seconds
[0m22:07:30.298462 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:07:30.298927 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m22:07:30.300068 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.303706 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:07:30.304153 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:07:30.305182 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.307184 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m22:07:30.307599 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:07:30.307992 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m22:07:30.309464 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.312365 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:07:30.313384 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:07:30.313813 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:07:30.316016 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.317477 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m22:07:30.318054 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c93250>]}
[0m22:07:30.318712 [info ] [Thread-1  ]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.05s]
[0m22:07:30.319578 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m22:07:30.320283 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m22:07:30.320829 [info ] [Thread-1  ]: 11 of 22 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m22:07:30.321519 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.dim_actor)
[0m22:07:30.322123 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m22:07:30.325891 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m22:07:30.326844 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m22:07:30.332189 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_actor"
[0m22:07:30.333029 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:07:30.333445 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: BEGIN
[0m22:07:30.333831 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.339613 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:07:30.340149 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:07:30.340637 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."actor"
  );
  
[0m22:07:30.342533 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.001 seconds
[0m22:07:30.346280 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:07:30.346720 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m22:07:30.347693 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.352511 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:07:30.352970 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m22:07:30.354110 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.356160 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m22:07:30.356594 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:07:30.356997 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m22:07:30.358389 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.361338 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m22:07:30.362197 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:07:30.362615 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m22:07:30.364501 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m22:07:30.365988 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: Close
[0m22:07:30.366567 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d50c70>]}
[0m22:07:30.367230 [info ] [Thread-1  ]: 11 of 22 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m22:07:30.367899 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m22:07:30.368411 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m22:07:30.368949 [info ] [Thread-1  ]: 12 of 22 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m22:07:30.369584 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m22:07:30.370020 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m22:07:30.373796 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m22:07:30.374675 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m22:07:30.379595 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_address"
[0m22:07:30.380648 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:07:30.381144 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: BEGIN
[0m22:07:30.381564 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.389318 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:07:30.389840 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:07:30.390265 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."address"
  );
  
[0m22:07:30.392535 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m22:07:30.396366 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:07:30.396848 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m22:07:30.398138 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.402152 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:07:30.402732 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m22:07:30.404381 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.406834 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m22:07:30.407318 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:07:30.407723 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m22:07:30.409326 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.412300 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m22:07:30.413205 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:07:30.413630 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m22:07:30.416224 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.417920 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: Close
[0m22:07:30.418581 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115b10a0>]}
[0m22:07:30.419333 [info ] [Thread-1  ]: 12 of 22 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m22:07:30.420199 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m22:07:30.420775 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m22:07:30.421332 [info ] [Thread-1  ]: 13 of 22 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m22:07:30.422191 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m22:07:30.422742 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m22:07:30.429204 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m22:07:30.430853 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m22:07:30.438449 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_customer"
[0m22:07:30.440005 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:07:30.440666 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: BEGIN
[0m22:07:30.441130 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.449458 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:07:30.450060 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:07:30.450929 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."customer"
  );
  
[0m22:07:30.453820 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m22:07:30.457814 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:07:30.458385 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m22:07:30.459625 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.463312 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:07:30.463796 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m22:07:30.464973 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.467155 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m22:07:30.467628 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:07:30.468043 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m22:07:30.469791 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.474435 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m22:07:30.476208 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:07:30.476991 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m22:07:30.479862 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.482039 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: Close
[0m22:07:30.482864 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c9f6a0>]}
[0m22:07:30.484174 [info ] [Thread-1  ]: 13 of 22 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m22:07:30.485682 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m22:07:30.486543 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m22:07:30.487534 [info ] [Thread-1  ]: 14 of 22 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m22:07:30.488500 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m22:07:30.489225 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m22:07:30.495838 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m22:07:30.496925 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m22:07:30.502414 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film"
[0m22:07:30.503500 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:07:30.504046 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: BEGIN
[0m22:07:30.504452 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.512170 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:07:30.512728 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:07:30.513203 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film"
  );
  
[0m22:07:30.520493 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.007 seconds
[0m22:07:30.526713 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:07:30.527488 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m22:07:30.529359 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.536899 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:07:30.537539 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m22:07:30.538938 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.542133 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m22:07:30.542668 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:07:30.543277 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m22:07:30.545502 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:07:30.549614 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m22:07:30.550719 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:07:30.551145 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m22:07:30.554297 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m22:07:30.556157 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: Close
[0m22:07:30.556991 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111db5f10>]}
[0m22:07:30.557724 [info ] [Thread-1  ]: 14 of 22 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.07s]
[0m22:07:30.558515 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m22:07:30.559152 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m22:07:30.559697 [info ] [Thread-1  ]: 15 of 22 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m22:07:30.560434 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m22:07:30.560919 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m22:07:30.564883 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m22:07:30.565912 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m22:07:30.572456 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film_actor"
[0m22:07:30.573319 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:07:30.573758 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: BEGIN
[0m22:07:30.574263 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.580736 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:07:30.581252 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:07:30.581685 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m22:07:30.586898 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.005 seconds
[0m22:07:30.591535 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:07:30.591994 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m22:07:30.593280 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.596865 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:07:30.597321 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m22:07:30.598527 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.600791 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m22:07:30.601243 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:07:30.601646 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m22:07:30.603506 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.606505 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m22:07:30.607395 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:07:30.607813 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m22:07:30.610255 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.611820 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: Close
[0m22:07:30.612419 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11178fca0>]}
[0m22:07:30.613115 [info ] [Thread-1  ]: 15 of 22 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m22:07:30.613815 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m22:07:30.614358 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m22:07:30.615002 [info ] [Thread-1  ]: 16 of 22 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m22:07:30.615555 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m22:07:30.615984 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m22:07:30.621238 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m22:07:30.622460 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m22:07:30.628051 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_inventory"
[0m22:07:30.628924 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:07:30.629357 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: BEGIN
[0m22:07:30.629747 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.635593 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:07:30.636248 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:07:30.637217 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."inventory"
  );
  
[0m22:07:30.641986 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:07:30.646420 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:07:30.647259 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m22:07:30.648688 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.653630 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:07:30.654354 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m22:07:30.655867 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.658391 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m22:07:30.658879 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:07:30.659296 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m22:07:30.661087 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.664096 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m22:07:30.665098 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:07:30.665535 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m22:07:30.667671 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.669241 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: Close
[0m22:07:30.669987 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ceed30>]}
[0m22:07:30.670789 [info ] [Thread-1  ]: 16 of 22 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m22:07:30.671536 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m22:07:30.672298 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m22:07:30.673035 [info ] [Thread-1  ]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:07:30.673926 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m22:07:30.674719 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m22:07:30.679587 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m22:07:30.680785 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m22:07:30.706608 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m22:07:30.707634 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:07:30.708124 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m22:07:30.708540 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.714185 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:07:30.714688 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:07:30.715116 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:07:30.716886 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.001 seconds
[0m22:07:30.720737 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:07:30.721293 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:07:30.722771 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.724953 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m22:07:30.725420 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:07:30.725886 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m22:07:30.727382 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.730493 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:07:30.734189 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:07:30.743509 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:07:30.745858 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m22:07:30.748651 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m22:07:30.749583 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111db7e20>]}
[0m22:07:30.750779 [info ] [Thread-1  ]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.08s]
[0m22:07:30.752141 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m22:07:30.753095 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m22:07:30.753920 [info ] [Thread-1  ]: 18 of 22 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m22:07:30.754943 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now model.datawarehouse.fact_payment)
[0m22:07:30.755835 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m22:07:30.762957 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m22:07:30.764415 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m22:07:30.773335 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.fact_payment"
[0m22:07:30.774798 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:07:30.775574 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: BEGIN
[0m22:07:30.776247 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.783985 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:07:30.784963 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:07:30.786003 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."payment"
  );
  
[0m22:07:30.796562 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.010 seconds
[0m22:07:30.802100 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:07:30.802884 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m22:07:30.804305 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.809387 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:07:30.809859 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m22:07:30.811246 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.813490 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m22:07:30.813969 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:07:30.814455 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m22:07:30.817092 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:07:30.820455 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m22:07:30.823341 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:07:30.824122 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m22:07:30.826619 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.828568 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: Close
[0m22:07:30.829510 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d42610>]}
[0m22:07:30.830652 [info ] [Thread-1  ]: 18 of 22 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m22:07:30.831771 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m22:07:30.832294 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m22:07:30.833013 [info ] [Thread-1  ]: 19 of 22 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m22:07:30.833798 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m22:07:30.834354 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m22:07:30.839098 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m22:07:30.840401 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m22:07:30.847959 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_rental"
[0m22:07:30.849036 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:07:30.849502 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: BEGIN
[0m22:07:30.850007 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.857034 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:07:30.857785 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:07:30.858524 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."rental"
  );
  
[0m22:07:30.870447 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.011 seconds
[0m22:07:30.876893 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:07:30.877731 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m22:07:30.879457 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.884949 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:07:30.885751 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m22:07:30.887275 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.890039 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m22:07:30.890588 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:07:30.891146 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m22:07:30.895134 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m22:07:30.898484 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m22:07:30.899561 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:07:30.900213 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m22:07:30.903220 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.905265 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: Close
[0m22:07:30.906002 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e1bc70>]}
[0m22:07:30.906800 [info ] [Thread-1  ]: 19 of 22 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m22:07:30.907580 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m22:07:30.908236 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m22:07:30.908881 [info ] [Thread-1  ]: 20 of 22 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m22:07:30.909619 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m22:07:30.910331 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m22:07:30.914884 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m22:07:30.915926 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m22:07:30.923447 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_staff"
[0m22:07:30.924355 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:07:30.924797 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: BEGIN
[0m22:07:30.925191 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.931654 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:07:30.932177 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:07:30.932619 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."staff"
  );
  
[0m22:07:30.936676 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m22:07:30.941589 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:07:30.942283 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m22:07:30.943573 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.947677 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:07:30.948264 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m22:07:30.949482 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:30.951613 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m22:07:30.952081 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:07:30.952495 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m22:07:30.954122 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:30.957137 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m22:07:30.958154 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:07:30.958650 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m22:07:30.961156 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:30.962760 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: Close
[0m22:07:30.963406 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c9b7c0>]}
[0m22:07:30.964119 [info ] [Thread-1  ]: 20 of 22 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.05s]
[0m22:07:30.964817 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m22:07:30.965337 [debug] [Thread-1  ]: Began running node model.datawarehouse.total_revenue
[0m22:07:30.965960 [info ] [Thread-1  ]: 21 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m22:07:30.966555 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_staff, now model.datawarehouse.total_revenue)
[0m22:07:30.967001 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.total_revenue
[0m22:07:30.970787 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.total_revenue"
[0m22:07:30.971889 [debug] [Thread-1  ]: Began executing node model.datawarehouse.total_revenue
[0m22:07:30.977002 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.total_revenue"
[0m22:07:30.977904 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:07:30.978328 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: BEGIN
[0m22:07:30.978714 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:30.986263 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:07:30.986960 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:07:30.987663 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    date_trunc('month', payment_date) as month_year,
    sum(amount) as total_revenue
FROM "datawarehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY 1
ORDER BY 1
  );
  
[0m22:07:30.998625 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.010 seconds
[0m22:07:31.005543 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:07:31.006363 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
alter table "datawarehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m22:07:31.008027 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:31.012805 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:07:31.013302 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
alter table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m22:07:31.014744 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:31.017218 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: COMMIT
[0m22:07:31.017771 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:07:31.018235 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: COMMIT
[0m22:07:31.020002 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:31.027108 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m22:07:31.028431 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:07:31.028910 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
drop table if exists "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m22:07:31.031433 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:07:31.033591 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: Close
[0m22:07:31.034460 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e1d070>]}
[0m22:07:31.035550 [info ] [Thread-1  ]: 21 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 4[0m in 0.07s]
[0m22:07:31.036464 [debug] [Thread-1  ]: Finished running node model.datawarehouse.total_revenue
[0m22:07:31.037170 [debug] [Thread-1  ]: Began running node model.datawarehouse.best_selling_film
[0m22:07:31.037770 [info ] [Thread-1  ]: 22 of 22 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m22:07:31.038528 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.total_revenue, now model.datawarehouse.best_selling_film)
[0m22:07:31.039103 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.best_selling_film
[0m22:07:31.043573 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.best_selling_film"
[0m22:07:31.044608 [debug] [Thread-1  ]: Began executing node model.datawarehouse.best_selling_film
[0m22:07:31.050232 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.best_selling_film"
[0m22:07:31.051404 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:07:31.051846 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: BEGIN
[0m22:07:31.052232 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:07:31.060285 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:07:31.060915 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:07:31.061488 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.best_selling_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
	title  as film_name,
	count(distinct rental_id) as total_rental 
FROM "datawarehouse"."dbt_dev_intermediete"."dim_film" df 
left join "datawarehouse"."dbt_dev_intermediete"."dim_inventory" inv on df.film_id  = inv.film_id 
left join "datawarehouse"."dbt_dev_intermediete"."dim_rental" dr on inv.inventory_id  = dr.inventory_id 
group by 1
order by 2 desc
  );
  
[0m22:07:31.706544 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.644 seconds
[0m22:07:31.710407 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:07:31.710845 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.best_selling_film"} */
alter table "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp" rename to "best_selling_film"
[0m22:07:31.712102 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:07:31.714080 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: COMMIT
[0m22:07:31.714502 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:07:31.714890 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: COMMIT
[0m22:07:31.716758 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:07:31.719659 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_backup"
[0m22:07:31.720538 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:07:31.720944 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.best_selling_film"} */
drop table if exists "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_backup" cascade
[0m22:07:31.721995 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m22:07:31.723401 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: Close
[0m22:07:31.724111 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0394699-06f1-4618-a045-a98c5a1fce9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111504850>]}
[0m22:07:31.724774 [info ] [Thread-1  ]: 22 of 22 OK created sql table model dbt_dev_mart.best_selling_film ............. [[32mSELECT 1000[0m in 0.69s]
[0m22:07:31.725693 [debug] [Thread-1  ]: Finished running node model.datawarehouse.best_selling_film
[0m22:07:31.727295 [debug] [MainThread]: Using postgres connection "master"
[0m22:07:31.727786 [debug] [MainThread]: On master: BEGIN
[0m22:07:31.728245 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:07:31.735964 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m22:07:31.736719 [debug] [MainThread]: On master: COMMIT
[0m22:07:31.737415 [debug] [MainThread]: Using postgres connection "master"
[0m22:07:31.738101 [debug] [MainThread]: On master: COMMIT
[0m22:07:31.739266 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m22:07:31.740293 [debug] [MainThread]: On master: Close
[0m22:07:31.740925 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:07:31.741276 [debug] [MainThread]: Connection 'model.datawarehouse.best_selling_film' was properly closed.
[0m22:07:31.741773 [info ] [MainThread]: 
[0m22:07:31.742327 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 2.36 seconds (2.36s).
[0m22:07:31.747455 [debug] [MainThread]: Command end result
[0m22:07:31.794840 [info ] [MainThread]: 
[0m22:07:31.795419 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:07:31.795859 [info ] [MainThread]: 
[0m22:07:31.796289 [info ] [MainThread]: Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
[0m22:07:31.797897 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.3797028, "process_user_time": 3.386167, "process_kernel_time": 0.328461, "process_mem_max_rss": "110321664", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:07:31.798588 [debug] [MainThread]: Command `dbt run` succeeded at 22:07:31.798474 after 3.38 seconds
[0m22:07:31.799036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eecb2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103ea670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d04b50>]}
[0m22:07:34.931733 [debug] [MainThread]: Flushing usage events
[0m22:14:19.526043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11131a2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e3cb80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e3c880>]}


============================== 22:14:19.541545 | c66e374b-110c-4835-9493-224ecca085d9 ==============================
[0m22:14:19.541545 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:14:19.542520 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'version_check': 'True', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:14:19.767072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131695b0>]}
[0m22:14:19.829692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113189100>]}
[0m22:14:19.831256 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:14:19.851450 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:14:20.077981 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:14:20.079058 [debug] [MainThread]: Partial parsing: updated file: datawarehouse://models/mart/actor_most_roles_play.sql
[0m22:14:20.361723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b8f130>]}
[0m22:14:20.521004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139ae5e0>]}
[0m22:14:20.521676 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m22:14:20.522123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bb8b80>]}
[0m22:14:20.524749 [info ] [MainThread]: 
[0m22:14:20.525399 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:14:20.531861 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse'
[0m22:14:20.602963 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:14:20.603486 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:14:20.603882 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:14:20.644157 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.040 seconds
[0m22:14:20.645860 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:14:20.648994 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:14:20.653042 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:14:20.653493 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:20.660989 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m22:14:20.662893 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:14:20.666142 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:14:20.667038 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:14:20.667589 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:20.675781 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.008 seconds
[0m22:14:20.677464 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:14:20.680757 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse"
[0m22:14:20.681318 [debug] [ThreadPool]: On list_datawarehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse"} */

    select distinct nspname from pg_namespace
  
[0m22:14:20.681794 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:20.688850 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.007 seconds
[0m22:14:20.690664 [debug] [ThreadPool]: On list_datawarehouse: Close
[0m22:14:20.693977 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse, now list_datawarehouse_dbt_dev_intermediete)
[0m22:14:20.702234 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m22:14:20.702738 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m22:14:20.703084 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:20.708540 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:14:20.709017 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m22:14:20.709421 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m22:14:20.712466 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:14:20.714003 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m22:14:20.714691 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m22:14:20.715305 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now list_datawarehouse_dbt_dev_mart)
[0m22:14:20.719324 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m22:14:20.719735 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: BEGIN
[0m22:14:20.720081 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:20.724948 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:14:20.725415 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m22:14:20.725801 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_mart"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:14:20.728877 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:14:20.730340 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: ROLLBACK
[0m22:14:20.731122 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: Close
[0m22:14:20.731989 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev_raw)
[0m22:14:20.735302 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m22:14:20.735722 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m22:14:20.736069 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:20.740740 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:14:20.741201 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m22:14:20.741582 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:14:20.744568 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:14:20.746099 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m22:14:20.746770 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m22:14:20.747411 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev)
[0m22:14:20.752795 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m22:14:20.753206 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m22:14:20.753610 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:14:20.758427 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:14:20.758891 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m22:14:20.759273 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:14:20.762323 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:14:20.763708 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m22:14:20.764537 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m22:14:20.814086 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:20.814736 [debug] [MainThread]: On master: BEGIN
[0m22:14:20.815249 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:14:20.822714 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m22:14:20.823322 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:20.823961 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:14:20.835449 [debug] [MainThread]: SQL status: SELECT 38 in 0.011 seconds
[0m22:14:20.838259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c04c0>]}
[0m22:14:20.838841 [debug] [MainThread]: On master: ROLLBACK
[0m22:14:20.839724 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:20.840170 [debug] [MainThread]: On master: BEGIN
[0m22:14:20.841390 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:14:20.841843 [debug] [MainThread]: On master: COMMIT
[0m22:14:20.842215 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:20.842566 [debug] [MainThread]: On master: COMMIT
[0m22:14:20.843269 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:14:20.843672 [debug] [MainThread]: On master: Close
[0m22:14:20.844201 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:14:20.844600 [info ] [MainThread]: 
[0m22:14:20.847320 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m22:14:20.847925 [info ] [Thread-1  ]: 1 of 23 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m22:14:20.848659 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now model.datawarehouse.actor)
[0m22:14:20.849095 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m22:14:20.859658 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m22:14:20.860775 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m22:14:20.904194 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor"
[0m22:14:20.905121 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:14:20.905541 [debug] [Thread-1  ]: On model.datawarehouse.actor: BEGIN
[0m22:14:20.905924 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:20.912460 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:20.912976 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:14:20.913397 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."actor"
  );
  
[0m22:14:20.915417 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m22:14:20.922474 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:14:20.922938 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m22:14:20.924181 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:20.927686 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:14:20.928104 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
alter table "datawarehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m22:14:20.929213 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:20.952266 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m22:14:20.952765 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:14:20.953282 [debug] [Thread-1  ]: On model.datawarehouse.actor: COMMIT
[0m22:14:20.955212 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:20.962413 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m22:14:20.967393 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor"
[0m22:14:20.967843 [debug] [Thread-1  ]: On model.datawarehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m22:14:20.970274 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:20.973079 [debug] [Thread-1  ]: On model.datawarehouse.actor: Close
[0m22:14:20.975029 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115bbe80>]}
[0m22:14:20.975979 [info ] [Thread-1  ]: 1 of 23 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.13s]
[0m22:14:20.976806 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m22:14:20.977311 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m22:14:20.977823 [info ] [Thread-1  ]: 2 of 23 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m22:14:20.978618 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m22:14:20.979149 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m22:14:20.982864 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m22:14:20.983730 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m22:14:20.988969 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.address"
[0m22:14:20.989975 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:14:20.990409 [debug] [Thread-1  ]: On model.datawarehouse.address: BEGIN
[0m22:14:20.990806 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:20.996786 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:20.997295 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:14:20.997731 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."address"
  );
  
[0m22:14:21.000069 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m22:14:21.003817 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:14:21.004308 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m22:14:21.005687 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.009601 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:14:21.010103 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
alter table "datawarehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m22:14:21.011327 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.013478 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m22:14:21.014016 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:14:21.014421 [debug] [Thread-1  ]: On model.datawarehouse.address: COMMIT
[0m22:14:21.016107 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.019181 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."address__dbt_backup"
[0m22:14:21.020183 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.address"
[0m22:14:21.020616 [debug] [Thread-1  ]: On model.datawarehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.address"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m22:14:21.022744 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.024364 [debug] [Thread-1  ]: On model.datawarehouse.address: Close
[0m22:14:21.025127 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c39340>]}
[0m22:14:21.025988 [info ] [Thread-1  ]: 2 of 23 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.05s]
[0m22:14:21.026938 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m22:14:21.027719 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m22:14:21.028546 [info ] [Thread-1  ]: 3 of 23 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m22:14:21.029477 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m22:14:21.030069 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m22:14:21.035546 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m22:14:21.036412 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m22:14:21.041163 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.customer"
[0m22:14:21.042093 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:14:21.042540 [debug] [Thread-1  ]: On model.datawarehouse.customer: BEGIN
[0m22:14:21.042936 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.048976 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:21.049494 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:14:21.049916 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."customer"
  );
  
[0m22:14:21.052209 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m22:14:21.055914 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:14:21.056449 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m22:14:21.057565 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.061711 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:14:21.062220 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
alter table "datawarehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m22:14:21.063274 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.065301 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m22:14:21.065735 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:14:21.066136 [debug] [Thread-1  ]: On model.datawarehouse.customer: COMMIT
[0m22:14:21.067537 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.070580 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m22:14:21.071447 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.customer"
[0m22:14:21.071859 [debug] [Thread-1  ]: On model.datawarehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.customer"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m22:14:21.073824 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.075482 [debug] [Thread-1  ]: On model.datawarehouse.customer: Close
[0m22:14:21.076114 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114034d90>]}
[0m22:14:21.076803 [info ] [Thread-1  ]: 3 of 23 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.05s]
[0m22:14:21.077534 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m22:14:21.078088 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m22:14:21.078793 [info ] [Thread-1  ]: 4 of 23 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m22:14:21.079360 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m22:14:21.079782 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m22:14:21.083693 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m22:14:21.084596 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m22:14:21.089741 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film"
[0m22:14:21.090659 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:14:21.091178 [debug] [Thread-1  ]: On model.datawarehouse.film: BEGIN
[0m22:14:21.091757 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.097481 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:21.098007 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:14:21.098495 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film"
  );
  
[0m22:14:21.103565 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.005 seconds
[0m22:14:21.108859 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:14:21.109523 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m22:14:21.110601 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.114109 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:14:21.114535 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
alter table "datawarehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m22:14:21.115454 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.117571 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m22:14:21.117996 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:14:21.118395 [debug] [Thread-1  ]: On model.datawarehouse.film: COMMIT
[0m22:14:21.120139 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.123022 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film__dbt_backup"
[0m22:14:21.123884 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film"
[0m22:14:21.124293 [debug] [Thread-1  ]: On model.datawarehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m22:14:21.126821 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.128316 [debug] [Thread-1  ]: On model.datawarehouse.film: Close
[0m22:14:21.128898 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140cfee0>]}
[0m22:14:21.129565 [info ] [Thread-1  ]: 4 of 23 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.05s]
[0m22:14:21.130238 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m22:14:21.130775 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m22:14:21.131489 [info ] [Thread-1  ]: 5 of 23 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m22:14:21.132037 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m22:14:21.132458 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m22:14:21.136104 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m22:14:21.136934 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m22:14:21.141531 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.film_actor"
[0m22:14:21.142386 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:14:21.142858 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: BEGIN
[0m22:14:21.143250 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.148767 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:14:21.149283 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:14:21.149707 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."film_actor"
  );
  
[0m22:14:21.153913 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m22:14:21.157558 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:14:21.158009 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m22:14:21.159554 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.163550 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:14:21.164038 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
alter table "datawarehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m22:14:21.165158 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.167390 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m22:14:21.167853 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:14:21.168261 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: COMMIT
[0m22:14:21.169923 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.172882 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m22:14:21.175190 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.film_actor"
[0m22:14:21.175827 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m22:14:21.178033 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.179525 [debug] [Thread-1  ]: On model.datawarehouse.film_actor: Close
[0m22:14:21.180093 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139df490>]}
[0m22:14:21.180750 [info ] [Thread-1  ]: 5 of 23 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.05s]
[0m22:14:21.181488 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m22:14:21.182055 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m22:14:21.182645 [info ] [Thread-1  ]: 6 of 23 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m22:14:21.183369 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m22:14:21.183793 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m22:14:21.187250 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m22:14:21.188061 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m22:14:21.193654 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.inventory"
[0m22:14:21.194529 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:14:21.194953 [debug] [Thread-1  ]: On model.datawarehouse.inventory: BEGIN
[0m22:14:21.195363 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.200764 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:14:21.201300 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:14:21.201793 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."inventory"
  );
  
[0m22:14:21.205802 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:14:21.209835 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:14:21.210391 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m22:14:21.211559 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.215033 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:14:21.215500 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
alter table "datawarehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m22:14:21.216629 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.218735 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m22:14:21.219189 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:14:21.219590 [debug] [Thread-1  ]: On model.datawarehouse.inventory: COMMIT
[0m22:14:21.221493 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.224522 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m22:14:21.225427 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.inventory"
[0m22:14:21.226063 [debug] [Thread-1  ]: On model.datawarehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.inventory"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m22:14:21.228398 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.229944 [debug] [Thread-1  ]: On model.datawarehouse.inventory: Close
[0m22:14:21.230549 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11413a1c0>]}
[0m22:14:21.231242 [info ] [Thread-1  ]: 6 of 23 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.05s]
[0m22:14:21.231961 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m22:14:21.232524 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m22:14:21.233074 [info ] [Thread-1  ]: 7 of 23 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m22:14:21.233694 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m22:14:21.234146 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m22:14:21.237525 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m22:14:21.238752 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m22:14:21.248583 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_first_dbt_model"
[0m22:14:21.249604 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:14:21.250064 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: BEGIN
[0m22:14:21.250460 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.256515 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:21.257122 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:14:21.257639 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */

  
    

  create  table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:14:21.260331 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.002 seconds
[0m22:14:21.266530 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:14:21.267376 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:14:21.269271 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.274422 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:14:21.275068 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:14:21.276449 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.279105 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m22:14:21.279608 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:14:21.280338 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: COMMIT
[0m22:14:21.282320 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.285925 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m22:14:21.287109 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_first_dbt_model"
[0m22:14:21.287558 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_first_dbt_model"} */
drop table if exists "datawarehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m22:14:21.290521 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.292514 [debug] [Thread-1  ]: On model.datawarehouse.my_first_dbt_model: Close
[0m22:14:21.293258 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11400d6a0>]}
[0m22:14:21.294068 [info ] [Thread-1  ]: 7 of 23 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m22:14:21.295308 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m22:14:21.296270 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m22:14:21.297352 [info ] [Thread-1  ]: 8 of 23 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m22:14:21.298472 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m22:14:21.298995 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m22:14:21.304064 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m22:14:21.305123 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m22:14:21.312773 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.payment"
[0m22:14:21.313671 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:14:21.314121 [debug] [Thread-1  ]: On model.datawarehouse.payment: BEGIN
[0m22:14:21.314519 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.321269 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:21.321822 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:14:21.322258 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."payment"
  );
  
[0m22:14:21.332786 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.010 seconds
[0m22:14:21.336777 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:14:21.337237 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m22:14:21.338465 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.341959 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:14:21.342424 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
alter table "datawarehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m22:14:21.343851 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.345987 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m22:14:21.346547 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:14:21.346946 [debug] [Thread-1  ]: On model.datawarehouse.payment: COMMIT
[0m22:14:21.349861 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:14:21.354466 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m22:14:21.355397 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.payment"
[0m22:14:21.355827 [debug] [Thread-1  ]: On model.datawarehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.payment"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m22:14:21.358114 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.359664 [debug] [Thread-1  ]: On model.datawarehouse.payment: Close
[0m22:14:21.360362 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139df490>]}
[0m22:14:21.361077 [info ] [Thread-1  ]: 8 of 23 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.06s]
[0m22:14:21.361781 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m22:14:21.362385 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m22:14:21.362949 [info ] [Thread-1  ]: 9 of 23 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m22:14:21.364025 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m22:14:21.364820 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m22:14:21.369206 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m22:14:21.370099 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m22:14:21.374946 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.rental"
[0m22:14:21.375839 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:14:21.376491 [debug] [Thread-1  ]: On model.datawarehouse.rental: BEGIN
[0m22:14:21.377134 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.384465 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:14:21.384966 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:14:21.385386 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."rental"
  );
  
[0m22:14:21.398398 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.012 seconds
[0m22:14:21.402664 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:14:21.403222 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m22:14:21.404543 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.409560 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:14:21.410352 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
alter table "datawarehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m22:14:21.411966 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.414924 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m22:14:21.415442 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:14:21.415918 [debug] [Thread-1  ]: On model.datawarehouse.rental: COMMIT
[0m22:14:21.418364 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:14:21.422105 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m22:14:21.423031 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.rental"
[0m22:14:21.423451 [debug] [Thread-1  ]: On model.datawarehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.rental"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m22:14:21.425984 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.427670 [debug] [Thread-1  ]: On model.datawarehouse.rental: Close
[0m22:14:21.428407 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114151d00>]}
[0m22:14:21.429305 [info ] [Thread-1  ]: 9 of 23 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.06s]
[0m22:14:21.430031 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m22:14:21.430680 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m22:14:21.431212 [info ] [Thread-1  ]: 10 of 23 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m22:14:21.432377 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m22:14:21.433066 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m22:14:21.437493 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m22:14:21.438372 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m22:14:21.444675 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.staff"
[0m22:14:21.445586 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:14:21.446029 [debug] [Thread-1  ]: On model.datawarehouse.staff: BEGIN
[0m22:14:21.446426 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.453257 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:14:21.453865 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:14:21.454400 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."public"."staff"
  );
  
[0m22:14:21.458914 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m22:14:21.464894 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:14:21.465724 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m22:14:21.467353 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.473850 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:14:21.474647 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
alter table "datawarehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m22:14:21.476489 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.480153 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m22:14:21.480973 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:14:21.481713 [debug] [Thread-1  ]: On model.datawarehouse.staff: COMMIT
[0m22:14:21.483787 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.487045 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m22:14:21.488057 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.staff"
[0m22:14:21.488585 [debug] [Thread-1  ]: On model.datawarehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.staff"} */
drop table if exists "datawarehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m22:14:21.491463 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.493408 [debug] [Thread-1  ]: On model.datawarehouse.staff: Close
[0m22:14:21.494127 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114151d00>]}
[0m22:14:21.495247 [info ] [Thread-1  ]: 10 of 23 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m22:14:21.496321 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m22:14:21.497053 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m22:14:21.498059 [info ] [Thread-1  ]: 11 of 23 START sql table model dbt_dev_intermediete.dim_actor .................. [RUN]
[0m22:14:21.498948 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.dim_actor)
[0m22:14:21.499657 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m22:14:21.505652 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m22:14:21.506802 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m22:14:21.514170 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_actor"
[0m22:14:21.515519 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:14:21.516278 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: BEGIN
[0m22:14:21.517083 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.524094 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:14:21.524629 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:14:21.525065 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."actor"
  );
  
[0m22:14:21.527951 [debug] [Thread-1  ]: SQL status: SELECT 200 in 0.002 seconds
[0m22:14:21.533547 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:14:21.534062 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor" rename to "dim_actor__dbt_backup"
[0m22:14:21.535531 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.540274 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:14:21.540730 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m22:14:21.542051 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.544438 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m22:14:21.544974 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:14:21.545469 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: COMMIT
[0m22:14:21.546844 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.549968 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup"
[0m22:14:21.550893 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_actor"
[0m22:14:21.551320 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_actor__dbt_backup" cascade
[0m22:14:21.553271 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m22:14:21.554842 [debug] [Thread-1  ]: On model.datawarehouse.dim_actor: Close
[0m22:14:21.555448 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114151d00>]}
[0m22:14:21.556163 [info ] [Thread-1  ]: 11 of 23 OK created sql table model dbt_dev_intermediete.dim_actor ............. [[32mSELECT 200[0m in 0.06s]
[0m22:14:21.556910 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m22:14:21.557710 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m22:14:21.558476 [info ] [Thread-1  ]: 12 of 23 START sql table model dbt_dev_intermediete.dim_address ................ [RUN]
[0m22:14:21.559142 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m22:14:21.559650 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m22:14:21.563448 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m22:14:21.564286 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m22:14:21.569614 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_address"
[0m22:14:21.570524 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:14:21.570981 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: BEGIN
[0m22:14:21.571381 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.577329 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:21.577853 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:14:21.578316 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."address"
  );
  
[0m22:14:21.581027 [debug] [Thread-1  ]: SQL status: SELECT 603 in 0.002 seconds
[0m22:14:21.586089 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:14:21.586597 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address" rename to "dim_address__dbt_backup"
[0m22:14:21.587883 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.591430 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:14:21.591939 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_tmp" rename to "dim_address"
[0m22:14:21.593113 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.595442 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m22:14:21.595885 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:14:21.596293 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: COMMIT
[0m22:14:21.597771 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.600869 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup"
[0m22:14:21.601955 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_address"
[0m22:14:21.602413 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_address"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_address__dbt_backup" cascade
[0m22:14:21.604682 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.606459 [debug] [Thread-1  ]: On model.datawarehouse.dim_address: Close
[0m22:14:21.607197 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11417ccd0>]}
[0m22:14:21.608386 [info ] [Thread-1  ]: 12 of 23 OK created sql table model dbt_dev_intermediete.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m22:14:21.609527 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m22:14:21.610095 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m22:14:21.610731 [info ] [Thread-1  ]: 13 of 23 START sql table model dbt_dev_intermediete.dim_customer ............... [RUN]
[0m22:14:21.611326 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m22:14:21.611764 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m22:14:21.617205 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m22:14:21.618305 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m22:14:21.622975 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_customer"
[0m22:14:21.623840 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:14:21.624299 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: BEGIN
[0m22:14:21.624726 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.631190 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:21.631776 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:14:21.632332 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."customer"
  );
  
[0m22:14:21.634742 [debug] [Thread-1  ]: SQL status: SELECT 599 in 0.002 seconds
[0m22:14:21.638802 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:14:21.639309 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer" rename to "dim_customer__dbt_backup"
[0m22:14:21.640435 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.644699 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:14:21.645197 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m22:14:21.646371 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.648652 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m22:14:21.649468 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:14:21.650055 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: COMMIT
[0m22:14:21.651964 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.655899 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup"
[0m22:14:21.656996 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_customer"
[0m22:14:21.657431 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_customer"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_customer__dbt_backup" cascade
[0m22:14:21.659817 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.661529 [debug] [Thread-1  ]: On model.datawarehouse.dim_customer: Close
[0m22:14:21.662339 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139df490>]}
[0m22:14:21.663681 [info ] [Thread-1  ]: 13 of 23 OK created sql table model dbt_dev_intermediete.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m22:14:21.664804 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m22:14:21.665418 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m22:14:21.666049 [info ] [Thread-1  ]: 14 of 23 START sql table model dbt_dev_intermediete.dim_film ................... [RUN]
[0m22:14:21.666688 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m22:14:21.667202 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m22:14:21.671103 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m22:14:21.671936 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m22:14:21.677148 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film"
[0m22:14:21.678051 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:14:21.678625 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: BEGIN
[0m22:14:21.679107 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.684187 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:14:21.684693 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:14:21.685106 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film"
  );
  
[0m22:14:21.689830 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.004 seconds
[0m22:14:21.694803 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:14:21.695254 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film" rename to "dim_film__dbt_backup"
[0m22:14:21.696220 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.699565 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:14:21.699992 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_tmp" rename to "dim_film"
[0m22:14:21.700904 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.000 seconds
[0m22:14:21.703164 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m22:14:21.703643 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:14:21.704048 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: COMMIT
[0m22:14:21.705786 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.708887 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup"
[0m22:14:21.709768 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film"
[0m22:14:21.710186 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film__dbt_backup" cascade
[0m22:14:21.712397 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.713860 [debug] [Thread-1  ]: On model.datawarehouse.dim_film: Close
[0m22:14:21.714427 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139df490>]}
[0m22:14:21.715078 [info ] [Thread-1  ]: 14 of 23 OK created sql table model dbt_dev_intermediete.dim_film .............. [[32mSELECT 1000[0m in 0.05s]
[0m22:14:21.715739 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m22:14:21.716247 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m22:14:21.716851 [info ] [Thread-1  ]: 15 of 23 START sql table model dbt_dev_intermediete.dim_film_actor ............. [RUN]
[0m22:14:21.717385 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m22:14:21.717815 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m22:14:21.721245 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m22:14:21.722198 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m22:14:21.727269 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_film_actor"
[0m22:14:21.728572 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:14:21.729034 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: BEGIN
[0m22:14:21.729429 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.734762 [debug] [Thread-1  ]: SQL status: BEGIN in 0.005 seconds
[0m22:14:21.735264 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:14:21.735683 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m22:14:21.739931 [debug] [Thread-1  ]: SQL status: SELECT 5462 in 0.004 seconds
[0m22:14:21.743700 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:14:21.744266 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m22:14:21.745267 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.748832 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:14:21.749269 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m22:14:21.750228 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.752405 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m22:14:21.752938 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:14:21.753388 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: COMMIT
[0m22:14:21.755558 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:14:21.758906 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup"
[0m22:14:21.759854 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_film_actor"
[0m22:14:21.760271 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_film_actor"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_film_actor__dbt_backup" cascade
[0m22:14:21.762563 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.764119 [debug] [Thread-1  ]: On model.datawarehouse.dim_film_actor: Close
[0m22:14:21.764757 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139db640>]}
[0m22:14:21.765471 [info ] [Thread-1  ]: 15 of 23 OK created sql table model dbt_dev_intermediete.dim_film_actor ........ [[32mSELECT 5462[0m in 0.05s]
[0m22:14:21.766426 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m22:14:21.767102 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m22:14:21.767738 [info ] [Thread-1  ]: 16 of 23 START sql table model dbt_dev_intermediete.dim_inventory .............. [RUN]
[0m22:14:21.768431 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m22:14:21.768928 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m22:14:21.775396 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m22:14:21.776687 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m22:14:21.781631 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_inventory"
[0m22:14:21.782505 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:14:21.782951 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: BEGIN
[0m22:14:21.783345 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.789132 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:21.789676 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:14:21.790092 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."inventory"
  );
  
[0m22:14:21.794263 [debug] [Thread-1  ]: SQL status: SELECT 4581 in 0.004 seconds
[0m22:14:21.797969 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:14:21.798445 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m22:14:21.799532 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.803152 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:14:21.803670 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m22:14:21.804880 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.807055 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m22:14:21.807521 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:14:21.807944 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: COMMIT
[0m22:14:21.809497 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.812671 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup"
[0m22:14:21.813740 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_inventory"
[0m22:14:21.814195 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_inventory"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_inventory__dbt_backup" cascade
[0m22:14:21.816624 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.818250 [debug] [Thread-1  ]: On model.datawarehouse.dim_inventory: Close
[0m22:14:21.819004 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114139ac0>]}
[0m22:14:21.819878 [info ] [Thread-1  ]: 16 of 23 OK created sql table model dbt_dev_intermediete.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m22:14:21.820920 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m22:14:21.821581 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m22:14:21.822272 [info ] [Thread-1  ]: 17 of 23 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m22:14:21.822835 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m22:14:21.823374 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m22:14:21.827751 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m22:14:21.828811 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m22:14:21.851880 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.my_second_dbt_model"
[0m22:14:21.852820 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:14:21.853247 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: BEGIN
[0m22:14:21.853664 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.861560 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:14:21.862466 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:14:21.863409 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */

  create view "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "datawarehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m22:14:21.866187 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.002 seconds
[0m22:14:21.872050 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:14:21.872757 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
alter table "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:14:21.874380 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.876834 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m22:14:21.877383 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:14:21.877863 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: COMMIT
[0m22:14:21.879579 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:21.882910 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m22:14:21.886134 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.my_second_dbt_model"
[0m22:14:21.886602 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.my_second_dbt_model"} */
drop view if exists "datawarehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m22:14:21.887996 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.001 seconds
[0m22:14:21.889918 [debug] [Thread-1  ]: On model.datawarehouse.my_second_dbt_model: Close
[0m22:14:21.890622 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114122820>]}
[0m22:14:21.891431 [info ] [Thread-1  ]: 17 of 23 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m22:14:21.892226 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m22:14:21.892945 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m22:14:21.893492 [info ] [Thread-1  ]: 18 of 23 START sql table model dbt_dev_intermediete.fact_payment ............... [RUN]
[0m22:14:21.894150 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now model.datawarehouse.fact_payment)
[0m22:14:21.894597 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m22:14:21.898398 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m22:14:21.899499 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m22:14:21.905028 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.fact_payment"
[0m22:14:21.906232 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:14:21.906663 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: BEGIN
[0m22:14:21.907049 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.914068 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:14:21.914768 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:14:21.915257 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."payment"
  );
  
[0m22:14:21.926326 [debug] [Thread-1  ]: SQL status: SELECT 14596 in 0.010 seconds
[0m22:14:21.930751 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:14:21.931274 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment" rename to "fact_payment__dbt_backup"
[0m22:14:21.933889 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.002 seconds
[0m22:14:21.939564 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:14:21.940096 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
alter table "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m22:14:21.941710 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:21.944093 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m22:14:21.944647 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:14:21.945098 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: COMMIT
[0m22:14:21.948400 [debug] [Thread-1  ]: SQL status: COMMIT in 0.003 seconds
[0m22:14:21.952462 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup"
[0m22:14:21.955903 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.fact_payment"
[0m22:14:21.956680 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.fact_payment"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."fact_payment__dbt_backup" cascade
[0m22:14:21.959624 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:21.961201 [debug] [Thread-1  ]: On model.datawarehouse.fact_payment: Close
[0m22:14:21.961949 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114252280>]}
[0m22:14:21.962709 [info ] [Thread-1  ]: 18 of 23 OK created sql table model dbt_dev_intermediete.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m22:14:21.963510 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m22:14:21.964347 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m22:14:21.965122 [info ] [Thread-1  ]: 19 of 23 START sql table model dbt_dev_intermediete.dim_rental ................. [RUN]
[0m22:14:21.965982 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m22:14:21.966615 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m22:14:21.971212 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m22:14:21.972595 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m22:14:21.978749 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_rental"
[0m22:14:21.979897 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:14:21.980388 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: BEGIN
[0m22:14:21.980799 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:21.987732 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:14:21.988274 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:14:21.988723 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."rental"
  );
  
[0m22:14:22.004837 [debug] [Thread-1  ]: SQL status: SELECT 16044 in 0.015 seconds
[0m22:14:22.011467 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:14:22.012277 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental" rename to "dim_rental__dbt_backup"
[0m22:14:22.013844 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.019404 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:14:22.019887 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m22:14:22.021163 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.023731 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m22:14:22.024250 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:14:22.024709 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: COMMIT
[0m22:14:22.027050 [debug] [Thread-1  ]: SQL status: COMMIT in 0.002 seconds
[0m22:14:22.030547 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup"
[0m22:14:22.031487 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_rental"
[0m22:14:22.031908 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_rental"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_rental__dbt_backup" cascade
[0m22:14:22.034980 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.003 seconds
[0m22:14:22.036744 [debug] [Thread-1  ]: On model.datawarehouse.dim_rental: Close
[0m22:14:22.037525 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114152820>]}
[0m22:14:22.038408 [info ] [Thread-1  ]: 19 of 23 OK created sql table model dbt_dev_intermediete.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m22:14:22.039351 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m22:14:22.040012 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m22:14:22.040885 [info ] [Thread-1  ]: 20 of 23 START sql table model dbt_dev_intermediete.dim_staff .................. [RUN]
[0m22:14:22.041790 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m22:14:22.042437 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m22:14:22.046322 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m22:14:22.047423 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m22:14:22.054258 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.dim_staff"
[0m22:14:22.055217 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:14:22.055664 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: BEGIN
[0m22:14:22.056057 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:22.064193 [debug] [Thread-1  ]: SQL status: BEGIN in 0.008 seconds
[0m22:14:22.065052 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:14:22.065817 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */

  
    

  create  table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    

SELECT * FROM "datawarehouse"."dbt_dev_raw"."staff"
  );
  
[0m22:14:22.070451 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.004 seconds
[0m22:14:22.075012 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:14:22.075930 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff" rename to "dim_staff__dbt_backup"
[0m22:14:22.077732 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.082709 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:14:22.083231 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
alter table "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m22:14:22.084692 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.087143 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m22:14:22.087636 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:14:22.088044 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: COMMIT
[0m22:14:22.089609 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:22.092713 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup"
[0m22:14:22.093739 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.dim_staff"
[0m22:14:22.094177 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.dim_staff"} */
drop table if exists "datawarehouse"."dbt_dev_intermediete"."dim_staff__dbt_backup" cascade
[0m22:14:22.096602 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:22.098168 [debug] [Thread-1  ]: On model.datawarehouse.dim_staff: Close
[0m22:14:22.098839 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114252280>]}
[0m22:14:22.099700 [info ] [Thread-1  ]: 20 of 23 OK created sql table model dbt_dev_intermediete.dim_staff ............. [[32mSELECT 2[0m in 0.06s]
[0m22:14:22.100486 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m22:14:22.101051 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor_most_roles_play
[0m22:14:22.101715 [info ] [Thread-1  ]: 21 of 23 START sql table model dbt_dev_mart.actor_most_roles_play .............. [RUN]
[0m22:14:22.102279 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_staff, now model.datawarehouse.actor_most_roles_play)
[0m22:14:22.102747 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor_most_roles_play
[0m22:14:22.106890 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor_most_roles_play"
[0m22:14:22.107727 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor_most_roles_play
[0m22:14:22.114279 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.actor_most_roles_play"
[0m22:14:22.115249 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor_most_roles_play"
[0m22:14:22.115714 [debug] [Thread-1  ]: On model.datawarehouse.actor_most_roles_play: BEGIN
[0m22:14:22.116114 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:22.123248 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:14:22.123858 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor_most_roles_play"
[0m22:14:22.124511 [debug] [Thread-1  ]: On model.datawarehouse.actor_most_roles_play: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor_most_roles_play"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."actor_most_roles_play__dbt_tmp"
  
  
    as
  
  (
    

select
	concat(first_name, ' ', last_name) as actor_name,
	count(distinct film_id) as total_film
from "datawarehouse"."dbt_dev_intermediete"."dim_film_actor" dfa 
left join "datawarehouse"."dbt_dev_intermediete"."dim_actor" da on dfa.actor_id = da.actor_id
group by 1
order by 2 desc
  );
  
[0m22:14:22.139116 [debug] [Thread-1  ]: SQL status: SELECT 199 in 0.014 seconds
[0m22:14:22.143062 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor_most_roles_play"
[0m22:14:22.143508 [debug] [Thread-1  ]: On model.datawarehouse.actor_most_roles_play: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor_most_roles_play"} */
alter table "datawarehouse"."dbt_dev_mart"."actor_most_roles_play__dbt_tmp" rename to "actor_most_roles_play"
[0m22:14:22.145021 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.147328 [debug] [Thread-1  ]: On model.datawarehouse.actor_most_roles_play: COMMIT
[0m22:14:22.147843 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor_most_roles_play"
[0m22:14:22.148349 [debug] [Thread-1  ]: On model.datawarehouse.actor_most_roles_play: COMMIT
[0m22:14:22.150285 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:22.155283 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_mart"."actor_most_roles_play__dbt_backup"
[0m22:14:22.158874 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.actor_most_roles_play"
[0m22:14:22.159811 [debug] [Thread-1  ]: On model.datawarehouse.actor_most_roles_play: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.actor_most_roles_play"} */
drop table if exists "datawarehouse"."dbt_dev_mart"."actor_most_roles_play__dbt_backup" cascade
[0m22:14:22.161224 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.001 seconds
[0m22:14:22.164146 [debug] [Thread-1  ]: On model.datawarehouse.actor_most_roles_play: Close
[0m22:14:22.165320 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142877f0>]}
[0m22:14:22.166737 [info ] [Thread-1  ]: 21 of 23 OK created sql table model dbt_dev_mart.actor_most_roles_play ......... [[32mSELECT 199[0m in 0.06s]
[0m22:14:22.167959 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor_most_roles_play
[0m22:14:22.168763 [debug] [Thread-1  ]: Began running node model.datawarehouse.total_revenue
[0m22:14:22.169450 [info ] [Thread-1  ]: 22 of 23 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m22:14:22.170105 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor_most_roles_play, now model.datawarehouse.total_revenue)
[0m22:14:22.170600 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.total_revenue
[0m22:14:22.175943 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.total_revenue"
[0m22:14:22.177261 [debug] [Thread-1  ]: Began executing node model.datawarehouse.total_revenue
[0m22:14:22.183715 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.total_revenue"
[0m22:14:22.193379 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:14:22.194413 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: BEGIN
[0m22:14:22.195118 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:22.202333 [debug] [Thread-1  ]: SQL status: BEGIN in 0.007 seconds
[0m22:14:22.202865 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:14:22.203589 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    date_trunc('month', payment_date) as month_year,
    sum(amount) as total_revenue
FROM "datawarehouse"."dbt_dev_intermediete"."fact_payment"
GROUP BY 1
ORDER BY 1
  );
  
[0m22:14:22.213776 [debug] [Thread-1  ]: SQL status: SELECT 4 in 0.010 seconds
[0m22:14:22.218226 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:14:22.218729 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
alter table "datawarehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m22:14:22.219873 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.223404 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:14:22.223926 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
alter table "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m22:14:22.225327 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.227487 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: COMMIT
[0m22:14:22.227960 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:14:22.228362 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: COMMIT
[0m22:14:22.230000 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:22.233071 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m22:14:22.234032 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.total_revenue"
[0m22:14:22.234486 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.total_revenue"} */
drop table if exists "datawarehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m22:14:22.236747 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:22.238294 [debug] [Thread-1  ]: On model.datawarehouse.total_revenue: Close
[0m22:14:22.238894 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114260310>]}
[0m22:14:22.239641 [info ] [Thread-1  ]: 22 of 23 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 4[0m in 0.07s]
[0m22:14:22.240409 [debug] [Thread-1  ]: Finished running node model.datawarehouse.total_revenue
[0m22:14:22.241010 [debug] [Thread-1  ]: Began running node model.datawarehouse.best_selling_film
[0m22:14:22.241560 [info ] [Thread-1  ]: 23 of 23 START sql table model dbt_dev_mart.best_selling_film .................. [RUN]
[0m22:14:22.242195 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.total_revenue, now model.datawarehouse.best_selling_film)
[0m22:14:22.242640 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.best_selling_film
[0m22:14:22.246923 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.best_selling_film"
[0m22:14:22.247801 [debug] [Thread-1  ]: Began executing node model.datawarehouse.best_selling_film
[0m22:14:22.253137 [debug] [Thread-1  ]: Writing runtime sql for node "model.datawarehouse.best_selling_film"
[0m22:14:22.254004 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:14:22.254427 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: BEGIN
[0m22:14:22.254817 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:14:22.261051 [debug] [Thread-1  ]: SQL status: BEGIN in 0.006 seconds
[0m22:14:22.261566 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:14:22.262007 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.best_selling_film"} */

  
    

  create  table "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
	title  as film_name,
	count(distinct rental_id) as total_rental 
FROM "datawarehouse"."dbt_dev_intermediete"."dim_film" df 
left join "datawarehouse"."dbt_dev_intermediete"."dim_inventory" inv on df.film_id  = inv.film_id 
left join "datawarehouse"."dbt_dev_intermediete"."dim_rental" dr on inv.inventory_id  = dr.inventory_id 
group by 1
order by 2 desc
  );
  
[0m22:14:22.530082 [debug] [Thread-1  ]: SQL status: SELECT 1000 in 0.266 seconds
[0m22:14:22.533834 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:14:22.534256 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.best_selling_film"} */
alter table "datawarehouse"."dbt_dev_mart"."best_selling_film" rename to "best_selling_film__dbt_backup"
[0m22:14:22.535467 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.539011 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:14:22.539437 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.best_selling_film"} */
alter table "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_tmp" rename to "best_selling_film"
[0m22:14:22.540609 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:14:22.542558 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: COMMIT
[0m22:14:22.542967 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:14:22.543355 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: COMMIT
[0m22:14:22.545097 [debug] [Thread-1  ]: SQL status: COMMIT in 0.001 seconds
[0m22:14:22.548047 [debug] [Thread-1  ]: Applying DROP to: "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_backup"
[0m22:14:22.548967 [debug] [Thread-1  ]: Using postgres connection "model.datawarehouse.best_selling_film"
[0m22:14:22.549369 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "node_id": "model.datawarehouse.best_selling_film"} */
drop table if exists "datawarehouse"."dbt_dev_mart"."best_selling_film__dbt_backup" cascade
[0m22:14:22.551674 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.002 seconds
[0m22:14:22.553110 [debug] [Thread-1  ]: On model.datawarehouse.best_selling_film: Close
[0m22:14:22.553775 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c66e374b-110c-4835-9493-224ecca085d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139df490>]}
[0m22:14:25.899403 [info ] [Thread-1  ]: 23 of 23 OK created sql table model dbt_dev_mart.best_selling_film ............. [[32mSELECT 1000[0m in 0.31s]
[0m22:14:25.900675 [debug] [Thread-1  ]: Finished running node model.datawarehouse.best_selling_film
[0m22:14:25.902647 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:25.903184 [debug] [MainThread]: On master: BEGIN
[0m22:14:25.903663 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:14:25.912177 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m22:14:25.912844 [debug] [MainThread]: On master: COMMIT
[0m22:14:25.913502 [debug] [MainThread]: Using postgres connection "master"
[0m22:14:25.913923 [debug] [MainThread]: On master: COMMIT
[0m22:14:25.914861 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:14:25.915272 [debug] [MainThread]: On master: Close
[0m22:14:25.915816 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:14:25.916194 [debug] [MainThread]: Connection 'model.datawarehouse.best_selling_film' was properly closed.
[0m22:14:25.916717 [info ] [MainThread]: 
[0m22:14:25.917272 [info ] [MainThread]: Finished running 22 table models, 1 view model in 0 hours 0 minutes and 5.39 seconds (5.39s).
[0m22:14:25.922313 [debug] [MainThread]: Command end result
[0m22:14:26.023389 [info ] [MainThread]: 
[0m22:14:26.023944 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:14:26.024402 [info ] [MainThread]: 
[0m22:14:26.024898 [info ] [MainThread]: Done. PASS=23 WARN=0 ERROR=0 SKIP=0 TOTAL=23
[0m22:14:26.026962 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.5832887, "process_user_time": 3.667115, "process_kernel_time": 0.46931, "process_mem_max_rss": "110657536", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:14:26.027684 [debug] [MainThread]: Command `dbt run` succeeded at 22:14:26.027570 after 6.58 seconds
[0m22:14:26.028133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11131a2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131759d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113175b80>]}
[0m22:14:26.028558 [debug] [MainThread]: Flushing usage events
[0m22:15:45.134321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067cb2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082edb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082ed820>]}


============================== 22:15:45.142046 | e0d9beb6-879b-4602-8298-253277b5106b ==============================
[0m22:15:45.142046 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:15:45.142797 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'debug': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt docs generate', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:15:45.323319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e0d9beb6-879b-4602-8298-253277b5106b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a76f10>]}
[0m22:15:45.387053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e0d9beb6-879b-4602-8298-253277b5106b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108679d90>]}
[0m22:15:45.388015 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m22:15:45.407423 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m22:15:45.590180 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:15:45.590747 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:15:45.655527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0d9beb6-879b-4602-8298-253277b5106b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108efd130>]}
[0m22:15:45.673931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0d9beb6-879b-4602-8298-253277b5106b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f21790>]}
[0m22:15:45.674782 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m22:15:45.675261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0d9beb6-879b-4602-8298-253277b5106b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f21730>]}
[0m22:15:45.678454 [info ] [MainThread]: 
[0m22:15:45.679136 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:15:45.686232 [debug] [ThreadPool]: Acquiring new postgres connection 'list_datawarehouse_dbt_dev_mart'
[0m22:15:45.755474 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m22:15:45.756015 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: BEGIN
[0m22:15:45.756474 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:15:45.777755 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m22:15:45.778260 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_mart"
[0m22:15:45.778641 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_mart"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m22:15:45.781998 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.003 seconds
[0m22:15:45.783528 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: ROLLBACK
[0m22:15:45.784241 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_mart: Close
[0m22:15:45.784908 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_mart, now list_datawarehouse_dbt_dev)
[0m22:15:45.788084 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m22:15:45.788491 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: BEGIN
[0m22:15:45.788839 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:15:45.793494 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:15:45.793955 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev"
[0m22:15:45.794355 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m22:15:45.797512 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m22:15:45.798964 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: ROLLBACK
[0m22:15:45.799671 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev: Close
[0m22:15:45.800324 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev, now list_datawarehouse_dbt_dev_raw)
[0m22:15:45.803173 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m22:15:45.803572 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: BEGIN
[0m22:15:45.803908 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:15:45.808698 [debug] [ThreadPool]: SQL status: BEGIN in 0.005 seconds
[0m22:15:45.809169 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_raw"
[0m22:15:45.809560 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_raw"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m22:15:45.812568 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:15:45.814117 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: ROLLBACK
[0m22:15:45.814846 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_raw: Close
[0m22:15:45.815482 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_raw, now list_datawarehouse_dbt_dev_intermediete)
[0m22:15:45.819608 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m22:15:45.819999 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: BEGIN
[0m22:15:45.820349 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:15:45.826045 [debug] [ThreadPool]: SQL status: BEGIN in 0.006 seconds
[0m22:15:45.826517 [debug] [ThreadPool]: Using postgres connection "list_datawarehouse_dbt_dev_intermediete"
[0m22:15:45.826913 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "list_datawarehouse_dbt_dev_intermediete"} */
select
      'datawarehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediete'
    union all
    select
      'datawarehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediete'
  
[0m22:15:45.829939 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m22:15:45.831627 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: ROLLBACK
[0m22:15:45.832583 [debug] [ThreadPool]: On list_datawarehouse_dbt_dev_intermediete: Close
[0m22:15:45.840852 [debug] [MainThread]: Using postgres connection "master"
[0m22:15:45.841345 [debug] [MainThread]: On master: BEGIN
[0m22:15:45.841703 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:15:45.846871 [debug] [MainThread]: SQL status: BEGIN in 0.005 seconds
[0m22:15:45.847358 [debug] [MainThread]: Using postgres connection "master"
[0m22:15:45.847815 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:15:45.854942 [debug] [MainThread]: SQL status: SELECT 38 in 0.007 seconds
[0m22:15:45.857779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0d9beb6-879b-4602-8298-253277b5106b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10829da90>]}
[0m22:15:45.858283 [debug] [MainThread]: On master: ROLLBACK
[0m22:15:45.859311 [debug] [MainThread]: On master: Close
[0m22:15:45.859850 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:15:45.860357 [info ] [MainThread]: 
[0m22:15:45.862665 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor
[0m22:15:45.863259 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_datawarehouse_dbt_dev_intermediete, now model.datawarehouse.actor)
[0m22:15:45.863721 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor
[0m22:15:45.876046 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor"
[0m22:15:45.877011 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor
[0m22:15:45.877904 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor
[0m22:15:45.878478 [debug] [Thread-1  ]: Began running node model.datawarehouse.address
[0m22:15:45.878962 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor, now model.datawarehouse.address)
[0m22:15:45.879602 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.address
[0m22:15:45.884244 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.address"
[0m22:15:45.885199 [debug] [Thread-1  ]: Began executing node model.datawarehouse.address
[0m22:15:45.886004 [debug] [Thread-1  ]: Finished running node model.datawarehouse.address
[0m22:15:45.886469 [debug] [Thread-1  ]: Began running node model.datawarehouse.customer
[0m22:15:45.887024 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.address, now model.datawarehouse.customer)
[0m22:15:45.887460 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.customer
[0m22:15:45.891320 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.customer"
[0m22:15:45.892340 [debug] [Thread-1  ]: Began executing node model.datawarehouse.customer
[0m22:15:45.893185 [debug] [Thread-1  ]: Finished running node model.datawarehouse.customer
[0m22:15:45.893645 [debug] [Thread-1  ]: Began running node model.datawarehouse.film
[0m22:15:45.894098 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.customer, now model.datawarehouse.film)
[0m22:15:45.894507 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film
[0m22:15:45.898223 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film"
[0m22:15:45.899014 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film
[0m22:15:45.899776 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film
[0m22:15:45.900230 [debug] [Thread-1  ]: Began running node model.datawarehouse.film_actor
[0m22:15:45.900674 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film, now model.datawarehouse.film_actor)
[0m22:15:45.901115 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.film_actor
[0m22:15:45.904730 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.film_actor"
[0m22:15:45.905751 [debug] [Thread-1  ]: Began executing node model.datawarehouse.film_actor
[0m22:15:45.906826 [debug] [Thread-1  ]: Finished running node model.datawarehouse.film_actor
[0m22:15:45.907352 [debug] [Thread-1  ]: Began running node model.datawarehouse.inventory
[0m22:15:45.907803 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.film_actor, now model.datawarehouse.inventory)
[0m22:15:45.908250 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.inventory
[0m22:15:45.911882 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.inventory"
[0m22:15:45.912765 [debug] [Thread-1  ]: Began executing node model.datawarehouse.inventory
[0m22:15:45.913604 [debug] [Thread-1  ]: Finished running node model.datawarehouse.inventory
[0m22:15:45.914206 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_first_dbt_model
[0m22:15:45.914676 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.inventory, now model.datawarehouse.my_first_dbt_model)
[0m22:15:45.915092 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_first_dbt_model
[0m22:15:45.918202 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_first_dbt_model"
[0m22:15:45.919101 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_first_dbt_model
[0m22:15:45.919865 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_first_dbt_model
[0m22:15:45.920358 [debug] [Thread-1  ]: Began running node model.datawarehouse.payment
[0m22:15:45.920824 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_first_dbt_model, now model.datawarehouse.payment)
[0m22:15:45.921246 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.payment
[0m22:15:45.925085 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.payment"
[0m22:15:45.926097 [debug] [Thread-1  ]: Began executing node model.datawarehouse.payment
[0m22:15:45.926905 [debug] [Thread-1  ]: Finished running node model.datawarehouse.payment
[0m22:15:45.927370 [debug] [Thread-1  ]: Began running node model.datawarehouse.rental
[0m22:15:45.927826 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.payment, now model.datawarehouse.rental)
[0m22:15:45.928237 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.rental
[0m22:15:45.931968 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.rental"
[0m22:15:45.932808 [debug] [Thread-1  ]: Began executing node model.datawarehouse.rental
[0m22:15:45.933553 [debug] [Thread-1  ]: Finished running node model.datawarehouse.rental
[0m22:15:45.934001 [debug] [Thread-1  ]: Began running node model.datawarehouse.staff
[0m22:15:45.935749 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.rental, now model.datawarehouse.staff)
[0m22:15:45.936184 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.staff
[0m22:15:45.940243 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.staff"
[0m22:15:45.941223 [debug] [Thread-1  ]: Began executing node model.datawarehouse.staff
[0m22:15:45.942008 [debug] [Thread-1  ]: Finished running node model.datawarehouse.staff
[0m22:15:45.942462 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_actor
[0m22:15:45.942905 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.staff, now model.datawarehouse.dim_actor)
[0m22:15:45.943324 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_actor
[0m22:15:45.946841 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_actor"
[0m22:15:45.947795 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_actor
[0m22:15:45.948575 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_actor
[0m22:15:45.949028 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_address
[0m22:15:45.949465 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_actor, now model.datawarehouse.dim_address)
[0m22:15:45.949864 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_address
[0m22:15:45.953246 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_address"
[0m22:15:45.954009 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_address
[0m22:15:45.954741 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_address
[0m22:15:45.955305 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_customer
[0m22:15:45.955914 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_address, now model.datawarehouse.dim_customer)
[0m22:15:45.956403 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_customer
[0m22:15:45.959973 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_customer"
[0m22:15:45.961058 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_customer
[0m22:15:45.961858 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_customer
[0m22:15:45.962644 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film
[0m22:15:45.963284 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_customer, now model.datawarehouse.dim_film)
[0m22:15:45.963774 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film
[0m22:15:45.967256 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film"
[0m22:15:45.968022 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film
[0m22:15:45.968789 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film
[0m22:15:45.969256 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_film_actor
[0m22:15:45.969703 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film, now model.datawarehouse.dim_film_actor)
[0m22:15:45.970118 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_film_actor
[0m22:15:45.973730 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_film_actor"
[0m22:15:45.974581 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_film_actor
[0m22:15:45.975395 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_film_actor
[0m22:15:45.975852 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_inventory
[0m22:15:45.976293 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_film_actor, now model.datawarehouse.dim_inventory)
[0m22:15:45.976739 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_inventory
[0m22:15:45.979928 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_inventory"
[0m22:15:45.980978 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_inventory
[0m22:15:45.981957 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_inventory
[0m22:15:45.982412 [debug] [Thread-1  ]: Began running node model.datawarehouse.my_second_dbt_model
[0m22:15:45.982852 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_inventory, now model.datawarehouse.my_second_dbt_model)
[0m22:15:45.983342 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.my_second_dbt_model
[0m22:15:45.988303 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.my_second_dbt_model"
[0m22:15:45.989291 [debug] [Thread-1  ]: Began executing node model.datawarehouse.my_second_dbt_model
[0m22:15:45.990064 [debug] [Thread-1  ]: Finished running node model.datawarehouse.my_second_dbt_model
[0m22:15:45.990527 [debug] [Thread-1  ]: Began running node test.datawarehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:15:45.990977 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.my_second_dbt_model, now test.datawarehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m22:15:45.991437 [debug] [Thread-1  ]: Began compiling node test.datawarehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:15:46.004536 [debug] [Thread-1  ]: Writing injected SQL for node "test.datawarehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m22:15:46.006027 [debug] [Thread-1  ]: Began executing node test.datawarehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:15:46.007274 [debug] [Thread-1  ]: Finished running node test.datawarehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m22:15:46.008017 [debug] [Thread-1  ]: Began running node test.datawarehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:15:46.008540 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.datawarehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.datawarehouse.unique_my_first_dbt_model_id.16e066b321)
[0m22:15:46.009182 [debug] [Thread-1  ]: Began compiling node test.datawarehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:15:46.016584 [debug] [Thread-1  ]: Writing injected SQL for node "test.datawarehouse.unique_my_first_dbt_model_id.16e066b321"
[0m22:15:46.017633 [debug] [Thread-1  ]: Began executing node test.datawarehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:15:46.018741 [debug] [Thread-1  ]: Finished running node test.datawarehouse.unique_my_first_dbt_model_id.16e066b321
[0m22:15:46.019292 [debug] [Thread-1  ]: Began running node model.datawarehouse.fact_payment
[0m22:15:46.019869 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.datawarehouse.unique_my_first_dbt_model_id.16e066b321, now model.datawarehouse.fact_payment)
[0m22:15:46.020328 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.fact_payment
[0m22:15:46.024545 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.fact_payment"
[0m22:15:46.025406 [debug] [Thread-1  ]: Began executing node model.datawarehouse.fact_payment
[0m22:15:46.026222 [debug] [Thread-1  ]: Finished running node model.datawarehouse.fact_payment
[0m22:15:46.026718 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_rental
[0m22:15:46.027260 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.fact_payment, now model.datawarehouse.dim_rental)
[0m22:15:46.027774 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_rental
[0m22:15:46.032299 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_rental"
[0m22:15:46.033136 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_rental
[0m22:15:46.033949 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_rental
[0m22:15:46.034430 [debug] [Thread-1  ]: Began running node model.datawarehouse.dim_staff
[0m22:15:46.034946 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_rental, now model.datawarehouse.dim_staff)
[0m22:15:46.035376 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.dim_staff
[0m22:15:46.038913 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.dim_staff"
[0m22:15:46.039726 [debug] [Thread-1  ]: Began executing node model.datawarehouse.dim_staff
[0m22:15:46.040506 [debug] [Thread-1  ]: Finished running node model.datawarehouse.dim_staff
[0m22:15:46.040975 [debug] [Thread-1  ]: Began running node model.datawarehouse.actor_most_roles_play
[0m22:15:46.041425 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.dim_staff, now model.datawarehouse.actor_most_roles_play)
[0m22:15:46.041842 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.actor_most_roles_play
[0m22:15:46.045530 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.actor_most_roles_play"
[0m22:15:46.046336 [debug] [Thread-1  ]: Began executing node model.datawarehouse.actor_most_roles_play
[0m22:15:46.047155 [debug] [Thread-1  ]: Finished running node model.datawarehouse.actor_most_roles_play
[0m22:15:46.047630 [debug] [Thread-1  ]: Began running node test.datawarehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:15:46.048087 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.actor_most_roles_play, now test.datawarehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m22:15:46.048499 [debug] [Thread-1  ]: Began compiling node test.datawarehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:15:46.052869 [debug] [Thread-1  ]: Writing injected SQL for node "test.datawarehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m22:15:46.053815 [debug] [Thread-1  ]: Began executing node test.datawarehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:15:46.054608 [debug] [Thread-1  ]: Finished running node test.datawarehouse.not_null_my_second_dbt_model_id.151b76d778
[0m22:15:46.055058 [debug] [Thread-1  ]: Began running node test.datawarehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:15:46.055647 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.datawarehouse.not_null_my_second_dbt_model_id.151b76d778, now test.datawarehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m22:15:46.056599 [debug] [Thread-1  ]: Began compiling node test.datawarehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:15:46.110943 [debug] [Thread-1  ]: Writing injected SQL for node "test.datawarehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m22:15:46.111799 [debug] [Thread-1  ]: Began executing node test.datawarehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:15:46.112601 [debug] [Thread-1  ]: Finished running node test.datawarehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m22:15:46.113178 [debug] [Thread-1  ]: Began running node model.datawarehouse.total_revenue
[0m22:15:46.113645 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.datawarehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.datawarehouse.total_revenue)
[0m22:15:46.114070 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.total_revenue
[0m22:15:46.118956 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.total_revenue"
[0m22:15:46.120479 [debug] [Thread-1  ]: Began executing node model.datawarehouse.total_revenue
[0m22:15:46.122069 [debug] [Thread-1  ]: Finished running node model.datawarehouse.total_revenue
[0m22:15:46.123030 [debug] [Thread-1  ]: Began running node model.datawarehouse.best_selling_film
[0m22:15:46.124034 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.datawarehouse.total_revenue, now model.datawarehouse.best_selling_film)
[0m22:15:46.124842 [debug] [Thread-1  ]: Began compiling node model.datawarehouse.best_selling_film
[0m22:15:46.132012 [debug] [Thread-1  ]: Writing injected SQL for node "model.datawarehouse.best_selling_film"
[0m22:15:46.133392 [debug] [Thread-1  ]: Began executing node model.datawarehouse.best_selling_film
[0m22:15:46.134789 [debug] [Thread-1  ]: Finished running node model.datawarehouse.best_selling_film
[0m22:15:46.136161 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:15:46.136567 [debug] [MainThread]: Connection 'model.datawarehouse.best_selling_film' was properly closed.
[0m22:15:46.142875 [debug] [MainThread]: Command end result
[0m22:15:46.309352 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m22:15:46.310156 [info ] [MainThread]: Building catalog
[0m22:15:46.338786 [debug] [ThreadPool]: Acquiring new postgres connection 'datawarehouse.information_schema'
[0m22:15:46.374030 [debug] [ThreadPool]: Using postgres connection "datawarehouse.information_schema"
[0m22:15:46.374680 [debug] [ThreadPool]: On datawarehouse.information_schema: BEGIN
[0m22:15:46.375259 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:15:46.383426 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m22:15:46.384144 [debug] [ThreadPool]: Using postgres connection "datawarehouse.information_schema"
[0m22:15:46.384798 [debug] [ThreadPool]: On datawarehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "datawarehouse", "target_name": "dev", "connection_name": "datawarehouse.information_schema"} */

    
    

    select
        'datawarehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_inventory')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('total_revenue')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('best_selling_film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('dbt_dev_mart') and
           upper(tbl.relname) = upper('actor_most_roles_play')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_first_dbt_model')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_address')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('inventory')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_film_actor')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('customer')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film_actor')) or (upper(sch.nspname) = upper('dbt_dev_raw') and
           upper(tbl.relname) = upper('staff')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_rental')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('rental')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('fact_payment')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('payment')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('address')) or (upper(sch.nspname) = upper('dbt_dev') and
           upper(tbl.relname) = upper('my_second_dbt_model')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('film')) or (upper(sch.nspname) = upper('public') and
           upper(tbl.relname) = upper('actor')) or (upper(sch.nspname) = upper('dbt_dev_intermediete') and
           upper(tbl.relname) = upper('dim_staff')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m22:15:46.393863 [debug] [ThreadPool]: SQL status: SELECT 206 in 0.008 seconds
[0m22:15:46.421982 [debug] [ThreadPool]: On datawarehouse.information_schema: ROLLBACK
[0m22:15:46.423436 [debug] [ThreadPool]: On datawarehouse.information_schema: Close
[0m22:15:46.505824 [info ] [MainThread]: Catalog written to /Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/target/catalog.json
[0m22:15:46.507613 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.4510654, "process_user_time": 2.553443, "process_kernel_time": 0.314341, "process_mem_max_rss": "105267200", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:15:46.508412 [debug] [MainThread]: Command `dbt docs generate` succeeded at 22:15:46.508294 after 1.45 seconds
[0m22:15:46.508831 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m22:15:46.509168 [debug] [MainThread]: Connection 'datawarehouse.information_schema' was properly closed.
[0m22:15:46.509558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067cb2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088a8bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093721f0>]}
[0m22:15:46.509998 [debug] [MainThread]: Flushing usage events
[0m22:16:52.968205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0272e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb48f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb48c40>]}


============================== 22:16:52.974980 | 477bb549-2501-4c71-b421-302721df6cb8 ==============================
[0m22:16:52.974980 [info ] [MainThread]: Running with dbt=1.8.5
[0m22:16:52.975707 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/user/Desktop/Learning Docker/belajar_docker/dbt/datawarehouse/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:16:53.145645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '477bb549-2501-4c71-b421-302721df6cb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2e0e80>]}
[0m22:16:53.206473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '477bb549-2501-4c71-b421-302721df6cb8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c55ea30>]}
[0m22:18:08.822877 [error] [MainThread]: Encountered an error:

[0m22:18:08.848489 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/lib/python3.9/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
  File "/Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/lib/python3.9/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
  File "/Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/lib/python3.9/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
  File "/Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/lib/python3.9/site-packages/dbt/cli/requires.py", line 247, in wrapper
    return func(*args, **kwargs)
  File "/Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/lib/python3.9/site-packages/dbt/cli/requires.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/lib/python3.9/site-packages/dbt/cli/main.py", line 303, in docs_serve
    results = task.run()
  File "/Users/user/Desktop/Learning Docker/belajar_docker/dbt/env/lib/python3.9/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socketserver.py", line 232, in serve_forever
    ready = selector.select(poll_interval)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt

[0m22:18:08.850816 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_wall_clock_time": 75.957664, "process_user_time": 1.558291, "process_kernel_time": 0.200615, "process_mem_max_rss": "92065792", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:18:08.851861 [debug] [MainThread]: Command `dbt docs serve` failed at 22:18:08.851706 after 75.96 seconds
[0m22:18:08.852512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b0272e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0e7250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0e75b0>]}
[0m22:18:08.853111 [debug] [MainThread]: Flushing usage events
